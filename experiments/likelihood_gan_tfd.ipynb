{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Generative Adversarial Network: Toronto Face Likelihood Experiments"
   ],
   "id": "891f1b1cacd919da"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-08T09:09:47.383607Z",
     "start_time": "2025-06-08T09:09:44.442894Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from utils import save_weights, load_weights\n",
    "import scipy.io\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from src.gan import GAN\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from likelihood import cross_validate_sigma, estimate_log_likelihood\n",
    "from utils import compute_mean_std, normalize_data, rescale_to_unit_interval_individual, rescale_to_unit_interval_global, save_weights"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:09:48.313007Z",
     "start_time": "2025-06-08T09:09:48.280404Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
   "id": "1f09ed92aab5cae3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:09:50.096807Z",
     "start_time": "2025-06-08T09:09:48.903200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = scipy.io.loadmat('./data/TFD/TFD_48x48.mat')\n",
    "data.keys()"
   ],
   "id": "b4e45444b2e0c33d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'images', 'labs_ex', 'labs_id', 'folds'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:09:51.167922Z",
     "start_time": "2025-06-08T09:09:51.162950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def configure_tfd(data, device='cuda', batch_size=100):\n",
    "    images = data['images']\n",
    "    labels = data['labs_id']\n",
    "\n",
    "    # Convert images to torch tensor if needed\n",
    "    if not isinstance(images, torch.Tensor):\n",
    "        images = torch.tensor(images, dtype=torch.float32)\n",
    "    images = images.to(device)\n",
    "\n",
    "    print(f\"Total number of samples: {images.shape[0]}\")\n",
    "\n",
    "    # Flatten images\n",
    "    X = images.reshape(images.shape[0], -1)\n",
    "\n",
    "    # Shuffle and split indices BEFORE normalization\n",
    "    total_samples = X.shape[0]\n",
    "    perm = torch.randperm(total_samples, device=device)\n",
    "    train_size = int(0.85 * total_samples)\n",
    "    train_idx = perm[:train_size]\n",
    "    test_idx = perm[train_size:]\n",
    "\n",
    "    X_train_raw = X[train_idx]\n",
    "    X_test = X[test_idx]  # leave unprocessed\n",
    "\n",
    "    # Compute mean and std from training set only\n",
    "    mean = X_train_raw.mean(dim=0)\n",
    "    std = X_train_raw.std(dim=0)\n",
    "\n",
    "    # Normalize only training data\n",
    "    X_train = (X_train_raw - mean) / std\n",
    "\n",
    "    # Create DataLoader for normalized training data\n",
    "    train_dataset = TensorDataset(X_train, torch.zeros(X_train.size(0), dtype=torch.uint8, device=device))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_loader, X_train, X_test, mean, std"
   ],
   "id": "6cb421e0a6ba4ea7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:09:54.720255Z",
     "start_time": "2025-06-08T09:09:54.239319Z"
    }
   },
   "cell_type": "code",
   "source": "train_loader, X_train, X_test, mean, std = configure_tfd(data, device=device, batch_size=100)",
   "id": "e3930b8315ed3b77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 102236\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Paper Configuration",
   "id": "6079fe9b338bb56b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:09:55.864745Z",
     "start_time": "2025-06-08T09:09:55.860873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "LATENT_DIM = 100\n",
    "NUM_EPOCHS = 300\n",
    "UNIFORM_RANGE = 3 ** 0.5\n",
    "GENERATOR_HIDDEN_DIM=8000\n",
    "DISCRIMINATOR_HIDDEN_DIM=1200\n",
    "INPUT_DIM = 2304\n",
    "LR = 0.05\n",
    "MIN_LR = 1e-6\n",
    "DECAY_FACTOR = (1/(1+4e-6))\n",
    "MOMENTUM = 0.5\n",
    "FINAL_MOMENTUM = 0.7\n",
    "MOMENTUM_SATURATE = 250\n",
    "BATCH_SIZE = 100\n",
    "USE_SIGMOID_GEN = False\n",
    "\n"
   ],
   "id": "e407935873d52bfd",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:09:58.577715Z",
     "start_time": "2025-06-08T09:09:57.479369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gan = GAN(\n",
    "    latent_dim=LATENT_DIM,\n",
    "    input_size=INPUT_DIM,\n",
    "    generator_hidden_dim=GENERATOR_HIDDEN_DIM,\n",
    "    discriminator_hidden_dim=DISCRIMINATOR_HIDDEN_DIM,\n",
    "    use_sigmoid_gen=USE_SIGMOID_GEN,\n",
    "    device=device\n",
    ")\n",
    "\n"
   ],
   "id": "8eba319989e4942c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T03:34:42.633845Z",
     "start_time": "2025-05-27T23:01:15.795798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gan.train_mbgd(\n",
    "    data_loader=train_loader,\n",
    "    learning_rate=LR,\n",
    "    uniform_range=UNIFORM_RANGE,\n",
    "    min_lr=MIN_LR,\n",
    "    decay_factor=DECAY_FACTOR,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    momentum=MOMENTUM,\n",
    "    final_momentum=FINAL_MOMENTUM,\n",
    "    momentum_saturate=MOMENTUM_SATURATE,\n",
    "    log_dir='./tmp_runs'\n",
    ")"
   ],
   "id": "8113ea0ee5b97fa3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/300] Batch 0 | G Loss: 0.6951 | D Loss: 1.3865 | LR: 0.050000 | Momentum: 0.5000\n",
      "[Epoch 1/300] Batch 100 | G Loss: 2.6417 | D Loss: 0.1725 | LR: 0.049980 | Momentum: 0.5000\n",
      "[Epoch 1/300] Batch 200 | G Loss: 5.6592 | D Loss: 0.5051 | LR: 0.049960 | Momentum: 0.5000\n",
      "[Epoch 1/300] Batch 300 | G Loss: 2.5310 | D Loss: 0.5150 | LR: 0.049940 | Momentum: 0.5000\n",
      "[Epoch 1/300] Batch 400 | G Loss: 1.9004 | D Loss: 0.4049 | LR: 0.049920 | Momentum: 0.5000\n",
      "[Epoch 1/300] Batch 500 | G Loss: 1.9381 | D Loss: 0.4915 | LR: 0.049900 | Momentum: 0.5000\n",
      "[Epoch 1/300] Batch 600 | G Loss: 2.5909 | D Loss: 0.7566 | LR: 0.049880 | Momentum: 0.5000\n",
      "[Epoch 1/300] Batch 700 | G Loss: 2.7229 | D Loss: 0.4005 | LR: 0.049860 | Momentum: 0.5000\n",
      "[Epoch 1/300] Batch 800 | G Loss: 3.0616 | D Loss: 0.5540 | LR: 0.049840 | Momentum: 0.5000\n",
      "[Epoch 2/300] Batch 0 | G Loss: 3.3330 | D Loss: 0.3974 | LR: 0.049827 | Momentum: 0.5000\n",
      "[Epoch 2/300] Batch 100 | G Loss: 4.3688 | D Loss: 0.8840 | LR: 0.049807 | Momentum: 0.5000\n",
      "[Epoch 2/300] Batch 200 | G Loss: 2.8866 | D Loss: 0.4563 | LR: 0.049787 | Momentum: 0.5000\n",
      "[Epoch 2/300] Batch 300 | G Loss: 2.3530 | D Loss: 0.6255 | LR: 0.049767 | Momentum: 0.5000\n",
      "[Epoch 2/300] Batch 400 | G Loss: 1.9085 | D Loss: 0.6097 | LR: 0.049747 | Momentum: 0.5000\n",
      "[Epoch 2/300] Batch 500 | G Loss: 1.3559 | D Loss: 0.9721 | LR: 0.049727 | Momentum: 0.5000\n",
      "[Epoch 2/300] Batch 600 | G Loss: 2.0594 | D Loss: 1.7395 | LR: 0.049707 | Momentum: 0.5000\n",
      "[Epoch 2/300] Batch 700 | G Loss: 1.4299 | D Loss: 1.7922 | LR: 0.049687 | Momentum: 0.5000\n",
      "[Epoch 2/300] Batch 800 | G Loss: 1.2005 | D Loss: 1.2107 | LR: 0.049667 | Momentum: 0.5000\n",
      "[Epoch 3/300] Batch 0 | G Loss: 1.6376 | D Loss: 0.9163 | LR: 0.049654 | Momentum: 0.5008\n",
      "[Epoch 3/300] Batch 100 | G Loss: 0.9636 | D Loss: 1.1449 | LR: 0.049634 | Momentum: 0.5008\n",
      "[Epoch 3/300] Batch 200 | G Loss: 1.5419 | D Loss: 1.1400 | LR: 0.049614 | Momentum: 0.5008\n",
      "[Epoch 3/300] Batch 300 | G Loss: 1.1826 | D Loss: 0.9668 | LR: 0.049594 | Momentum: 0.5008\n",
      "[Epoch 3/300] Batch 400 | G Loss: 1.0937 | D Loss: 1.0251 | LR: 0.049574 | Momentum: 0.5008\n",
      "[Epoch 3/300] Batch 500 | G Loss: 2.0298 | D Loss: 0.9756 | LR: 0.049554 | Momentum: 0.5008\n",
      "[Epoch 3/300] Batch 600 | G Loss: 1.0938 | D Loss: 0.8929 | LR: 0.049535 | Momentum: 0.5008\n",
      "[Epoch 3/300] Batch 700 | G Loss: 1.4933 | D Loss: 0.7288 | LR: 0.049515 | Momentum: 0.5008\n",
      "[Epoch 3/300] Batch 800 | G Loss: 1.2370 | D Loss: 1.0659 | LR: 0.049495 | Momentum: 0.5008\n",
      "[Epoch 4/300] Batch 0 | G Loss: 1.0191 | D Loss: 1.0769 | LR: 0.049481 | Momentum: 0.5016\n",
      "[Epoch 4/300] Batch 100 | G Loss: 1.2845 | D Loss: 0.9372 | LR: 0.049462 | Momentum: 0.5016\n",
      "[Epoch 4/300] Batch 200 | G Loss: 1.4225 | D Loss: 1.0012 | LR: 0.049442 | Momentum: 0.5016\n",
      "[Epoch 4/300] Batch 300 | G Loss: 2.4301 | D Loss: 1.3371 | LR: 0.049422 | Momentum: 0.5016\n",
      "[Epoch 4/300] Batch 400 | G Loss: 0.9976 | D Loss: 1.1853 | LR: 0.049402 | Momentum: 0.5016\n",
      "[Epoch 4/300] Batch 500 | G Loss: 1.3529 | D Loss: 1.1405 | LR: 0.049382 | Momentum: 0.5016\n",
      "[Epoch 4/300] Batch 600 | G Loss: 0.9950 | D Loss: 1.0511 | LR: 0.049363 | Momentum: 0.5016\n",
      "[Epoch 4/300] Batch 700 | G Loss: 1.0079 | D Loss: 0.9937 | LR: 0.049343 | Momentum: 0.5016\n",
      "[Epoch 4/300] Batch 800 | G Loss: 1.2464 | D Loss: 1.0284 | LR: 0.049323 | Momentum: 0.5016\n",
      "[Epoch 5/300] Batch 0 | G Loss: 1.1205 | D Loss: 1.0283 | LR: 0.049310 | Momentum: 0.5024\n",
      "[Epoch 5/300] Batch 100 | G Loss: 1.3710 | D Loss: 1.0341 | LR: 0.049290 | Momentum: 0.5024\n",
      "[Epoch 5/300] Batch 200 | G Loss: 1.5068 | D Loss: 1.0739 | LR: 0.049270 | Momentum: 0.5024\n",
      "[Epoch 5/300] Batch 300 | G Loss: 0.9692 | D Loss: 1.1082 | LR: 0.049250 | Momentum: 0.5024\n",
      "[Epoch 5/300] Batch 400 | G Loss: 1.7314 | D Loss: 1.1460 | LR: 0.049231 | Momentum: 0.5024\n",
      "[Epoch 5/300] Batch 500 | G Loss: 1.3205 | D Loss: 1.0307 | LR: 0.049211 | Momentum: 0.5024\n",
      "[Epoch 5/300] Batch 600 | G Loss: 1.5700 | D Loss: 1.1404 | LR: 0.049191 | Momentum: 0.5024\n",
      "[Epoch 5/300] Batch 700 | G Loss: 1.4586 | D Loss: 1.0595 | LR: 0.049172 | Momentum: 0.5024\n",
      "[Epoch 5/300] Batch 800 | G Loss: 1.0423 | D Loss: 1.1066 | LR: 0.049152 | Momentum: 0.5024\n",
      "[Epoch 6/300] Batch 0 | G Loss: 1.1742 | D Loss: 1.0631 | LR: 0.049139 | Momentum: 0.5032\n",
      "[Epoch 6/300] Batch 100 | G Loss: 1.3924 | D Loss: 0.9705 | LR: 0.049119 | Momentum: 0.5032\n",
      "[Epoch 6/300] Batch 200 | G Loss: 1.3054 | D Loss: 1.1772 | LR: 0.049099 | Momentum: 0.5032\n",
      "[Epoch 6/300] Batch 300 | G Loss: 1.2192 | D Loss: 1.1131 | LR: 0.049080 | Momentum: 0.5032\n",
      "[Epoch 6/300] Batch 400 | G Loss: 1.2038 | D Loss: 1.0008 | LR: 0.049060 | Momentum: 0.5032\n",
      "[Epoch 6/300] Batch 500 | G Loss: 1.3500 | D Loss: 1.1881 | LR: 0.049040 | Momentum: 0.5032\n",
      "[Epoch 6/300] Batch 600 | G Loss: 1.2249 | D Loss: 1.0617 | LR: 0.049021 | Momentum: 0.5032\n",
      "[Epoch 6/300] Batch 700 | G Loss: 1.3596 | D Loss: 1.0145 | LR: 0.049001 | Momentum: 0.5032\n",
      "[Epoch 6/300] Batch 800 | G Loss: 1.2906 | D Loss: 1.1499 | LR: 0.048982 | Momentum: 0.5032\n",
      "[Epoch 7/300] Batch 0 | G Loss: 1.1922 | D Loss: 1.1086 | LR: 0.048968 | Momentum: 0.5040\n",
      "[Epoch 7/300] Batch 100 | G Loss: 1.3313 | D Loss: 1.0516 | LR: 0.048948 | Momentum: 0.5040\n",
      "[Epoch 7/300] Batch 200 | G Loss: 1.4870 | D Loss: 1.2272 | LR: 0.048929 | Momentum: 0.5040\n",
      "[Epoch 7/300] Batch 300 | G Loss: 1.2030 | D Loss: 0.9889 | LR: 0.048909 | Momentum: 0.5040\n",
      "[Epoch 7/300] Batch 400 | G Loss: 1.8114 | D Loss: 1.1615 | LR: 0.048890 | Momentum: 0.5040\n",
      "[Epoch 7/300] Batch 500 | G Loss: 1.0773 | D Loss: 1.1056 | LR: 0.048870 | Momentum: 0.5040\n",
      "[Epoch 7/300] Batch 600 | G Loss: 1.4059 | D Loss: 1.1235 | LR: 0.048851 | Momentum: 0.5040\n",
      "[Epoch 7/300] Batch 700 | G Loss: 1.2357 | D Loss: 1.0446 | LR: 0.048831 | Momentum: 0.5040\n",
      "[Epoch 7/300] Batch 800 | G Loss: 1.3278 | D Loss: 1.0923 | LR: 0.048812 | Momentum: 0.5040\n",
      "[Epoch 8/300] Batch 0 | G Loss: 1.2687 | D Loss: 1.0251 | LR: 0.048798 | Momentum: 0.5048\n",
      "[Epoch 8/300] Batch 100 | G Loss: 1.0970 | D Loss: 1.0147 | LR: 0.048779 | Momentum: 0.5048\n",
      "[Epoch 8/300] Batch 200 | G Loss: 1.1520 | D Loss: 1.1135 | LR: 0.048759 | Momentum: 0.5048\n",
      "[Epoch 8/300] Batch 300 | G Loss: 1.2549 | D Loss: 1.0712 | LR: 0.048740 | Momentum: 0.5048\n",
      "[Epoch 8/300] Batch 400 | G Loss: 1.1567 | D Loss: 1.0071 | LR: 0.048720 | Momentum: 0.5048\n",
      "[Epoch 8/300] Batch 500 | G Loss: 1.2624 | D Loss: 1.1521 | LR: 0.048701 | Momentum: 0.5048\n",
      "[Epoch 8/300] Batch 600 | G Loss: 1.4287 | D Loss: 1.0020 | LR: 0.048681 | Momentum: 0.5048\n",
      "[Epoch 8/300] Batch 700 | G Loss: 1.3382 | D Loss: 1.0499 | LR: 0.048662 | Momentum: 0.5048\n",
      "[Epoch 8/300] Batch 800 | G Loss: 0.9810 | D Loss: 1.0436 | LR: 0.048642 | Momentum: 0.5048\n",
      "[Epoch 9/300] Batch 0 | G Loss: 1.4107 | D Loss: 1.1008 | LR: 0.048629 | Momentum: 0.5056\n",
      "[Epoch 9/300] Batch 100 | G Loss: 0.9702 | D Loss: 1.1001 | LR: 0.048609 | Momentum: 0.5056\n",
      "[Epoch 9/300] Batch 200 | G Loss: 1.0644 | D Loss: 1.0701 | LR: 0.048590 | Momentum: 0.5056\n",
      "[Epoch 9/300] Batch 300 | G Loss: 1.2117 | D Loss: 1.1518 | LR: 0.048570 | Momentum: 0.5056\n",
      "[Epoch 9/300] Batch 400 | G Loss: 1.0873 | D Loss: 1.1767 | LR: 0.048551 | Momentum: 0.5056\n",
      "[Epoch 9/300] Batch 500 | G Loss: 1.1536 | D Loss: 1.0887 | LR: 0.048532 | Momentum: 0.5056\n",
      "[Epoch 9/300] Batch 600 | G Loss: 1.0210 | D Loss: 0.9893 | LR: 0.048512 | Momentum: 0.5056\n",
      "[Epoch 9/300] Batch 700 | G Loss: 1.3679 | D Loss: 1.1634 | LR: 0.048493 | Momentum: 0.5056\n",
      "[Epoch 9/300] Batch 800 | G Loss: 1.2326 | D Loss: 1.1859 | LR: 0.048473 | Momentum: 0.5056\n",
      "[Epoch 10/300] Batch 0 | G Loss: 1.1377 | D Loss: 1.0638 | LR: 0.048460 | Momentum: 0.5064\n",
      "[Epoch 10/300] Batch 100 | G Loss: 1.1743 | D Loss: 1.0079 | LR: 0.048441 | Momentum: 0.5064\n",
      "[Epoch 10/300] Batch 200 | G Loss: 1.0380 | D Loss: 0.9930 | LR: 0.048421 | Momentum: 0.5064\n",
      "[Epoch 10/300] Batch 300 | G Loss: 1.2892 | D Loss: 1.1343 | LR: 0.048402 | Momentum: 0.5064\n",
      "[Epoch 10/300] Batch 400 | G Loss: 1.2241 | D Loss: 1.1010 | LR: 0.048383 | Momentum: 0.5064\n",
      "[Epoch 10/300] Batch 500 | G Loss: 1.0829 | D Loss: 1.0729 | LR: 0.048363 | Momentum: 0.5064\n",
      "[Epoch 10/300] Batch 600 | G Loss: 1.0643 | D Loss: 1.1008 | LR: 0.048344 | Momentum: 0.5064\n",
      "[Epoch 10/300] Batch 700 | G Loss: 1.1627 | D Loss: 1.0247 | LR: 0.048325 | Momentum: 0.5064\n",
      "[Epoch 10/300] Batch 800 | G Loss: 1.0740 | D Loss: 1.0970 | LR: 0.048305 | Momentum: 0.5064\n",
      "[Epoch 11/300] Batch 0 | G Loss: 1.2711 | D Loss: 0.9565 | LR: 0.048292 | Momentum: 0.5072\n",
      "[Epoch 11/300] Batch 100 | G Loss: 1.2884 | D Loss: 1.2116 | LR: 0.048273 | Momentum: 0.5072\n",
      "[Epoch 11/300] Batch 200 | G Loss: 1.0811 | D Loss: 1.1517 | LR: 0.048253 | Momentum: 0.5072\n",
      "[Epoch 11/300] Batch 300 | G Loss: 1.1658 | D Loss: 1.0608 | LR: 0.048234 | Momentum: 0.5072\n",
      "[Epoch 11/300] Batch 400 | G Loss: 1.2743 | D Loss: 0.9994 | LR: 0.048215 | Momentum: 0.5072\n",
      "[Epoch 11/300] Batch 500 | G Loss: 1.0707 | D Loss: 1.0204 | LR: 0.048195 | Momentum: 0.5072\n",
      "[Epoch 11/300] Batch 600 | G Loss: 1.2047 | D Loss: 1.1904 | LR: 0.048176 | Momentum: 0.5072\n",
      "[Epoch 11/300] Batch 700 | G Loss: 1.1778 | D Loss: 1.0208 | LR: 0.048157 | Momentum: 0.5072\n",
      "[Epoch 11/300] Batch 800 | G Loss: 1.2143 | D Loss: 1.1946 | LR: 0.048138 | Momentum: 0.5072\n",
      "[Epoch 12/300] Batch 0 | G Loss: 1.1448 | D Loss: 1.0392 | LR: 0.048124 | Momentum: 0.5080\n",
      "[Epoch 12/300] Batch 100 | G Loss: 1.0556 | D Loss: 0.9948 | LR: 0.048105 | Momentum: 0.5080\n",
      "[Epoch 12/300] Batch 200 | G Loss: 1.1932 | D Loss: 1.0670 | LR: 0.048086 | Momentum: 0.5080\n",
      "[Epoch 12/300] Batch 300 | G Loss: 1.1125 | D Loss: 1.1073 | LR: 0.048067 | Momentum: 0.5080\n",
      "[Epoch 12/300] Batch 400 | G Loss: 1.0984 | D Loss: 1.1641 | LR: 0.048047 | Momentum: 0.5080\n",
      "[Epoch 12/300] Batch 500 | G Loss: 1.2311 | D Loss: 1.2294 | LR: 0.048028 | Momentum: 0.5080\n",
      "[Epoch 12/300] Batch 600 | G Loss: 1.0038 | D Loss: 0.9812 | LR: 0.048009 | Momentum: 0.5080\n",
      "[Epoch 12/300] Batch 700 | G Loss: 1.0495 | D Loss: 1.0599 | LR: 0.047990 | Momentum: 0.5080\n",
      "[Epoch 12/300] Batch 800 | G Loss: 1.0519 | D Loss: 1.1106 | LR: 0.047971 | Momentum: 0.5080\n",
      "[Epoch 13/300] Batch 0 | G Loss: 1.1167 | D Loss: 1.0372 | LR: 0.047957 | Momentum: 0.5088\n",
      "[Epoch 13/300] Batch 100 | G Loss: 1.2178 | D Loss: 1.0645 | LR: 0.047938 | Momentum: 0.5088\n",
      "[Epoch 13/300] Batch 200 | G Loss: 1.2966 | D Loss: 0.9660 | LR: 0.047919 | Momentum: 0.5088\n",
      "[Epoch 13/300] Batch 300 | G Loss: 1.3300 | D Loss: 1.0451 | LR: 0.047900 | Momentum: 0.5088\n",
      "[Epoch 13/300] Batch 400 | G Loss: 0.9424 | D Loss: 1.0958 | LR: 0.047881 | Momentum: 0.5088\n",
      "[Epoch 13/300] Batch 500 | G Loss: 1.0937 | D Loss: 1.1264 | LR: 0.047861 | Momentum: 0.5088\n",
      "[Epoch 13/300] Batch 600 | G Loss: 1.0428 | D Loss: 1.0116 | LR: 0.047842 | Momentum: 0.5088\n",
      "[Epoch 13/300] Batch 700 | G Loss: 1.0534 | D Loss: 1.1773 | LR: 0.047823 | Momentum: 0.5088\n",
      "[Epoch 13/300] Batch 800 | G Loss: 1.1122 | D Loss: 1.0774 | LR: 0.047804 | Momentum: 0.5088\n",
      "[Epoch 14/300] Batch 0 | G Loss: 1.2735 | D Loss: 1.0502 | LR: 0.047791 | Momentum: 0.5096\n",
      "[Epoch 14/300] Batch 100 | G Loss: 0.9929 | D Loss: 1.1798 | LR: 0.047772 | Momentum: 0.5096\n",
      "[Epoch 14/300] Batch 200 | G Loss: 1.0100 | D Loss: 1.0373 | LR: 0.047753 | Momentum: 0.5096\n",
      "[Epoch 14/300] Batch 300 | G Loss: 0.9849 | D Loss: 1.0082 | LR: 0.047734 | Momentum: 0.5096\n",
      "[Epoch 14/300] Batch 400 | G Loss: 1.0319 | D Loss: 1.2167 | LR: 0.047714 | Momentum: 0.5096\n",
      "[Epoch 14/300] Batch 500 | G Loss: 1.0593 | D Loss: 1.1762 | LR: 0.047695 | Momentum: 0.5096\n",
      "[Epoch 14/300] Batch 600 | G Loss: 1.0695 | D Loss: 1.2168 | LR: 0.047676 | Momentum: 0.5096\n",
      "[Epoch 14/300] Batch 700 | G Loss: 1.0064 | D Loss: 1.1525 | LR: 0.047657 | Momentum: 0.5096\n",
      "[Epoch 14/300] Batch 800 | G Loss: 1.2268 | D Loss: 1.0952 | LR: 0.047638 | Momentum: 0.5096\n",
      "[Epoch 15/300] Batch 0 | G Loss: 1.0156 | D Loss: 1.2254 | LR: 0.047625 | Momentum: 0.5104\n",
      "[Epoch 15/300] Batch 100 | G Loss: 1.1149 | D Loss: 1.1950 | LR: 0.047606 | Momentum: 0.5104\n",
      "[Epoch 15/300] Batch 200 | G Loss: 1.1529 | D Loss: 1.1534 | LR: 0.047587 | Momentum: 0.5104\n",
      "[Epoch 15/300] Batch 300 | G Loss: 1.0182 | D Loss: 1.0676 | LR: 0.047568 | Momentum: 0.5104\n",
      "[Epoch 15/300] Batch 400 | G Loss: 0.8427 | D Loss: 1.1141 | LR: 0.047549 | Momentum: 0.5104\n",
      "[Epoch 15/300] Batch 500 | G Loss: 1.1540 | D Loss: 1.1098 | LR: 0.047530 | Momentum: 0.5104\n",
      "[Epoch 15/300] Batch 600 | G Loss: 1.0848 | D Loss: 1.1184 | LR: 0.047511 | Momentum: 0.5104\n",
      "[Epoch 15/300] Batch 700 | G Loss: 1.2126 | D Loss: 1.1623 | LR: 0.047492 | Momentum: 0.5104\n",
      "[Epoch 15/300] Batch 800 | G Loss: 1.0070 | D Loss: 1.1162 | LR: 0.047473 | Momentum: 0.5104\n",
      "[Epoch 16/300] Batch 0 | G Loss: 0.9756 | D Loss: 1.0878 | LR: 0.047460 | Momentum: 0.5112\n",
      "[Epoch 16/300] Batch 100 | G Loss: 1.0287 | D Loss: 1.1489 | LR: 0.047441 | Momentum: 0.5112\n",
      "[Epoch 16/300] Batch 200 | G Loss: 1.1144 | D Loss: 1.1607 | LR: 0.047422 | Momentum: 0.5112\n",
      "[Epoch 16/300] Batch 300 | G Loss: 0.9489 | D Loss: 1.0208 | LR: 0.047403 | Momentum: 0.5112\n",
      "[Epoch 16/300] Batch 400 | G Loss: 1.0415 | D Loss: 1.2136 | LR: 0.047384 | Momentum: 0.5112\n",
      "[Epoch 16/300] Batch 500 | G Loss: 1.0481 | D Loss: 1.1026 | LR: 0.047365 | Momentum: 0.5112\n",
      "[Epoch 16/300] Batch 600 | G Loss: 1.3128 | D Loss: 1.2111 | LR: 0.047346 | Momentum: 0.5112\n",
      "[Epoch 16/300] Batch 700 | G Loss: 0.9952 | D Loss: 1.1520 | LR: 0.047327 | Momentum: 0.5112\n",
      "[Epoch 16/300] Batch 800 | G Loss: 1.0176 | D Loss: 1.1596 | LR: 0.047308 | Momentum: 0.5112\n",
      "[Epoch 17/300] Batch 0 | G Loss: 1.0524 | D Loss: 1.0329 | LR: 0.047295 | Momentum: 0.5120\n",
      "[Epoch 17/300] Batch 100 | G Loss: 1.1476 | D Loss: 1.0644 | LR: 0.047276 | Momentum: 0.5120\n",
      "[Epoch 17/300] Batch 200 | G Loss: 0.9942 | D Loss: 1.1592 | LR: 0.047257 | Momentum: 0.5120\n",
      "[Epoch 17/300] Batch 300 | G Loss: 1.1108 | D Loss: 1.1078 | LR: 0.047238 | Momentum: 0.5120\n",
      "[Epoch 17/300] Batch 400 | G Loss: 1.2611 | D Loss: 1.2506 | LR: 0.047220 | Momentum: 0.5120\n",
      "[Epoch 17/300] Batch 500 | G Loss: 0.9989 | D Loss: 1.1487 | LR: 0.047201 | Momentum: 0.5120\n",
      "[Epoch 17/300] Batch 600 | G Loss: 1.1563 | D Loss: 1.1173 | LR: 0.047182 | Momentum: 0.5120\n",
      "[Epoch 17/300] Batch 700 | G Loss: 1.1424 | D Loss: 1.2330 | LR: 0.047163 | Momentum: 0.5120\n",
      "[Epoch 17/300] Batch 800 | G Loss: 1.0878 | D Loss: 1.0855 | LR: 0.047144 | Momentum: 0.5120\n",
      "[Epoch 18/300] Batch 0 | G Loss: 1.0454 | D Loss: 1.1223 | LR: 0.047131 | Momentum: 0.5128\n",
      "[Epoch 18/300] Batch 100 | G Loss: 0.9304 | D Loss: 1.2516 | LR: 0.047112 | Momentum: 0.5128\n",
      "[Epoch 18/300] Batch 200 | G Loss: 1.1878 | D Loss: 1.0628 | LR: 0.047093 | Momentum: 0.5128\n",
      "[Epoch 18/300] Batch 300 | G Loss: 1.0891 | D Loss: 1.0821 | LR: 0.047074 | Momentum: 0.5128\n",
      "[Epoch 18/300] Batch 400 | G Loss: 1.0438 | D Loss: 1.0747 | LR: 0.047056 | Momentum: 0.5128\n",
      "[Epoch 18/300] Batch 500 | G Loss: 1.0477 | D Loss: 1.0681 | LR: 0.047037 | Momentum: 0.5128\n",
      "[Epoch 18/300] Batch 600 | G Loss: 1.0548 | D Loss: 1.2516 | LR: 0.047018 | Momentum: 0.5128\n",
      "[Epoch 18/300] Batch 700 | G Loss: 1.1547 | D Loss: 1.1680 | LR: 0.046999 | Momentum: 0.5128\n",
      "[Epoch 18/300] Batch 800 | G Loss: 1.0996 | D Loss: 1.2359 | LR: 0.046980 | Momentum: 0.5128\n",
      "[Epoch 19/300] Batch 0 | G Loss: 0.9482 | D Loss: 1.0611 | LR: 0.046967 | Momentum: 0.5136\n",
      "[Epoch 19/300] Batch 100 | G Loss: 0.9607 | D Loss: 1.2746 | LR: 0.046949 | Momentum: 0.5136\n",
      "[Epoch 19/300] Batch 200 | G Loss: 1.1638 | D Loss: 1.1866 | LR: 0.046930 | Momentum: 0.5136\n",
      "[Epoch 19/300] Batch 300 | G Loss: 1.0121 | D Loss: 1.1331 | LR: 0.046911 | Momentum: 0.5136\n",
      "[Epoch 19/300] Batch 400 | G Loss: 0.9290 | D Loss: 1.0897 | LR: 0.046892 | Momentum: 0.5136\n",
      "[Epoch 19/300] Batch 500 | G Loss: 1.0717 | D Loss: 1.2416 | LR: 0.046874 | Momentum: 0.5136\n",
      "[Epoch 19/300] Batch 600 | G Loss: 0.9648 | D Loss: 1.1299 | LR: 0.046855 | Momentum: 0.5136\n",
      "[Epoch 19/300] Batch 700 | G Loss: 1.0359 | D Loss: 1.1229 | LR: 0.046836 | Momentum: 0.5136\n",
      "[Epoch 19/300] Batch 800 | G Loss: 0.9740 | D Loss: 1.2351 | LR: 0.046817 | Momentum: 0.5136\n",
      "[Epoch 20/300] Batch 0 | G Loss: 0.9191 | D Loss: 1.0967 | LR: 0.046804 | Momentum: 0.5144\n",
      "[Epoch 20/300] Batch 100 | G Loss: 1.1193 | D Loss: 1.0756 | LR: 0.046786 | Momentum: 0.5144\n",
      "[Epoch 20/300] Batch 200 | G Loss: 1.1337 | D Loss: 1.1620 | LR: 0.046767 | Momentum: 0.5144\n",
      "[Epoch 20/300] Batch 300 | G Loss: 0.9845 | D Loss: 1.1039 | LR: 0.046748 | Momentum: 0.5144\n",
      "[Epoch 20/300] Batch 400 | G Loss: 1.1138 | D Loss: 1.2224 | LR: 0.046730 | Momentum: 0.5144\n",
      "[Epoch 20/300] Batch 500 | G Loss: 0.9608 | D Loss: 1.0669 | LR: 0.046711 | Momentum: 0.5144\n",
      "[Epoch 20/300] Batch 600 | G Loss: 1.0436 | D Loss: 1.1319 | LR: 0.046692 | Momentum: 0.5144\n",
      "[Epoch 20/300] Batch 700 | G Loss: 0.9839 | D Loss: 1.2953 | LR: 0.046674 | Momentum: 0.5144\n",
      "[Epoch 20/300] Batch 800 | G Loss: 1.1513 | D Loss: 1.3147 | LR: 0.046655 | Momentum: 0.5144\n",
      "[Epoch 21/300] Batch 0 | G Loss: 1.1861 | D Loss: 1.1766 | LR: 0.046642 | Momentum: 0.5152\n",
      "[Epoch 21/300] Batch 100 | G Loss: 0.9473 | D Loss: 1.0983 | LR: 0.046623 | Momentum: 0.5152\n",
      "[Epoch 21/300] Batch 200 | G Loss: 1.0256 | D Loss: 1.0736 | LR: 0.046605 | Momentum: 0.5152\n",
      "[Epoch 21/300] Batch 300 | G Loss: 0.9599 | D Loss: 1.1595 | LR: 0.046586 | Momentum: 0.5152\n",
      "[Epoch 21/300] Batch 400 | G Loss: 0.9889 | D Loss: 1.1004 | LR: 0.046568 | Momentum: 0.5152\n",
      "[Epoch 21/300] Batch 500 | G Loss: 0.9543 | D Loss: 1.0956 | LR: 0.046549 | Momentum: 0.5152\n",
      "[Epoch 21/300] Batch 600 | G Loss: 1.1482 | D Loss: 1.0913 | LR: 0.046530 | Momentum: 0.5152\n",
      "[Epoch 21/300] Batch 700 | G Loss: 0.9968 | D Loss: 1.1520 | LR: 0.046512 | Momentum: 0.5152\n",
      "[Epoch 21/300] Batch 800 | G Loss: 1.0567 | D Loss: 1.1748 | LR: 0.046493 | Momentum: 0.5152\n",
      "[Epoch 22/300] Batch 0 | G Loss: 1.0432 | D Loss: 1.1584 | LR: 0.046480 | Momentum: 0.5160\n",
      "[Epoch 22/300] Batch 100 | G Loss: 0.9490 | D Loss: 1.1742 | LR: 0.046462 | Momentum: 0.5160\n",
      "[Epoch 22/300] Batch 200 | G Loss: 1.0284 | D Loss: 1.1508 | LR: 0.046443 | Momentum: 0.5160\n",
      "[Epoch 22/300] Batch 300 | G Loss: 1.1357 | D Loss: 1.2456 | LR: 0.046424 | Momentum: 0.5160\n",
      "[Epoch 22/300] Batch 400 | G Loss: 1.1804 | D Loss: 1.2404 | LR: 0.046406 | Momentum: 0.5160\n",
      "[Epoch 22/300] Batch 500 | G Loss: 1.0813 | D Loss: 1.1707 | LR: 0.046387 | Momentum: 0.5160\n",
      "[Epoch 22/300] Batch 600 | G Loss: 1.1626 | D Loss: 1.1166 | LR: 0.046369 | Momentum: 0.5160\n",
      "[Epoch 22/300] Batch 700 | G Loss: 1.0224 | D Loss: 1.1932 | LR: 0.046350 | Momentum: 0.5160\n",
      "[Epoch 22/300] Batch 800 | G Loss: 0.9731 | D Loss: 1.2116 | LR: 0.046332 | Momentum: 0.5160\n",
      "[Epoch 23/300] Batch 0 | G Loss: 1.0326 | D Loss: 1.1828 | LR: 0.046319 | Momentum: 0.5168\n",
      "[Epoch 23/300] Batch 100 | G Loss: 1.0184 | D Loss: 1.1235 | LR: 0.046300 | Momentum: 0.5168\n",
      "[Epoch 23/300] Batch 200 | G Loss: 1.1390 | D Loss: 1.1906 | LR: 0.046282 | Momentum: 0.5168\n",
      "[Epoch 23/300] Batch 300 | G Loss: 0.8987 | D Loss: 1.1949 | LR: 0.046263 | Momentum: 0.5168\n",
      "[Epoch 23/300] Batch 400 | G Loss: 1.2103 | D Loss: 1.1119 | LR: 0.046245 | Momentum: 0.5168\n",
      "[Epoch 23/300] Batch 500 | G Loss: 1.0054 | D Loss: 1.2955 | LR: 0.046226 | Momentum: 0.5168\n",
      "[Epoch 23/300] Batch 600 | G Loss: 1.1161 | D Loss: 1.1217 | LR: 0.046208 | Momentum: 0.5168\n",
      "[Epoch 23/300] Batch 700 | G Loss: 1.0747 | D Loss: 1.1257 | LR: 0.046189 | Momentum: 0.5168\n",
      "[Epoch 23/300] Batch 800 | G Loss: 0.8941 | D Loss: 1.1812 | LR: 0.046171 | Momentum: 0.5168\n",
      "[Epoch 24/300] Batch 0 | G Loss: 1.0703 | D Loss: 1.1558 | LR: 0.046158 | Momentum: 0.5176\n",
      "[Epoch 24/300] Batch 100 | G Loss: 0.9554 | D Loss: 1.2312 | LR: 0.046140 | Momentum: 0.5176\n",
      "[Epoch 24/300] Batch 200 | G Loss: 1.1534 | D Loss: 1.1866 | LR: 0.046121 | Momentum: 0.5176\n",
      "[Epoch 24/300] Batch 300 | G Loss: 1.0895 | D Loss: 1.1520 | LR: 0.046103 | Momentum: 0.5176\n",
      "[Epoch 24/300] Batch 400 | G Loss: 1.1866 | D Loss: 1.0229 | LR: 0.046084 | Momentum: 0.5176\n",
      "[Epoch 24/300] Batch 500 | G Loss: 1.0418 | D Loss: 1.1874 | LR: 0.046066 | Momentum: 0.5176\n",
      "[Epoch 24/300] Batch 600 | G Loss: 0.9830 | D Loss: 1.2213 | LR: 0.046048 | Momentum: 0.5176\n",
      "[Epoch 24/300] Batch 700 | G Loss: 0.9502 | D Loss: 1.2067 | LR: 0.046029 | Momentum: 0.5176\n",
      "[Epoch 24/300] Batch 800 | G Loss: 1.0123 | D Loss: 1.2059 | LR: 0.046011 | Momentum: 0.5176\n",
      "[Epoch 25/300] Batch 0 | G Loss: 1.1264 | D Loss: 1.1663 | LR: 0.045998 | Momentum: 0.5184\n",
      "[Epoch 25/300] Batch 100 | G Loss: 1.0806 | D Loss: 1.1404 | LR: 0.045980 | Momentum: 0.5184\n",
      "[Epoch 25/300] Batch 200 | G Loss: 0.9695 | D Loss: 1.2568 | LR: 0.045961 | Momentum: 0.5184\n",
      "[Epoch 25/300] Batch 300 | G Loss: 1.2683 | D Loss: 1.2432 | LR: 0.045943 | Momentum: 0.5184\n",
      "[Epoch 25/300] Batch 400 | G Loss: 0.9345 | D Loss: 1.2005 | LR: 0.045925 | Momentum: 0.5184\n",
      "[Epoch 25/300] Batch 500 | G Loss: 0.9401 | D Loss: 1.2642 | LR: 0.045906 | Momentum: 0.5184\n",
      "[Epoch 25/300] Batch 600 | G Loss: 1.2176 | D Loss: 1.2279 | LR: 0.045888 | Momentum: 0.5184\n",
      "[Epoch 25/300] Batch 700 | G Loss: 1.0251 | D Loss: 1.2113 | LR: 0.045869 | Momentum: 0.5184\n",
      "[Epoch 25/300] Batch 800 | G Loss: 1.1182 | D Loss: 1.2149 | LR: 0.045851 | Momentum: 0.5184\n",
      "[Epoch 26/300] Batch 0 | G Loss: 1.0673 | D Loss: 1.2615 | LR: 0.045838 | Momentum: 0.5192\n",
      "[Epoch 26/300] Batch 100 | G Loss: 0.9632 | D Loss: 1.2319 | LR: 0.045820 | Momentum: 0.5192\n",
      "[Epoch 26/300] Batch 200 | G Loss: 1.0055 | D Loss: 1.1465 | LR: 0.045802 | Momentum: 0.5192\n",
      "[Epoch 26/300] Batch 300 | G Loss: 1.1155 | D Loss: 1.1317 | LR: 0.045783 | Momentum: 0.5192\n",
      "[Epoch 26/300] Batch 400 | G Loss: 0.9133 | D Loss: 1.2367 | LR: 0.045765 | Momentum: 0.5192\n",
      "[Epoch 26/300] Batch 500 | G Loss: 0.9090 | D Loss: 1.1717 | LR: 0.045747 | Momentum: 0.5192\n",
      "[Epoch 26/300] Batch 600 | G Loss: 1.1393 | D Loss: 1.1920 | LR: 0.045729 | Momentum: 0.5192\n",
      "[Epoch 26/300] Batch 700 | G Loss: 1.0351 | D Loss: 1.1553 | LR: 0.045710 | Momentum: 0.5192\n",
      "[Epoch 26/300] Batch 800 | G Loss: 0.9758 | D Loss: 1.2245 | LR: 0.045692 | Momentum: 0.5192\n",
      "[Epoch 27/300] Batch 0 | G Loss: 0.9542 | D Loss: 1.1672 | LR: 0.045679 | Momentum: 0.5200\n",
      "[Epoch 27/300] Batch 100 | G Loss: 1.0439 | D Loss: 1.1579 | LR: 0.045661 | Momentum: 0.5200\n",
      "[Epoch 27/300] Batch 200 | G Loss: 0.9290 | D Loss: 1.0902 | LR: 0.045643 | Momentum: 0.5200\n",
      "[Epoch 27/300] Batch 300 | G Loss: 0.9985 | D Loss: 1.1119 | LR: 0.045625 | Momentum: 0.5200\n",
      "[Epoch 27/300] Batch 400 | G Loss: 0.8652 | D Loss: 1.1651 | LR: 0.045606 | Momentum: 0.5200\n",
      "[Epoch 27/300] Batch 500 | G Loss: 1.0086 | D Loss: 1.1326 | LR: 0.045588 | Momentum: 0.5200\n",
      "[Epoch 27/300] Batch 600 | G Loss: 1.0416 | D Loss: 1.1833 | LR: 0.045570 | Momentum: 0.5200\n",
      "[Epoch 27/300] Batch 700 | G Loss: 0.9783 | D Loss: 1.2230 | LR: 0.045552 | Momentum: 0.5200\n",
      "[Epoch 27/300] Batch 800 | G Loss: 1.0044 | D Loss: 1.1110 | LR: 0.045533 | Momentum: 0.5200\n",
      "[Epoch 28/300] Batch 0 | G Loss: 0.9213 | D Loss: 1.2048 | LR: 0.045521 | Momentum: 0.5208\n",
      "[Epoch 28/300] Batch 100 | G Loss: 1.0377 | D Loss: 1.1251 | LR: 0.045503 | Momentum: 0.5208\n",
      "[Epoch 28/300] Batch 200 | G Loss: 0.9920 | D Loss: 1.1660 | LR: 0.045484 | Momentum: 0.5208\n",
      "[Epoch 28/300] Batch 300 | G Loss: 1.0263 | D Loss: 1.1118 | LR: 0.045466 | Momentum: 0.5208\n",
      "[Epoch 28/300] Batch 400 | G Loss: 0.9691 | D Loss: 1.2474 | LR: 0.045448 | Momentum: 0.5208\n",
      "[Epoch 28/300] Batch 500 | G Loss: 0.9681 | D Loss: 1.1402 | LR: 0.045430 | Momentum: 0.5208\n",
      "[Epoch 28/300] Batch 600 | G Loss: 1.0797 | D Loss: 1.2386 | LR: 0.045412 | Momentum: 0.5208\n",
      "[Epoch 28/300] Batch 700 | G Loss: 1.0231 | D Loss: 1.1871 | LR: 0.045394 | Momentum: 0.5208\n",
      "[Epoch 28/300] Batch 800 | G Loss: 0.9501 | D Loss: 1.1338 | LR: 0.045375 | Momentum: 0.5208\n",
      "[Epoch 29/300] Batch 0 | G Loss: 0.9415 | D Loss: 1.1852 | LR: 0.045363 | Momentum: 0.5216\n",
      "[Epoch 29/300] Batch 100 | G Loss: 0.9564 | D Loss: 1.1334 | LR: 0.045345 | Momentum: 0.5216\n",
      "[Epoch 29/300] Batch 200 | G Loss: 1.0307 | D Loss: 1.0926 | LR: 0.045327 | Momentum: 0.5216\n",
      "[Epoch 29/300] Batch 300 | G Loss: 0.9899 | D Loss: 1.1357 | LR: 0.045309 | Momentum: 0.5216\n",
      "[Epoch 29/300] Batch 400 | G Loss: 0.9893 | D Loss: 1.0678 | LR: 0.045290 | Momentum: 0.5216\n",
      "[Epoch 29/300] Batch 500 | G Loss: 1.0625 | D Loss: 1.2066 | LR: 0.045272 | Momentum: 0.5216\n",
      "[Epoch 29/300] Batch 600 | G Loss: 1.0343 | D Loss: 1.1875 | LR: 0.045254 | Momentum: 0.5216\n",
      "[Epoch 29/300] Batch 700 | G Loss: 0.9798 | D Loss: 1.1546 | LR: 0.045236 | Momentum: 0.5216\n",
      "[Epoch 29/300] Batch 800 | G Loss: 0.9853 | D Loss: 1.0760 | LR: 0.045218 | Momentum: 0.5216\n",
      "[Epoch 30/300] Batch 0 | G Loss: 1.0078 | D Loss: 1.1766 | LR: 0.045206 | Momentum: 0.5224\n",
      "[Epoch 30/300] Batch 100 | G Loss: 1.0142 | D Loss: 1.2465 | LR: 0.045187 | Momentum: 0.5224\n",
      "[Epoch 30/300] Batch 200 | G Loss: 0.9618 | D Loss: 1.1272 | LR: 0.045169 | Momentum: 0.5224\n",
      "[Epoch 30/300] Batch 300 | G Loss: 1.0394 | D Loss: 1.0978 | LR: 0.045151 | Momentum: 0.5224\n",
      "[Epoch 30/300] Batch 400 | G Loss: 1.0343 | D Loss: 1.1790 | LR: 0.045133 | Momentum: 0.5224\n",
      "[Epoch 30/300] Batch 500 | G Loss: 0.9435 | D Loss: 1.1643 | LR: 0.045115 | Momentum: 0.5224\n",
      "[Epoch 30/300] Batch 600 | G Loss: 1.0667 | D Loss: 1.1706 | LR: 0.045097 | Momentum: 0.5224\n",
      "[Epoch 30/300] Batch 700 | G Loss: 1.0401 | D Loss: 1.1694 | LR: 0.045079 | Momentum: 0.5224\n",
      "[Epoch 30/300] Batch 800 | G Loss: 1.0894 | D Loss: 1.1856 | LR: 0.045061 | Momentum: 0.5224\n",
      "[Epoch 31/300] Batch 0 | G Loss: 0.9282 | D Loss: 1.1340 | LR: 0.045049 | Momentum: 0.5232\n",
      "[Epoch 31/300] Batch 100 | G Loss: 1.0109 | D Loss: 1.1346 | LR: 0.045031 | Momentum: 0.5232\n",
      "[Epoch 31/300] Batch 200 | G Loss: 0.9605 | D Loss: 1.0905 | LR: 0.045013 | Momentum: 0.5232\n",
      "[Epoch 31/300] Batch 300 | G Loss: 0.8917 | D Loss: 1.0276 | LR: 0.044995 | Momentum: 0.5232\n",
      "[Epoch 31/300] Batch 400 | G Loss: 0.9682 | D Loss: 1.2536 | LR: 0.044977 | Momentum: 0.5232\n",
      "[Epoch 31/300] Batch 500 | G Loss: 0.9405 | D Loss: 1.1519 | LR: 0.044959 | Momentum: 0.5232\n",
      "[Epoch 31/300] Batch 600 | G Loss: 1.0519 | D Loss: 1.2378 | LR: 0.044941 | Momentum: 0.5232\n",
      "[Epoch 31/300] Batch 700 | G Loss: 1.0127 | D Loss: 1.2262 | LR: 0.044923 | Momentum: 0.5232\n",
      "[Epoch 31/300] Batch 800 | G Loss: 1.0616 | D Loss: 1.0712 | LR: 0.044905 | Momentum: 0.5232\n",
      "[Epoch 32/300] Batch 0 | G Loss: 1.0029 | D Loss: 1.0948 | LR: 0.044892 | Momentum: 0.5240\n",
      "[Epoch 32/300] Batch 100 | G Loss: 1.1187 | D Loss: 1.1013 | LR: 0.044874 | Momentum: 0.5240\n",
      "[Epoch 32/300] Batch 200 | G Loss: 0.8979 | D Loss: 1.1931 | LR: 0.044856 | Momentum: 0.5240\n",
      "[Epoch 32/300] Batch 300 | G Loss: 1.0021 | D Loss: 1.1774 | LR: 0.044839 | Momentum: 0.5240\n",
      "[Epoch 32/300] Batch 400 | G Loss: 0.9148 | D Loss: 1.1766 | LR: 0.044821 | Momentum: 0.5240\n",
      "[Epoch 32/300] Batch 500 | G Loss: 0.9123 | D Loss: 1.0951 | LR: 0.044803 | Momentum: 0.5240\n",
      "[Epoch 32/300] Batch 600 | G Loss: 0.9298 | D Loss: 1.1627 | LR: 0.044785 | Momentum: 0.5240\n",
      "[Epoch 32/300] Batch 700 | G Loss: 0.9482 | D Loss: 1.2183 | LR: 0.044767 | Momentum: 0.5240\n",
      "[Epoch 32/300] Batch 800 | G Loss: 1.0397 | D Loss: 1.2032 | LR: 0.044749 | Momentum: 0.5240\n",
      "[Epoch 33/300] Batch 0 | G Loss: 0.9239 | D Loss: 1.1704 | LR: 0.044737 | Momentum: 0.5248\n",
      "[Epoch 33/300] Batch 100 | G Loss: 1.0423 | D Loss: 1.1370 | LR: 0.044719 | Momentum: 0.5248\n",
      "[Epoch 33/300] Batch 200 | G Loss: 1.0486 | D Loss: 1.1265 | LR: 0.044701 | Momentum: 0.5248\n",
      "[Epoch 33/300] Batch 300 | G Loss: 0.9708 | D Loss: 1.0859 | LR: 0.044683 | Momentum: 0.5248\n",
      "[Epoch 33/300] Batch 400 | G Loss: 0.9363 | D Loss: 1.1568 | LR: 0.044665 | Momentum: 0.5248\n",
      "[Epoch 33/300] Batch 500 | G Loss: 0.9805 | D Loss: 1.1166 | LR: 0.044647 | Momentum: 0.5248\n",
      "[Epoch 33/300] Batch 600 | G Loss: 0.9141 | D Loss: 1.0641 | LR: 0.044629 | Momentum: 0.5248\n",
      "[Epoch 33/300] Batch 700 | G Loss: 0.9993 | D Loss: 1.0672 | LR: 0.044611 | Momentum: 0.5248\n",
      "[Epoch 33/300] Batch 800 | G Loss: 0.9419 | D Loss: 1.0431 | LR: 0.044594 | Momentum: 0.5248\n",
      "[Epoch 34/300] Batch 0 | G Loss: 0.9778 | D Loss: 1.0831 | LR: 0.044581 | Momentum: 0.5256\n",
      "[Epoch 34/300] Batch 100 | G Loss: 1.0745 | D Loss: 1.1863 | LR: 0.044564 | Momentum: 0.5256\n",
      "[Epoch 34/300] Batch 200 | G Loss: 1.0083 | D Loss: 1.0830 | LR: 0.044546 | Momentum: 0.5256\n",
      "[Epoch 34/300] Batch 300 | G Loss: 1.0527 | D Loss: 1.2958 | LR: 0.044528 | Momentum: 0.5256\n",
      "[Epoch 34/300] Batch 400 | G Loss: 0.9934 | D Loss: 1.1347 | LR: 0.044510 | Momentum: 0.5256\n",
      "[Epoch 34/300] Batch 500 | G Loss: 1.0808 | D Loss: 1.1571 | LR: 0.044492 | Momentum: 0.5256\n",
      "[Epoch 34/300] Batch 600 | G Loss: 0.9753 | D Loss: 1.1024 | LR: 0.044474 | Momentum: 0.5256\n",
      "[Epoch 34/300] Batch 700 | G Loss: 0.9611 | D Loss: 1.1919 | LR: 0.044457 | Momentum: 0.5256\n",
      "[Epoch 34/300] Batch 800 | G Loss: 1.0186 | D Loss: 1.2804 | LR: 0.044439 | Momentum: 0.5256\n",
      "[Epoch 35/300] Batch 0 | G Loss: 1.0500 | D Loss: 1.1205 | LR: 0.044427 | Momentum: 0.5264\n",
      "[Epoch 35/300] Batch 100 | G Loss: 0.8433 | D Loss: 1.1972 | LR: 0.044409 | Momentum: 0.5264\n",
      "[Epoch 35/300] Batch 200 | G Loss: 0.9301 | D Loss: 1.2122 | LR: 0.044391 | Momentum: 0.5264\n",
      "[Epoch 35/300] Batch 300 | G Loss: 1.0454 | D Loss: 1.1998 | LR: 0.044373 | Momentum: 0.5264\n",
      "[Epoch 35/300] Batch 400 | G Loss: 0.9910 | D Loss: 1.2882 | LR: 0.044356 | Momentum: 0.5264\n",
      "[Epoch 35/300] Batch 500 | G Loss: 1.0279 | D Loss: 1.1627 | LR: 0.044338 | Momentum: 0.5264\n",
      "[Epoch 35/300] Batch 600 | G Loss: 0.9324 | D Loss: 1.1034 | LR: 0.044320 | Momentum: 0.5264\n",
      "[Epoch 35/300] Batch 700 | G Loss: 0.9100 | D Loss: 1.1352 | LR: 0.044302 | Momentum: 0.5264\n",
      "[Epoch 35/300] Batch 800 | G Loss: 1.0092 | D Loss: 1.2579 | LR: 0.044285 | Momentum: 0.5264\n",
      "[Epoch 36/300] Batch 0 | G Loss: 1.0517 | D Loss: 1.1494 | LR: 0.044272 | Momentum: 0.5272\n",
      "[Epoch 36/300] Batch 100 | G Loss: 0.9544 | D Loss: 1.2045 | LR: 0.044255 | Momentum: 0.5272\n",
      "[Epoch 36/300] Batch 200 | G Loss: 0.9482 | D Loss: 1.1412 | LR: 0.044237 | Momentum: 0.5272\n",
      "[Epoch 36/300] Batch 300 | G Loss: 1.0264 | D Loss: 1.1747 | LR: 0.044219 | Momentum: 0.5272\n",
      "[Epoch 36/300] Batch 400 | G Loss: 1.0194 | D Loss: 1.2127 | LR: 0.044202 | Momentum: 0.5272\n",
      "[Epoch 36/300] Batch 500 | G Loss: 1.0314 | D Loss: 1.1974 | LR: 0.044184 | Momentum: 0.5272\n",
      "[Epoch 36/300] Batch 600 | G Loss: 0.9470 | D Loss: 1.2137 | LR: 0.044166 | Momentum: 0.5272\n",
      "[Epoch 36/300] Batch 700 | G Loss: 1.0173 | D Loss: 1.1900 | LR: 0.044149 | Momentum: 0.5272\n",
      "[Epoch 36/300] Batch 800 | G Loss: 0.9411 | D Loss: 1.2261 | LR: 0.044131 | Momentum: 0.5272\n",
      "[Epoch 37/300] Batch 0 | G Loss: 0.9475 | D Loss: 1.1406 | LR: 0.044119 | Momentum: 0.5280\n",
      "[Epoch 37/300] Batch 100 | G Loss: 0.9839 | D Loss: 1.1918 | LR: 0.044101 | Momentum: 0.5280\n",
      "[Epoch 37/300] Batch 200 | G Loss: 0.9447 | D Loss: 1.1182 | LR: 0.044084 | Momentum: 0.5280\n",
      "[Epoch 37/300] Batch 300 | G Loss: 0.9579 | D Loss: 1.1987 | LR: 0.044066 | Momentum: 0.5280\n",
      "[Epoch 37/300] Batch 400 | G Loss: 1.0341 | D Loss: 1.2515 | LR: 0.044048 | Momentum: 0.5280\n",
      "[Epoch 37/300] Batch 500 | G Loss: 0.9700 | D Loss: 1.2586 | LR: 0.044031 | Momentum: 0.5280\n",
      "[Epoch 37/300] Batch 600 | G Loss: 0.9492 | D Loss: 1.2369 | LR: 0.044013 | Momentum: 0.5280\n",
      "[Epoch 37/300] Batch 700 | G Loss: 0.9988 | D Loss: 1.2431 | LR: 0.043995 | Momentum: 0.5280\n",
      "[Epoch 37/300] Batch 800 | G Loss: 1.0041 | D Loss: 1.0700 | LR: 0.043978 | Momentum: 0.5280\n",
      "[Epoch 38/300] Batch 0 | G Loss: 0.9297 | D Loss: 1.1248 | LR: 0.043966 | Momentum: 0.5288\n",
      "[Epoch 38/300] Batch 100 | G Loss: 1.0053 | D Loss: 1.1935 | LR: 0.043948 | Momentum: 0.5288\n",
      "[Epoch 38/300] Batch 200 | G Loss: 0.9924 | D Loss: 1.1427 | LR: 0.043931 | Momentum: 0.5288\n",
      "[Epoch 38/300] Batch 300 | G Loss: 0.9695 | D Loss: 1.1784 | LR: 0.043913 | Momentum: 0.5288\n",
      "[Epoch 38/300] Batch 400 | G Loss: 1.0885 | D Loss: 1.1757 | LR: 0.043895 | Momentum: 0.5288\n",
      "[Epoch 38/300] Batch 500 | G Loss: 0.9111 | D Loss: 1.1601 | LR: 0.043878 | Momentum: 0.5288\n",
      "[Epoch 38/300] Batch 600 | G Loss: 0.9595 | D Loss: 1.2398 | LR: 0.043860 | Momentum: 0.5288\n",
      "[Epoch 38/300] Batch 700 | G Loss: 0.9463 | D Loss: 1.1412 | LR: 0.043843 | Momentum: 0.5288\n",
      "[Epoch 38/300] Batch 800 | G Loss: 0.9167 | D Loss: 1.1769 | LR: 0.043825 | Momentum: 0.5288\n",
      "[Epoch 39/300] Batch 0 | G Loss: 0.9385 | D Loss: 1.0796 | LR: 0.043813 | Momentum: 0.5296\n",
      "[Epoch 39/300] Batch 100 | G Loss: 0.8958 | D Loss: 1.1507 | LR: 0.043796 | Momentum: 0.5296\n",
      "[Epoch 39/300] Batch 200 | G Loss: 1.1218 | D Loss: 1.1997 | LR: 0.043778 | Momentum: 0.5296\n",
      "[Epoch 39/300] Batch 300 | G Loss: 0.9607 | D Loss: 1.1013 | LR: 0.043761 | Momentum: 0.5296\n",
      "[Epoch 39/300] Batch 400 | G Loss: 0.8665 | D Loss: 1.1903 | LR: 0.043743 | Momentum: 0.5296\n",
      "[Epoch 39/300] Batch 500 | G Loss: 0.9715 | D Loss: 1.1196 | LR: 0.043726 | Momentum: 0.5296\n",
      "[Epoch 39/300] Batch 600 | G Loss: 0.9728 | D Loss: 1.1045 | LR: 0.043708 | Momentum: 0.5296\n",
      "[Epoch 39/300] Batch 700 | G Loss: 0.9720 | D Loss: 1.3212 | LR: 0.043691 | Momentum: 0.5296\n",
      "[Epoch 39/300] Batch 800 | G Loss: 0.9730 | D Loss: 1.1307 | LR: 0.043673 | Momentum: 0.5296\n",
      "[Epoch 40/300] Batch 0 | G Loss: 1.0265 | D Loss: 1.1505 | LR: 0.043661 | Momentum: 0.5304\n",
      "[Epoch 40/300] Batch 100 | G Loss: 0.9270 | D Loss: 1.1261 | LR: 0.043644 | Momentum: 0.5304\n",
      "[Epoch 40/300] Batch 200 | G Loss: 1.0682 | D Loss: 1.1213 | LR: 0.043626 | Momentum: 0.5304\n",
      "[Epoch 40/300] Batch 300 | G Loss: 0.9409 | D Loss: 1.2126 | LR: 0.043609 | Momentum: 0.5304\n",
      "[Epoch 40/300] Batch 400 | G Loss: 1.0053 | D Loss: 1.2006 | LR: 0.043591 | Momentum: 0.5304\n",
      "[Epoch 40/300] Batch 500 | G Loss: 0.9575 | D Loss: 1.1354 | LR: 0.043574 | Momentum: 0.5304\n",
      "[Epoch 40/300] Batch 600 | G Loss: 0.9967 | D Loss: 1.1656 | LR: 0.043557 | Momentum: 0.5304\n",
      "[Epoch 40/300] Batch 700 | G Loss: 0.9548 | D Loss: 1.1700 | LR: 0.043539 | Momentum: 0.5304\n",
      "[Epoch 40/300] Batch 800 | G Loss: 0.8850 | D Loss: 1.1679 | LR: 0.043522 | Momentum: 0.5304\n",
      "[Epoch 41/300] Batch 0 | G Loss: 1.0141 | D Loss: 1.0236 | LR: 0.043510 | Momentum: 0.5312\n",
      "[Epoch 41/300] Batch 100 | G Loss: 1.0407 | D Loss: 1.1326 | LR: 0.043492 | Momentum: 0.5312\n",
      "[Epoch 41/300] Batch 200 | G Loss: 1.2151 | D Loss: 1.2426 | LR: 0.043475 | Momentum: 0.5312\n",
      "[Epoch 41/300] Batch 300 | G Loss: 0.9628 | D Loss: 1.2441 | LR: 0.043457 | Momentum: 0.5312\n",
      "[Epoch 41/300] Batch 400 | G Loss: 0.9368 | D Loss: 1.1492 | LR: 0.043440 | Momentum: 0.5312\n",
      "[Epoch 41/300] Batch 500 | G Loss: 0.9932 | D Loss: 1.2368 | LR: 0.043423 | Momentum: 0.5312\n",
      "[Epoch 41/300] Batch 600 | G Loss: 1.0318 | D Loss: 1.2105 | LR: 0.043405 | Momentum: 0.5312\n",
      "[Epoch 41/300] Batch 700 | G Loss: 0.9959 | D Loss: 1.2420 | LR: 0.043388 | Momentum: 0.5312\n",
      "[Epoch 41/300] Batch 800 | G Loss: 1.0458 | D Loss: 1.2137 | LR: 0.043371 | Momentum: 0.5312\n",
      "[Epoch 42/300] Batch 0 | G Loss: 0.9281 | D Loss: 1.1261 | LR: 0.043359 | Momentum: 0.5320\n",
      "[Epoch 42/300] Batch 100 | G Loss: 0.9051 | D Loss: 1.2281 | LR: 0.043341 | Momentum: 0.5320\n",
      "[Epoch 42/300] Batch 200 | G Loss: 1.1035 | D Loss: 1.1127 | LR: 0.043324 | Momentum: 0.5320\n",
      "[Epoch 42/300] Batch 300 | G Loss: 0.9009 | D Loss: 1.1561 | LR: 0.043307 | Momentum: 0.5320\n",
      "[Epoch 42/300] Batch 400 | G Loss: 0.8549 | D Loss: 1.2271 | LR: 0.043289 | Momentum: 0.5320\n",
      "[Epoch 42/300] Batch 500 | G Loss: 1.0411 | D Loss: 1.1941 | LR: 0.043272 | Momentum: 0.5320\n",
      "[Epoch 42/300] Batch 600 | G Loss: 0.9837 | D Loss: 1.1823 | LR: 0.043255 | Momentum: 0.5320\n",
      "[Epoch 42/300] Batch 700 | G Loss: 0.8597 | D Loss: 1.1908 | LR: 0.043237 | Momentum: 0.5320\n",
      "[Epoch 42/300] Batch 800 | G Loss: 0.8930 | D Loss: 1.1563 | LR: 0.043220 | Momentum: 0.5320\n",
      "[Epoch 43/300] Batch 0 | G Loss: 0.9694 | D Loss: 1.1822 | LR: 0.043208 | Momentum: 0.5328\n",
      "[Epoch 43/300] Batch 100 | G Loss: 0.9790 | D Loss: 1.1858 | LR: 0.043191 | Momentum: 0.5328\n",
      "[Epoch 43/300] Batch 200 | G Loss: 1.0550 | D Loss: 1.2321 | LR: 0.043174 | Momentum: 0.5328\n",
      "[Epoch 43/300] Batch 300 | G Loss: 0.9600 | D Loss: 1.1298 | LR: 0.043156 | Momentum: 0.5328\n",
      "[Epoch 43/300] Batch 400 | G Loss: 0.9389 | D Loss: 1.1223 | LR: 0.043139 | Momentum: 0.5328\n",
      "[Epoch 43/300] Batch 500 | G Loss: 1.0909 | D Loss: 1.3037 | LR: 0.043122 | Momentum: 0.5328\n",
      "[Epoch 43/300] Batch 600 | G Loss: 0.9578 | D Loss: 1.1738 | LR: 0.043105 | Momentum: 0.5328\n",
      "[Epoch 43/300] Batch 700 | G Loss: 0.9971 | D Loss: 1.1768 | LR: 0.043087 | Momentum: 0.5328\n",
      "[Epoch 43/300] Batch 800 | G Loss: 0.9960 | D Loss: 1.2789 | LR: 0.043070 | Momentum: 0.5328\n",
      "[Epoch 44/300] Batch 0 | G Loss: 1.0141 | D Loss: 1.2427 | LR: 0.043058 | Momentum: 0.5336\n",
      "[Epoch 44/300] Batch 100 | G Loss: 1.0135 | D Loss: 1.2830 | LR: 0.043041 | Momentum: 0.5336\n",
      "[Epoch 44/300] Batch 200 | G Loss: 0.8804 | D Loss: 1.1435 | LR: 0.043024 | Momentum: 0.5336\n",
      "[Epoch 44/300] Batch 300 | G Loss: 0.9697 | D Loss: 1.1067 | LR: 0.043007 | Momentum: 0.5336\n",
      "[Epoch 44/300] Batch 400 | G Loss: 1.0219 | D Loss: 1.2398 | LR: 0.042989 | Momentum: 0.5336\n",
      "[Epoch 44/300] Batch 500 | G Loss: 1.0209 | D Loss: 1.1818 | LR: 0.042972 | Momentum: 0.5336\n",
      "[Epoch 44/300] Batch 600 | G Loss: 0.8740 | D Loss: 1.1972 | LR: 0.042955 | Momentum: 0.5336\n",
      "[Epoch 44/300] Batch 700 | G Loss: 1.0790 | D Loss: 1.2063 | LR: 0.042938 | Momentum: 0.5336\n",
      "[Epoch 44/300] Batch 800 | G Loss: 0.9765 | D Loss: 1.0978 | LR: 0.042921 | Momentum: 0.5336\n",
      "[Epoch 45/300] Batch 0 | G Loss: 1.0472 | D Loss: 1.1751 | LR: 0.042909 | Momentum: 0.5344\n",
      "[Epoch 45/300] Batch 100 | G Loss: 0.9218 | D Loss: 1.1557 | LR: 0.042892 | Momentum: 0.5344\n",
      "[Epoch 45/300] Batch 200 | G Loss: 1.1096 | D Loss: 1.1903 | LR: 0.042875 | Momentum: 0.5344\n",
      "[Epoch 45/300] Batch 300 | G Loss: 0.8983 | D Loss: 1.1277 | LR: 0.042857 | Momentum: 0.5344\n",
      "[Epoch 45/300] Batch 400 | G Loss: 1.0080 | D Loss: 1.1678 | LR: 0.042840 | Momentum: 0.5344\n",
      "[Epoch 45/300] Batch 500 | G Loss: 0.9004 | D Loss: 1.2058 | LR: 0.042823 | Momentum: 0.5344\n",
      "[Epoch 45/300] Batch 600 | G Loss: 1.0695 | D Loss: 1.0730 | LR: 0.042806 | Momentum: 0.5344\n",
      "[Epoch 45/300] Batch 700 | G Loss: 1.0005 | D Loss: 1.0892 | LR: 0.042789 | Momentum: 0.5344\n",
      "[Epoch 45/300] Batch 800 | G Loss: 0.9446 | D Loss: 1.2124 | LR: 0.042772 | Momentum: 0.5344\n",
      "[Epoch 46/300] Batch 0 | G Loss: 1.0805 | D Loss: 1.1220 | LR: 0.042760 | Momentum: 0.5352\n",
      "[Epoch 46/300] Batch 100 | G Loss: 1.0353 | D Loss: 1.2586 | LR: 0.042743 | Momentum: 0.5352\n",
      "[Epoch 46/300] Batch 200 | G Loss: 1.0088 | D Loss: 1.1730 | LR: 0.042726 | Momentum: 0.5352\n",
      "[Epoch 46/300] Batch 300 | G Loss: 0.9565 | D Loss: 1.2342 | LR: 0.042709 | Momentum: 0.5352\n",
      "[Epoch 46/300] Batch 400 | G Loss: 0.9569 | D Loss: 1.2472 | LR: 0.042692 | Momentum: 0.5352\n",
      "[Epoch 46/300] Batch 500 | G Loss: 0.9151 | D Loss: 1.1554 | LR: 0.042675 | Momentum: 0.5352\n",
      "[Epoch 46/300] Batch 600 | G Loss: 0.9693 | D Loss: 1.2237 | LR: 0.042658 | Momentum: 0.5352\n",
      "[Epoch 46/300] Batch 700 | G Loss: 0.9386 | D Loss: 1.1481 | LR: 0.042640 | Momentum: 0.5352\n",
      "[Epoch 46/300] Batch 800 | G Loss: 1.0218 | D Loss: 1.1865 | LR: 0.042623 | Momentum: 0.5352\n",
      "[Epoch 47/300] Batch 0 | G Loss: 0.9491 | D Loss: 1.2488 | LR: 0.042612 | Momentum: 0.5360\n",
      "[Epoch 47/300] Batch 100 | G Loss: 0.8762 | D Loss: 1.2037 | LR: 0.042595 | Momentum: 0.5360\n",
      "[Epoch 47/300] Batch 200 | G Loss: 1.0221 | D Loss: 1.2871 | LR: 0.042578 | Momentum: 0.5360\n",
      "[Epoch 47/300] Batch 300 | G Loss: 0.8928 | D Loss: 1.1413 | LR: 0.042561 | Momentum: 0.5360\n",
      "[Epoch 47/300] Batch 400 | G Loss: 0.9576 | D Loss: 1.1910 | LR: 0.042544 | Momentum: 0.5360\n",
      "[Epoch 47/300] Batch 500 | G Loss: 0.9512 | D Loss: 1.1819 | LR: 0.042526 | Momentum: 0.5360\n",
      "[Epoch 47/300] Batch 600 | G Loss: 0.9651 | D Loss: 1.1681 | LR: 0.042509 | Momentum: 0.5360\n",
      "[Epoch 47/300] Batch 700 | G Loss: 0.9727 | D Loss: 1.1861 | LR: 0.042492 | Momentum: 0.5360\n",
      "[Epoch 47/300] Batch 800 | G Loss: 0.9934 | D Loss: 1.2168 | LR: 0.042475 | Momentum: 0.5360\n",
      "[Epoch 48/300] Batch 0 | G Loss: 0.9603 | D Loss: 1.1610 | LR: 0.042464 | Momentum: 0.5368\n",
      "[Epoch 48/300] Batch 100 | G Loss: 0.9495 | D Loss: 1.2040 | LR: 0.042447 | Momentum: 0.5368\n",
      "[Epoch 48/300] Batch 200 | G Loss: 0.8867 | D Loss: 1.3525 | LR: 0.042430 | Momentum: 0.5368\n",
      "[Epoch 48/300] Batch 300 | G Loss: 1.0161 | D Loss: 1.2156 | LR: 0.042413 | Momentum: 0.5368\n",
      "[Epoch 48/300] Batch 400 | G Loss: 0.9316 | D Loss: 1.1491 | LR: 0.042396 | Momentum: 0.5368\n",
      "[Epoch 48/300] Batch 500 | G Loss: 0.9489 | D Loss: 1.1923 | LR: 0.042379 | Momentum: 0.5368\n",
      "[Epoch 48/300] Batch 600 | G Loss: 1.0366 | D Loss: 1.1410 | LR: 0.042362 | Momentum: 0.5368\n",
      "[Epoch 48/300] Batch 700 | G Loss: 0.9989 | D Loss: 1.1365 | LR: 0.042345 | Momentum: 0.5368\n",
      "[Epoch 48/300] Batch 800 | G Loss: 1.0059 | D Loss: 1.0899 | LR: 0.042328 | Momentum: 0.5368\n",
      "[Epoch 49/300] Batch 0 | G Loss: 0.8654 | D Loss: 1.1961 | LR: 0.042316 | Momentum: 0.5376\n",
      "[Epoch 49/300] Batch 100 | G Loss: 0.9558 | D Loss: 1.2243 | LR: 0.042300 | Momentum: 0.5376\n",
      "[Epoch 49/300] Batch 200 | G Loss: 0.9294 | D Loss: 1.2140 | LR: 0.042283 | Momentum: 0.5376\n",
      "[Epoch 49/300] Batch 300 | G Loss: 1.0034 | D Loss: 1.1079 | LR: 0.042266 | Momentum: 0.5376\n",
      "[Epoch 49/300] Batch 400 | G Loss: 1.0760 | D Loss: 1.1588 | LR: 0.042249 | Momentum: 0.5376\n",
      "[Epoch 49/300] Batch 500 | G Loss: 0.8824 | D Loss: 1.1256 | LR: 0.042232 | Momentum: 0.5376\n",
      "[Epoch 49/300] Batch 600 | G Loss: 0.8813 | D Loss: 1.2315 | LR: 0.042215 | Momentum: 0.5376\n",
      "[Epoch 49/300] Batch 700 | G Loss: 1.0826 | D Loss: 1.1146 | LR: 0.042198 | Momentum: 0.5376\n",
      "[Epoch 49/300] Batch 800 | G Loss: 1.0053 | D Loss: 1.3866 | LR: 0.042181 | Momentum: 0.5376\n",
      "[Epoch 50/300] Batch 0 | G Loss: 1.0191 | D Loss: 1.1095 | LR: 0.042170 | Momentum: 0.5384\n",
      "[Epoch 50/300] Batch 100 | G Loss: 0.9890 | D Loss: 1.1099 | LR: 0.042153 | Momentum: 0.5384\n",
      "[Epoch 50/300] Batch 200 | G Loss: 0.9226 | D Loss: 1.1859 | LR: 0.042136 | Momentum: 0.5384\n",
      "[Epoch 50/300] Batch 300 | G Loss: 0.9292 | D Loss: 1.2022 | LR: 0.042119 | Momentum: 0.5384\n",
      "[Epoch 50/300] Batch 400 | G Loss: 0.9119 | D Loss: 1.1983 | LR: 0.042102 | Momentum: 0.5384\n",
      "[Epoch 50/300] Batch 500 | G Loss: 1.0205 | D Loss: 1.2947 | LR: 0.042085 | Momentum: 0.5384\n",
      "[Epoch 50/300] Batch 600 | G Loss: 0.9351 | D Loss: 1.2019 | LR: 0.042069 | Momentum: 0.5384\n",
      "[Epoch 50/300] Batch 700 | G Loss: 1.0081 | D Loss: 1.1631 | LR: 0.042052 | Momentum: 0.5384\n",
      "[Epoch 50/300] Batch 800 | G Loss: 0.9109 | D Loss: 1.2433 | LR: 0.042035 | Momentum: 0.5384\n",
      "[Epoch 51/300] Batch 0 | G Loss: 0.9755 | D Loss: 1.1690 | LR: 0.042023 | Momentum: 0.5392\n",
      "[Epoch 51/300] Batch 100 | G Loss: 0.9934 | D Loss: 1.1692 | LR: 0.042006 | Momentum: 0.5392\n",
      "[Epoch 51/300] Batch 200 | G Loss: 1.0132 | D Loss: 1.1627 | LR: 0.041990 | Momentum: 0.5392\n",
      "[Epoch 51/300] Batch 300 | G Loss: 0.9420 | D Loss: 1.1130 | LR: 0.041973 | Momentum: 0.5392\n",
      "[Epoch 51/300] Batch 400 | G Loss: 0.9610 | D Loss: 1.1980 | LR: 0.041956 | Momentum: 0.5392\n",
      "[Epoch 51/300] Batch 500 | G Loss: 0.9215 | D Loss: 1.1942 | LR: 0.041939 | Momentum: 0.5392\n",
      "[Epoch 51/300] Batch 600 | G Loss: 0.8514 | D Loss: 1.1940 | LR: 0.041923 | Momentum: 0.5392\n",
      "[Epoch 51/300] Batch 700 | G Loss: 0.9332 | D Loss: 1.2238 | LR: 0.041906 | Momentum: 0.5392\n",
      "[Epoch 51/300] Batch 800 | G Loss: 1.0740 | D Loss: 1.2345 | LR: 0.041889 | Momentum: 0.5392\n",
      "[Epoch 52/300] Batch 0 | G Loss: 0.9526 | D Loss: 1.2182 | LR: 0.041877 | Momentum: 0.5400\n",
      "[Epoch 52/300] Batch 100 | G Loss: 0.9058 | D Loss: 1.1660 | LR: 0.041861 | Momentum: 0.5400\n",
      "[Epoch 52/300] Batch 200 | G Loss: 0.8951 | D Loss: 1.1310 | LR: 0.041844 | Momentum: 0.5400\n",
      "[Epoch 52/300] Batch 300 | G Loss: 0.8980 | D Loss: 1.1067 | LR: 0.041827 | Momentum: 0.5400\n",
      "[Epoch 52/300] Batch 400 | G Loss: 0.9694 | D Loss: 1.2707 | LR: 0.041810 | Momentum: 0.5400\n",
      "[Epoch 52/300] Batch 500 | G Loss: 0.9317 | D Loss: 1.2271 | LR: 0.041794 | Momentum: 0.5400\n",
      "[Epoch 52/300] Batch 600 | G Loss: 1.0062 | D Loss: 1.1668 | LR: 0.041777 | Momentum: 0.5400\n",
      "[Epoch 52/300] Batch 700 | G Loss: 0.9368 | D Loss: 1.2537 | LR: 0.041760 | Momentum: 0.5400\n",
      "[Epoch 52/300] Batch 800 | G Loss: 1.1487 | D Loss: 1.1495 | LR: 0.041744 | Momentum: 0.5400\n",
      "[Epoch 53/300] Batch 0 | G Loss: 1.0466 | D Loss: 1.1647 | LR: 0.041732 | Momentum: 0.5408\n",
      "[Epoch 53/300] Batch 100 | G Loss: 0.9999 | D Loss: 1.2743 | LR: 0.041715 | Momentum: 0.5408\n",
      "[Epoch 53/300] Batch 200 | G Loss: 0.9985 | D Loss: 1.1083 | LR: 0.041699 | Momentum: 0.5408\n",
      "[Epoch 53/300] Batch 300 | G Loss: 0.9590 | D Loss: 1.2429 | LR: 0.041682 | Momentum: 0.5408\n",
      "[Epoch 53/300] Batch 400 | G Loss: 0.9270 | D Loss: 1.1950 | LR: 0.041665 | Momentum: 0.5408\n",
      "[Epoch 53/300] Batch 500 | G Loss: 0.9678 | D Loss: 1.2927 | LR: 0.041649 | Momentum: 0.5408\n",
      "[Epoch 53/300] Batch 600 | G Loss: 0.9202 | D Loss: 1.1943 | LR: 0.041632 | Momentum: 0.5408\n",
      "[Epoch 53/300] Batch 700 | G Loss: 0.9827 | D Loss: 1.2048 | LR: 0.041615 | Momentum: 0.5408\n",
      "[Epoch 53/300] Batch 800 | G Loss: 0.8920 | D Loss: 1.1892 | LR: 0.041599 | Momentum: 0.5408\n",
      "[Epoch 54/300] Batch 0 | G Loss: 0.9189 | D Loss: 1.1920 | LR: 0.041587 | Momentum: 0.5416\n",
      "[Epoch 54/300] Batch 100 | G Loss: 1.1539 | D Loss: 1.1453 | LR: 0.041571 | Momentum: 0.5416\n",
      "[Epoch 54/300] Batch 200 | G Loss: 0.9417 | D Loss: 1.1822 | LR: 0.041554 | Momentum: 0.5416\n",
      "[Epoch 54/300] Batch 300 | G Loss: 0.9730 | D Loss: 1.2720 | LR: 0.041537 | Momentum: 0.5416\n",
      "[Epoch 54/300] Batch 400 | G Loss: 0.9282 | D Loss: 1.1785 | LR: 0.041521 | Momentum: 0.5416\n",
      "[Epoch 54/300] Batch 500 | G Loss: 1.0047 | D Loss: 1.1016 | LR: 0.041504 | Momentum: 0.5416\n",
      "[Epoch 54/300] Batch 600 | G Loss: 1.0315 | D Loss: 1.3296 | LR: 0.041488 | Momentum: 0.5416\n",
      "[Epoch 54/300] Batch 700 | G Loss: 0.9331 | D Loss: 1.1947 | LR: 0.041471 | Momentum: 0.5416\n",
      "[Epoch 54/300] Batch 800 | G Loss: 0.9062 | D Loss: 1.0822 | LR: 0.041454 | Momentum: 0.5416\n",
      "[Epoch 55/300] Batch 0 | G Loss: 0.9280 | D Loss: 1.1768 | LR: 0.041443 | Momentum: 0.5424\n",
      "[Epoch 55/300] Batch 100 | G Loss: 1.0042 | D Loss: 1.1705 | LR: 0.041426 | Momentum: 0.5424\n",
      "[Epoch 55/300] Batch 200 | G Loss: 0.9417 | D Loss: 1.2187 | LR: 0.041410 | Momentum: 0.5424\n",
      "[Epoch 55/300] Batch 300 | G Loss: 0.9988 | D Loss: 1.1183 | LR: 0.041393 | Momentum: 0.5424\n",
      "[Epoch 55/300] Batch 400 | G Loss: 0.9593 | D Loss: 1.2513 | LR: 0.041377 | Momentum: 0.5424\n",
      "[Epoch 55/300] Batch 500 | G Loss: 1.0005 | D Loss: 1.2675 | LR: 0.041360 | Momentum: 0.5424\n",
      "[Epoch 55/300] Batch 600 | G Loss: 1.0515 | D Loss: 1.1383 | LR: 0.041344 | Momentum: 0.5424\n",
      "[Epoch 55/300] Batch 700 | G Loss: 1.0524 | D Loss: 1.1462 | LR: 0.041327 | Momentum: 0.5424\n",
      "[Epoch 55/300] Batch 800 | G Loss: 0.9021 | D Loss: 1.1525 | LR: 0.041311 | Momentum: 0.5424\n",
      "[Epoch 56/300] Batch 0 | G Loss: 0.8687 | D Loss: 1.1684 | LR: 0.041299 | Momentum: 0.5432\n",
      "[Epoch 56/300] Batch 100 | G Loss: 0.9006 | D Loss: 1.1721 | LR: 0.041283 | Momentum: 0.5432\n",
      "[Epoch 56/300] Batch 200 | G Loss: 0.9134 | D Loss: 1.1382 | LR: 0.041266 | Momentum: 0.5432\n",
      "[Epoch 56/300] Batch 300 | G Loss: 0.9588 | D Loss: 1.1469 | LR: 0.041250 | Momentum: 0.5432\n",
      "[Epoch 56/300] Batch 400 | G Loss: 0.9197 | D Loss: 1.1993 | LR: 0.041233 | Momentum: 0.5432\n",
      "[Epoch 56/300] Batch 500 | G Loss: 0.9681 | D Loss: 1.0921 | LR: 0.041217 | Momentum: 0.5432\n",
      "[Epoch 56/300] Batch 600 | G Loss: 0.9474 | D Loss: 1.0664 | LR: 0.041200 | Momentum: 0.5432\n",
      "[Epoch 56/300] Batch 700 | G Loss: 1.0969 | D Loss: 1.1083 | LR: 0.041184 | Momentum: 0.5432\n",
      "[Epoch 56/300] Batch 800 | G Loss: 0.9458 | D Loss: 1.1068 | LR: 0.041167 | Momentum: 0.5432\n",
      "[Epoch 57/300] Batch 0 | G Loss: 0.8939 | D Loss: 1.2964 | LR: 0.041156 | Momentum: 0.5440\n",
      "[Epoch 57/300] Batch 100 | G Loss: 1.0232 | D Loss: 1.1935 | LR: 0.041139 | Momentum: 0.5440\n",
      "[Epoch 57/300] Batch 200 | G Loss: 0.9662 | D Loss: 1.2333 | LR: 0.041123 | Momentum: 0.5440\n",
      "[Epoch 57/300] Batch 300 | G Loss: 0.9092 | D Loss: 1.1273 | LR: 0.041107 | Momentum: 0.5440\n",
      "[Epoch 57/300] Batch 400 | G Loss: 1.0066 | D Loss: 1.1785 | LR: 0.041090 | Momentum: 0.5440\n",
      "[Epoch 57/300] Batch 500 | G Loss: 1.0103 | D Loss: 1.1012 | LR: 0.041074 | Momentum: 0.5440\n",
      "[Epoch 57/300] Batch 600 | G Loss: 0.9282 | D Loss: 1.2154 | LR: 0.041057 | Momentum: 0.5440\n",
      "[Epoch 57/300] Batch 700 | G Loss: 1.0108 | D Loss: 1.1230 | LR: 0.041041 | Momentum: 0.5440\n",
      "[Epoch 57/300] Batch 800 | G Loss: 0.8792 | D Loss: 1.2664 | LR: 0.041024 | Momentum: 0.5440\n",
      "[Epoch 58/300] Batch 0 | G Loss: 0.9713 | D Loss: 1.0981 | LR: 0.041013 | Momentum: 0.5448\n",
      "[Epoch 58/300] Batch 100 | G Loss: 0.9273 | D Loss: 1.2087 | LR: 0.040997 | Momentum: 0.5448\n",
      "[Epoch 58/300] Batch 200 | G Loss: 1.0256 | D Loss: 1.0781 | LR: 0.040980 | Momentum: 0.5448\n",
      "[Epoch 58/300] Batch 300 | G Loss: 0.9544 | D Loss: 1.2709 | LR: 0.040964 | Momentum: 0.5448\n",
      "[Epoch 58/300] Batch 400 | G Loss: 0.9073 | D Loss: 1.1790 | LR: 0.040948 | Momentum: 0.5448\n",
      "[Epoch 58/300] Batch 500 | G Loss: 0.9906 | D Loss: 1.2074 | LR: 0.040931 | Momentum: 0.5448\n",
      "[Epoch 58/300] Batch 600 | G Loss: 0.9962 | D Loss: 1.2223 | LR: 0.040915 | Momentum: 0.5448\n",
      "[Epoch 58/300] Batch 700 | G Loss: 0.9833 | D Loss: 1.1819 | LR: 0.040898 | Momentum: 0.5448\n",
      "[Epoch 58/300] Batch 800 | G Loss: 0.9492 | D Loss: 1.2239 | LR: 0.040882 | Momentum: 0.5448\n",
      "[Epoch 59/300] Batch 0 | G Loss: 0.9057 | D Loss: 1.1784 | LR: 0.040871 | Momentum: 0.5456\n",
      "[Epoch 59/300] Batch 100 | G Loss: 0.9876 | D Loss: 1.2322 | LR: 0.040854 | Momentum: 0.5456\n",
      "[Epoch 59/300] Batch 200 | G Loss: 0.9626 | D Loss: 1.1682 | LR: 0.040838 | Momentum: 0.5456\n",
      "[Epoch 59/300] Batch 300 | G Loss: 0.9370 | D Loss: 1.1426 | LR: 0.040822 | Momentum: 0.5456\n",
      "[Epoch 59/300] Batch 400 | G Loss: 0.9093 | D Loss: 1.2568 | LR: 0.040805 | Momentum: 0.5456\n",
      "[Epoch 59/300] Batch 500 | G Loss: 0.9685 | D Loss: 1.0877 | LR: 0.040789 | Momentum: 0.5456\n",
      "[Epoch 59/300] Batch 600 | G Loss: 0.9129 | D Loss: 1.1885 | LR: 0.040773 | Momentum: 0.5456\n",
      "[Epoch 59/300] Batch 700 | G Loss: 1.0365 | D Loss: 1.1674 | LR: 0.040757 | Momentum: 0.5456\n",
      "[Epoch 59/300] Batch 800 | G Loss: 0.9788 | D Loss: 1.2349 | LR: 0.040740 | Momentum: 0.5456\n",
      "[Epoch 60/300] Batch 0 | G Loss: 0.9848 | D Loss: 1.1854 | LR: 0.040729 | Momentum: 0.5464\n",
      "[Epoch 60/300] Batch 100 | G Loss: 1.0170 | D Loss: 1.2413 | LR: 0.040713 | Momentum: 0.5464\n",
      "[Epoch 60/300] Batch 200 | G Loss: 0.9780 | D Loss: 1.2329 | LR: 0.040696 | Momentum: 0.5464\n",
      "[Epoch 60/300] Batch 300 | G Loss: 0.8982 | D Loss: 1.1073 | LR: 0.040680 | Momentum: 0.5464\n",
      "[Epoch 60/300] Batch 400 | G Loss: 0.9609 | D Loss: 1.1667 | LR: 0.040664 | Momentum: 0.5464\n",
      "[Epoch 60/300] Batch 500 | G Loss: 0.9448 | D Loss: 1.1760 | LR: 0.040648 | Momentum: 0.5464\n",
      "[Epoch 60/300] Batch 600 | G Loss: 0.9476 | D Loss: 1.2796 | LR: 0.040631 | Momentum: 0.5464\n",
      "[Epoch 60/300] Batch 700 | G Loss: 0.9304 | D Loss: 1.1972 | LR: 0.040615 | Momentum: 0.5464\n",
      "[Epoch 60/300] Batch 800 | G Loss: 0.9160 | D Loss: 1.1337 | LR: 0.040599 | Momentum: 0.5464\n",
      "[Epoch 61/300] Batch 0 | G Loss: 1.0434 | D Loss: 1.1850 | LR: 0.040588 | Momentum: 0.5472\n",
      "[Epoch 61/300] Batch 100 | G Loss: 1.0074 | D Loss: 1.1391 | LR: 0.040571 | Momentum: 0.5472\n",
      "[Epoch 61/300] Batch 200 | G Loss: 1.0702 | D Loss: 1.1143 | LR: 0.040555 | Momentum: 0.5472\n",
      "[Epoch 61/300] Batch 300 | G Loss: 0.9081 | D Loss: 1.1793 | LR: 0.040539 | Momentum: 0.5472\n",
      "[Epoch 61/300] Batch 400 | G Loss: 0.9783 | D Loss: 1.1118 | LR: 0.040523 | Momentum: 0.5472\n",
      "[Epoch 61/300] Batch 500 | G Loss: 0.9971 | D Loss: 1.1583 | LR: 0.040507 | Momentum: 0.5472\n",
      "[Epoch 61/300] Batch 600 | G Loss: 0.9257 | D Loss: 1.1409 | LR: 0.040490 | Momentum: 0.5472\n",
      "[Epoch 61/300] Batch 700 | G Loss: 0.9798 | D Loss: 1.2233 | LR: 0.040474 | Momentum: 0.5472\n",
      "[Epoch 61/300] Batch 800 | G Loss: 0.9155 | D Loss: 1.1339 | LR: 0.040458 | Momentum: 0.5472\n",
      "[Epoch 62/300] Batch 0 | G Loss: 0.9615 | D Loss: 1.2899 | LR: 0.040447 | Momentum: 0.5480\n",
      "[Epoch 62/300] Batch 100 | G Loss: 0.9514 | D Loss: 1.0856 | LR: 0.040431 | Momentum: 0.5480\n",
      "[Epoch 62/300] Batch 200 | G Loss: 0.9872 | D Loss: 1.1499 | LR: 0.040414 | Momentum: 0.5480\n",
      "[Epoch 62/300] Batch 300 | G Loss: 0.9407 | D Loss: 1.1738 | LR: 0.040398 | Momentum: 0.5480\n",
      "[Epoch 62/300] Batch 400 | G Loss: 0.8985 | D Loss: 1.1394 | LR: 0.040382 | Momentum: 0.5480\n",
      "[Epoch 62/300] Batch 500 | G Loss: 0.8728 | D Loss: 1.2293 | LR: 0.040366 | Momentum: 0.5480\n",
      "[Epoch 62/300] Batch 600 | G Loss: 0.9980 | D Loss: 1.2850 | LR: 0.040350 | Momentum: 0.5480\n",
      "[Epoch 62/300] Batch 700 | G Loss: 1.0025 | D Loss: 1.0903 | LR: 0.040334 | Momentum: 0.5480\n",
      "[Epoch 62/300] Batch 800 | G Loss: 0.9271 | D Loss: 1.2246 | LR: 0.040318 | Momentum: 0.5480\n",
      "[Epoch 63/300] Batch 0 | G Loss: 0.8977 | D Loss: 1.1959 | LR: 0.040306 | Momentum: 0.5488\n",
      "[Epoch 63/300] Batch 100 | G Loss: 0.9599 | D Loss: 1.1261 | LR: 0.040290 | Momentum: 0.5488\n",
      "[Epoch 63/300] Batch 200 | G Loss: 0.9103 | D Loss: 1.2172 | LR: 0.040274 | Momentum: 0.5488\n",
      "[Epoch 63/300] Batch 300 | G Loss: 0.9268 | D Loss: 1.2298 | LR: 0.040258 | Momentum: 0.5488\n",
      "[Epoch 63/300] Batch 400 | G Loss: 0.9827 | D Loss: 1.2142 | LR: 0.040242 | Momentum: 0.5488\n",
      "[Epoch 63/300] Batch 500 | G Loss: 0.9702 | D Loss: 1.2631 | LR: 0.040226 | Momentum: 0.5488\n",
      "[Epoch 63/300] Batch 600 | G Loss: 0.9720 | D Loss: 1.1850 | LR: 0.040210 | Momentum: 0.5488\n",
      "[Epoch 63/300] Batch 700 | G Loss: 1.0209 | D Loss: 1.1256 | LR: 0.040194 | Momentum: 0.5488\n",
      "[Epoch 63/300] Batch 800 | G Loss: 0.8936 | D Loss: 1.2320 | LR: 0.040178 | Momentum: 0.5488\n",
      "[Epoch 64/300] Batch 0 | G Loss: 0.9028 | D Loss: 1.2640 | LR: 0.040167 | Momentum: 0.5496\n",
      "[Epoch 64/300] Batch 100 | G Loss: 0.9529 | D Loss: 1.2002 | LR: 0.040151 | Momentum: 0.5496\n",
      "[Epoch 64/300] Batch 200 | G Loss: 0.8699 | D Loss: 1.1693 | LR: 0.040134 | Momentum: 0.5496\n",
      "[Epoch 64/300] Batch 300 | G Loss: 0.9033 | D Loss: 1.3451 | LR: 0.040118 | Momentum: 0.5496\n",
      "[Epoch 64/300] Batch 400 | G Loss: 1.0803 | D Loss: 1.1594 | LR: 0.040102 | Momentum: 0.5496\n",
      "[Epoch 64/300] Batch 500 | G Loss: 0.9269 | D Loss: 1.0923 | LR: 0.040086 | Momentum: 0.5496\n",
      "[Epoch 64/300] Batch 600 | G Loss: 0.8948 | D Loss: 1.1550 | LR: 0.040070 | Momentum: 0.5496\n",
      "[Epoch 64/300] Batch 700 | G Loss: 0.9516 | D Loss: 1.1753 | LR: 0.040054 | Momentum: 0.5496\n",
      "[Epoch 64/300] Batch 800 | G Loss: 1.0793 | D Loss: 1.1871 | LR: 0.040038 | Momentum: 0.5496\n",
      "[Epoch 65/300] Batch 0 | G Loss: 0.9215 | D Loss: 1.1299 | LR: 0.040027 | Momentum: 0.5504\n",
      "[Epoch 65/300] Batch 100 | G Loss: 0.9963 | D Loss: 1.1637 | LR: 0.040011 | Momentum: 0.5504\n",
      "[Epoch 65/300] Batch 200 | G Loss: 0.9150 | D Loss: 1.1756 | LR: 0.039995 | Momentum: 0.5504\n",
      "[Epoch 65/300] Batch 300 | G Loss: 0.9066 | D Loss: 1.1555 | LR: 0.039979 | Momentum: 0.5504\n",
      "[Epoch 65/300] Batch 400 | G Loss: 0.9024 | D Loss: 1.0857 | LR: 0.039963 | Momentum: 0.5504\n",
      "[Epoch 65/300] Batch 500 | G Loss: 0.9394 | D Loss: 1.1917 | LR: 0.039947 | Momentum: 0.5504\n",
      "[Epoch 65/300] Batch 600 | G Loss: 0.9303 | D Loss: 1.1561 | LR: 0.039931 | Momentum: 0.5504\n",
      "[Epoch 65/300] Batch 700 | G Loss: 0.9757 | D Loss: 1.1712 | LR: 0.039915 | Momentum: 0.5504\n",
      "[Epoch 65/300] Batch 800 | G Loss: 0.9342 | D Loss: 1.1287 | LR: 0.039899 | Momentum: 0.5504\n",
      "[Epoch 66/300] Batch 0 | G Loss: 0.8865 | D Loss: 1.2742 | LR: 0.039888 | Momentum: 0.5512\n",
      "[Epoch 66/300] Batch 100 | G Loss: 0.9937 | D Loss: 1.0987 | LR: 0.039872 | Momentum: 0.5512\n",
      "[Epoch 66/300] Batch 200 | G Loss: 0.9241 | D Loss: 1.1988 | LR: 0.039856 | Momentum: 0.5512\n",
      "[Epoch 66/300] Batch 300 | G Loss: 1.0294 | D Loss: 1.1577 | LR: 0.039840 | Momentum: 0.5512\n",
      "[Epoch 66/300] Batch 400 | G Loss: 0.9912 | D Loss: 1.1327 | LR: 0.039825 | Momentum: 0.5512\n",
      "[Epoch 66/300] Batch 500 | G Loss: 0.9543 | D Loss: 1.1922 | LR: 0.039809 | Momentum: 0.5512\n",
      "[Epoch 66/300] Batch 600 | G Loss: 0.8919 | D Loss: 1.1717 | LR: 0.039793 | Momentum: 0.5512\n",
      "[Epoch 66/300] Batch 700 | G Loss: 0.9415 | D Loss: 1.2146 | LR: 0.039777 | Momentum: 0.5512\n",
      "[Epoch 66/300] Batch 800 | G Loss: 0.9982 | D Loss: 1.0490 | LR: 0.039761 | Momentum: 0.5512\n",
      "[Epoch 67/300] Batch 0 | G Loss: 1.0232 | D Loss: 1.2122 | LR: 0.039750 | Momentum: 0.5520\n",
      "[Epoch 67/300] Batch 100 | G Loss: 0.9594 | D Loss: 1.2083 | LR: 0.039734 | Momentum: 0.5520\n",
      "[Epoch 67/300] Batch 200 | G Loss: 1.0327 | D Loss: 1.0807 | LR: 0.039718 | Momentum: 0.5520\n",
      "[Epoch 67/300] Batch 300 | G Loss: 0.9281 | D Loss: 1.1629 | LR: 0.039702 | Momentum: 0.5520\n",
      "[Epoch 67/300] Batch 400 | G Loss: 0.9779 | D Loss: 1.1332 | LR: 0.039686 | Momentum: 0.5520\n",
      "[Epoch 67/300] Batch 500 | G Loss: 0.9685 | D Loss: 1.2798 | LR: 0.039670 | Momentum: 0.5520\n",
      "[Epoch 67/300] Batch 600 | G Loss: 1.0522 | D Loss: 1.1945 | LR: 0.039655 | Momentum: 0.5520\n",
      "[Epoch 67/300] Batch 700 | G Loss: 1.0405 | D Loss: 1.2920 | LR: 0.039639 | Momentum: 0.5520\n",
      "[Epoch 67/300] Batch 800 | G Loss: 0.9114 | D Loss: 1.2845 | LR: 0.039623 | Momentum: 0.5520\n",
      "[Epoch 68/300] Batch 0 | G Loss: 0.9153 | D Loss: 1.1875 | LR: 0.039612 | Momentum: 0.5528\n",
      "[Epoch 68/300] Batch 100 | G Loss: 1.0063 | D Loss: 1.1151 | LR: 0.039596 | Momentum: 0.5528\n",
      "[Epoch 68/300] Batch 200 | G Loss: 0.9006 | D Loss: 1.1151 | LR: 0.039580 | Momentum: 0.5528\n",
      "[Epoch 68/300] Batch 300 | G Loss: 1.0006 | D Loss: 1.2572 | LR: 0.039564 | Momentum: 0.5528\n",
      "[Epoch 68/300] Batch 400 | G Loss: 0.9509 | D Loss: 1.1642 | LR: 0.039549 | Momentum: 0.5528\n",
      "[Epoch 68/300] Batch 500 | G Loss: 1.0761 | D Loss: 1.0655 | LR: 0.039533 | Momentum: 0.5528\n",
      "[Epoch 68/300] Batch 600 | G Loss: 0.8633 | D Loss: 1.1982 | LR: 0.039517 | Momentum: 0.5528\n",
      "[Epoch 68/300] Batch 700 | G Loss: 0.8877 | D Loss: 1.1212 | LR: 0.039501 | Momentum: 0.5528\n",
      "[Epoch 68/300] Batch 800 | G Loss: 0.9386 | D Loss: 1.1719 | LR: 0.039485 | Momentum: 0.5528\n",
      "[Epoch 69/300] Batch 0 | G Loss: 0.9892 | D Loss: 1.1921 | LR: 0.039475 | Momentum: 0.5536\n",
      "[Epoch 69/300] Batch 100 | G Loss: 0.9327 | D Loss: 1.1191 | LR: 0.039459 | Momentum: 0.5536\n",
      "[Epoch 69/300] Batch 200 | G Loss: 1.0331 | D Loss: 1.2075 | LR: 0.039443 | Momentum: 0.5536\n",
      "[Epoch 69/300] Batch 300 | G Loss: 1.0153 | D Loss: 1.2097 | LR: 0.039427 | Momentum: 0.5536\n",
      "[Epoch 69/300] Batch 400 | G Loss: 0.9833 | D Loss: 1.2057 | LR: 0.039411 | Momentum: 0.5536\n",
      "[Epoch 69/300] Batch 500 | G Loss: 0.9864 | D Loss: 1.2681 | LR: 0.039396 | Momentum: 0.5536\n",
      "[Epoch 69/300] Batch 600 | G Loss: 0.9047 | D Loss: 1.1896 | LR: 0.039380 | Momentum: 0.5536\n",
      "[Epoch 69/300] Batch 700 | G Loss: 0.9070 | D Loss: 1.2145 | LR: 0.039364 | Momentum: 0.5536\n",
      "[Epoch 69/300] Batch 800 | G Loss: 1.0010 | D Loss: 1.2178 | LR: 0.039348 | Momentum: 0.5536\n",
      "[Epoch 70/300] Batch 0 | G Loss: 1.0098 | D Loss: 1.1164 | LR: 0.039338 | Momentum: 0.5544\n",
      "[Epoch 70/300] Batch 100 | G Loss: 0.9661 | D Loss: 1.1993 | LR: 0.039322 | Momentum: 0.5544\n",
      "[Epoch 70/300] Batch 200 | G Loss: 0.8877 | D Loss: 1.2258 | LR: 0.039306 | Momentum: 0.5544\n",
      "[Epoch 70/300] Batch 300 | G Loss: 0.9913 | D Loss: 1.1800 | LR: 0.039290 | Momentum: 0.5544\n",
      "[Epoch 70/300] Batch 400 | G Loss: 0.9820 | D Loss: 1.1229 | LR: 0.039275 | Momentum: 0.5544\n",
      "[Epoch 70/300] Batch 500 | G Loss: 0.9247 | D Loss: 1.1608 | LR: 0.039259 | Momentum: 0.5544\n",
      "[Epoch 70/300] Batch 600 | G Loss: 1.0064 | D Loss: 1.1479 | LR: 0.039243 | Momentum: 0.5544\n",
      "[Epoch 70/300] Batch 700 | G Loss: 0.9014 | D Loss: 1.1149 | LR: 0.039228 | Momentum: 0.5544\n",
      "[Epoch 70/300] Batch 800 | G Loss: 0.9099 | D Loss: 1.2188 | LR: 0.039212 | Momentum: 0.5544\n",
      "[Epoch 71/300] Batch 0 | G Loss: 0.9070 | D Loss: 1.2554 | LR: 0.039201 | Momentum: 0.5552\n",
      "[Epoch 71/300] Batch 100 | G Loss: 0.8900 | D Loss: 1.2343 | LR: 0.039185 | Momentum: 0.5552\n",
      "[Epoch 71/300] Batch 200 | G Loss: 0.9796 | D Loss: 1.1823 | LR: 0.039170 | Momentum: 0.5552\n",
      "[Epoch 71/300] Batch 300 | G Loss: 0.9254 | D Loss: 1.0851 | LR: 0.039154 | Momentum: 0.5552\n",
      "[Epoch 71/300] Batch 400 | G Loss: 0.9861 | D Loss: 1.1726 | LR: 0.039138 | Momentum: 0.5552\n",
      "[Epoch 71/300] Batch 500 | G Loss: 0.8713 | D Loss: 1.1954 | LR: 0.039123 | Momentum: 0.5552\n",
      "[Epoch 71/300] Batch 600 | G Loss: 0.9102 | D Loss: 1.1366 | LR: 0.039107 | Momentum: 0.5552\n",
      "[Epoch 71/300] Batch 700 | G Loss: 0.9605 | D Loss: 1.1790 | LR: 0.039091 | Momentum: 0.5552\n",
      "[Epoch 71/300] Batch 800 | G Loss: 0.9377 | D Loss: 1.2567 | LR: 0.039076 | Momentum: 0.5552\n",
      "[Epoch 72/300] Batch 0 | G Loss: 0.9531 | D Loss: 1.0560 | LR: 0.039065 | Momentum: 0.5560\n",
      "[Epoch 72/300] Batch 100 | G Loss: 0.8523 | D Loss: 1.1542 | LR: 0.039049 | Momentum: 0.5560\n",
      "[Epoch 72/300] Batch 200 | G Loss: 0.8771 | D Loss: 1.2111 | LR: 0.039034 | Momentum: 0.5560\n",
      "[Epoch 72/300] Batch 300 | G Loss: 0.8826 | D Loss: 1.2918 | LR: 0.039018 | Momentum: 0.5560\n",
      "[Epoch 72/300] Batch 400 | G Loss: 0.9973 | D Loss: 1.1370 | LR: 0.039003 | Momentum: 0.5560\n",
      "[Epoch 72/300] Batch 500 | G Loss: 0.9483 | D Loss: 1.1691 | LR: 0.038987 | Momentum: 0.5560\n",
      "[Epoch 72/300] Batch 600 | G Loss: 0.9435 | D Loss: 1.2969 | LR: 0.038971 | Momentum: 0.5560\n",
      "[Epoch 72/300] Batch 700 | G Loss: 0.9050 | D Loss: 1.2368 | LR: 0.038956 | Momentum: 0.5560\n",
      "[Epoch 72/300] Batch 800 | G Loss: 0.9924 | D Loss: 1.2115 | LR: 0.038940 | Momentum: 0.5560\n",
      "[Epoch 73/300] Batch 0 | G Loss: 1.0163 | D Loss: 1.2450 | LR: 0.038929 | Momentum: 0.5568\n",
      "[Epoch 73/300] Batch 100 | G Loss: 0.9980 | D Loss: 1.0945 | LR: 0.038914 | Momentum: 0.5568\n",
      "[Epoch 73/300] Batch 200 | G Loss: 0.9833 | D Loss: 1.1879 | LR: 0.038898 | Momentum: 0.5568\n",
      "[Epoch 73/300] Batch 300 | G Loss: 0.9633 | D Loss: 1.1363 | LR: 0.038883 | Momentum: 0.5568\n",
      "[Epoch 73/300] Batch 400 | G Loss: 0.9814 | D Loss: 1.1899 | LR: 0.038867 | Momentum: 0.5568\n",
      "[Epoch 73/300] Batch 500 | G Loss: 0.9607 | D Loss: 1.2356 | LR: 0.038852 | Momentum: 0.5568\n",
      "[Epoch 73/300] Batch 600 | G Loss: 0.9646 | D Loss: 1.1708 | LR: 0.038836 | Momentum: 0.5568\n",
      "[Epoch 73/300] Batch 700 | G Loss: 1.0637 | D Loss: 1.2331 | LR: 0.038821 | Momentum: 0.5568\n",
      "[Epoch 73/300] Batch 800 | G Loss: 1.0143 | D Loss: 1.1499 | LR: 0.038805 | Momentum: 0.5568\n",
      "[Epoch 74/300] Batch 0 | G Loss: 0.9258 | D Loss: 1.0937 | LR: 0.038794 | Momentum: 0.5576\n",
      "[Epoch 74/300] Batch 100 | G Loss: 0.9449 | D Loss: 1.0889 | LR: 0.038779 | Momentum: 0.5576\n",
      "[Epoch 74/300] Batch 200 | G Loss: 0.9495 | D Loss: 1.1829 | LR: 0.038763 | Momentum: 0.5576\n",
      "[Epoch 74/300] Batch 300 | G Loss: 1.0087 | D Loss: 1.0685 | LR: 0.038748 | Momentum: 0.5576\n",
      "[Epoch 74/300] Batch 400 | G Loss: 0.9960 | D Loss: 1.1747 | LR: 0.038732 | Momentum: 0.5576\n",
      "[Epoch 74/300] Batch 500 | G Loss: 1.0274 | D Loss: 1.1310 | LR: 0.038717 | Momentum: 0.5576\n",
      "[Epoch 74/300] Batch 600 | G Loss: 0.9717 | D Loss: 1.1659 | LR: 0.038701 | Momentum: 0.5576\n",
      "[Epoch 74/300] Batch 700 | G Loss: 1.0560 | D Loss: 1.1549 | LR: 0.038686 | Momentum: 0.5576\n",
      "[Epoch 74/300] Batch 800 | G Loss: 1.0150 | D Loss: 1.1298 | LR: 0.038670 | Momentum: 0.5576\n",
      "[Epoch 75/300] Batch 0 | G Loss: 0.9095 | D Loss: 1.1827 | LR: 0.038660 | Momentum: 0.5584\n",
      "[Epoch 75/300] Batch 100 | G Loss: 0.9330 | D Loss: 1.0734 | LR: 0.038644 | Momentum: 0.5584\n",
      "[Epoch 75/300] Batch 200 | G Loss: 0.9167 | D Loss: 1.2907 | LR: 0.038629 | Momentum: 0.5584\n",
      "[Epoch 75/300] Batch 300 | G Loss: 0.9750 | D Loss: 1.1181 | LR: 0.038613 | Momentum: 0.5584\n",
      "[Epoch 75/300] Batch 400 | G Loss: 0.9395 | D Loss: 1.2453 | LR: 0.038598 | Momentum: 0.5584\n",
      "[Epoch 75/300] Batch 500 | G Loss: 0.9084 | D Loss: 1.2126 | LR: 0.038583 | Momentum: 0.5584\n",
      "[Epoch 75/300] Batch 600 | G Loss: 0.9773 | D Loss: 1.1454 | LR: 0.038567 | Momentum: 0.5584\n",
      "[Epoch 75/300] Batch 700 | G Loss: 0.9369 | D Loss: 1.2474 | LR: 0.038552 | Momentum: 0.5584\n",
      "[Epoch 75/300] Batch 800 | G Loss: 0.9325 | D Loss: 1.1956 | LR: 0.038536 | Momentum: 0.5584\n",
      "[Epoch 76/300] Batch 0 | G Loss: 1.0576 | D Loss: 1.2085 | LR: 0.038526 | Momentum: 0.5592\n",
      "[Epoch 76/300] Batch 100 | G Loss: 0.9435 | D Loss: 1.1735 | LR: 0.038510 | Momentum: 0.5592\n",
      "[Epoch 76/300] Batch 200 | G Loss: 0.8621 | D Loss: 1.1656 | LR: 0.038495 | Momentum: 0.5592\n",
      "[Epoch 76/300] Batch 300 | G Loss: 0.8778 | D Loss: 1.1666 | LR: 0.038479 | Momentum: 0.5592\n",
      "[Epoch 76/300] Batch 400 | G Loss: 0.8928 | D Loss: 1.2645 | LR: 0.038464 | Momentum: 0.5592\n",
      "[Epoch 76/300] Batch 500 | G Loss: 1.0150 | D Loss: 1.1545 | LR: 0.038449 | Momentum: 0.5592\n",
      "[Epoch 76/300] Batch 600 | G Loss: 0.9589 | D Loss: 1.2495 | LR: 0.038433 | Momentum: 0.5592\n",
      "[Epoch 76/300] Batch 700 | G Loss: 0.9374 | D Loss: 1.1763 | LR: 0.038418 | Momentum: 0.5592\n",
      "[Epoch 76/300] Batch 800 | G Loss: 0.8091 | D Loss: 1.1839 | LR: 0.038403 | Momentum: 0.5592\n",
      "[Epoch 77/300] Batch 0 | G Loss: 1.0802 | D Loss: 1.1668 | LR: 0.038392 | Momentum: 0.5600\n",
      "[Epoch 77/300] Batch 100 | G Loss: 0.8176 | D Loss: 1.0733 | LR: 0.038377 | Momentum: 0.5600\n",
      "[Epoch 77/300] Batch 200 | G Loss: 1.0053 | D Loss: 1.3450 | LR: 0.038361 | Momentum: 0.5600\n",
      "[Epoch 77/300] Batch 300 | G Loss: 0.9227 | D Loss: 1.0917 | LR: 0.038346 | Momentum: 0.5600\n",
      "[Epoch 77/300] Batch 400 | G Loss: 0.9695 | D Loss: 1.1021 | LR: 0.038331 | Momentum: 0.5600\n",
      "[Epoch 77/300] Batch 500 | G Loss: 0.8435 | D Loss: 1.1557 | LR: 0.038315 | Momentum: 0.5600\n",
      "[Epoch 77/300] Batch 600 | G Loss: 0.9356 | D Loss: 1.2358 | LR: 0.038300 | Momentum: 0.5600\n",
      "[Epoch 77/300] Batch 700 | G Loss: 0.9320 | D Loss: 1.2318 | LR: 0.038285 | Momentum: 0.5600\n",
      "[Epoch 77/300] Batch 800 | G Loss: 0.9167 | D Loss: 1.1517 | LR: 0.038269 | Momentum: 0.5600\n",
      "[Epoch 78/300] Batch 0 | G Loss: 0.9330 | D Loss: 1.2151 | LR: 0.038259 | Momentum: 0.5608\n",
      "[Epoch 78/300] Batch 100 | G Loss: 0.9133 | D Loss: 1.1478 | LR: 0.038243 | Momentum: 0.5608\n",
      "[Epoch 78/300] Batch 200 | G Loss: 0.9626 | D Loss: 1.2015 | LR: 0.038228 | Momentum: 0.5608\n",
      "[Epoch 78/300] Batch 300 | G Loss: 0.8836 | D Loss: 1.1940 | LR: 0.038213 | Momentum: 0.5608\n",
      "[Epoch 78/300] Batch 400 | G Loss: 0.9622 | D Loss: 1.1860 | LR: 0.038198 | Momentum: 0.5608\n",
      "[Epoch 78/300] Batch 500 | G Loss: 0.9171 | D Loss: 1.1210 | LR: 0.038182 | Momentum: 0.5608\n",
      "[Epoch 78/300] Batch 600 | G Loss: 0.9246 | D Loss: 1.2188 | LR: 0.038167 | Momentum: 0.5608\n",
      "[Epoch 78/300] Batch 700 | G Loss: 0.9999 | D Loss: 1.2865 | LR: 0.038152 | Momentum: 0.5608\n",
      "[Epoch 78/300] Batch 800 | G Loss: 0.8923 | D Loss: 1.2860 | LR: 0.038136 | Momentum: 0.5608\n",
      "[Epoch 79/300] Batch 0 | G Loss: 0.9635 | D Loss: 1.2343 | LR: 0.038126 | Momentum: 0.5616\n",
      "[Epoch 79/300] Batch 100 | G Loss: 0.9415 | D Loss: 1.2410 | LR: 0.038111 | Momentum: 0.5616\n",
      "[Epoch 79/300] Batch 200 | G Loss: 0.9513 | D Loss: 1.1208 | LR: 0.038095 | Momentum: 0.5616\n",
      "[Epoch 79/300] Batch 300 | G Loss: 0.9001 | D Loss: 1.1060 | LR: 0.038080 | Momentum: 0.5616\n",
      "[Epoch 79/300] Batch 400 | G Loss: 0.9328 | D Loss: 1.2623 | LR: 0.038065 | Momentum: 0.5616\n",
      "[Epoch 79/300] Batch 500 | G Loss: 0.9040 | D Loss: 1.2290 | LR: 0.038050 | Momentum: 0.5616\n",
      "[Epoch 79/300] Batch 600 | G Loss: 0.9316 | D Loss: 1.1836 | LR: 0.038035 | Momentum: 0.5616\n",
      "[Epoch 79/300] Batch 700 | G Loss: 0.9952 | D Loss: 1.2175 | LR: 0.038019 | Momentum: 0.5616\n",
      "[Epoch 79/300] Batch 800 | G Loss: 0.9245 | D Loss: 1.1441 | LR: 0.038004 | Momentum: 0.5616\n",
      "[Epoch 80/300] Batch 0 | G Loss: 0.9020 | D Loss: 1.1526 | LR: 0.037994 | Momentum: 0.5624\n",
      "[Epoch 80/300] Batch 100 | G Loss: 0.9459 | D Loss: 1.3120 | LR: 0.037978 | Momentum: 0.5624\n",
      "[Epoch 80/300] Batch 200 | G Loss: 0.9719 | D Loss: 1.1377 | LR: 0.037963 | Momentum: 0.5624\n",
      "[Epoch 80/300] Batch 300 | G Loss: 0.8556 | D Loss: 1.2229 | LR: 0.037948 | Momentum: 0.5624\n",
      "[Epoch 80/300] Batch 400 | G Loss: 0.9218 | D Loss: 1.1634 | LR: 0.037933 | Momentum: 0.5624\n",
      "[Epoch 80/300] Batch 500 | G Loss: 0.8785 | D Loss: 1.2719 | LR: 0.037918 | Momentum: 0.5624\n",
      "[Epoch 80/300] Batch 600 | G Loss: 0.9787 | D Loss: 1.1602 | LR: 0.037903 | Momentum: 0.5624\n",
      "[Epoch 80/300] Batch 700 | G Loss: 0.9789 | D Loss: 1.2509 | LR: 0.037887 | Momentum: 0.5624\n",
      "[Epoch 80/300] Batch 800 | G Loss: 0.9484 | D Loss: 1.1078 | LR: 0.037872 | Momentum: 0.5624\n",
      "[Epoch 81/300] Batch 0 | G Loss: 0.9791 | D Loss: 1.1839 | LR: 0.037862 | Momentum: 0.5632\n",
      "[Epoch 81/300] Batch 100 | G Loss: 1.1080 | D Loss: 1.1652 | LR: 0.037847 | Momentum: 0.5632\n",
      "[Epoch 81/300] Batch 200 | G Loss: 1.0126 | D Loss: 1.1999 | LR: 0.037832 | Momentum: 0.5632\n",
      "[Epoch 81/300] Batch 300 | G Loss: 0.9906 | D Loss: 1.1389 | LR: 0.037816 | Momentum: 0.5632\n",
      "[Epoch 81/300] Batch 400 | G Loss: 0.9347 | D Loss: 1.3045 | LR: 0.037801 | Momentum: 0.5632\n",
      "[Epoch 81/300] Batch 500 | G Loss: 0.9132 | D Loss: 1.2393 | LR: 0.037786 | Momentum: 0.5632\n",
      "[Epoch 81/300] Batch 600 | G Loss: 1.0120 | D Loss: 1.1620 | LR: 0.037771 | Momentum: 0.5632\n",
      "[Epoch 81/300] Batch 700 | G Loss: 0.9721 | D Loss: 1.1848 | LR: 0.037756 | Momentum: 0.5632\n",
      "[Epoch 81/300] Batch 800 | G Loss: 0.9808 | D Loss: 1.2031 | LR: 0.037741 | Momentum: 0.5632\n",
      "[Epoch 82/300] Batch 0 | G Loss: 0.8412 | D Loss: 1.1685 | LR: 0.037730 | Momentum: 0.5640\n",
      "[Epoch 82/300] Batch 100 | G Loss: 1.0160 | D Loss: 1.1529 | LR: 0.037715 | Momentum: 0.5640\n",
      "[Epoch 82/300] Batch 200 | G Loss: 0.9422 | D Loss: 1.1300 | LR: 0.037700 | Momentum: 0.5640\n",
      "[Epoch 82/300] Batch 300 | G Loss: 0.9317 | D Loss: 1.2806 | LR: 0.037685 | Momentum: 0.5640\n",
      "[Epoch 82/300] Batch 400 | G Loss: 0.9983 | D Loss: 1.1400 | LR: 0.037670 | Momentum: 0.5640\n",
      "[Epoch 82/300] Batch 500 | G Loss: 0.9678 | D Loss: 1.1537 | LR: 0.037655 | Momentum: 0.5640\n",
      "[Epoch 82/300] Batch 600 | G Loss: 0.9799 | D Loss: 1.1910 | LR: 0.037640 | Momentum: 0.5640\n",
      "[Epoch 82/300] Batch 700 | G Loss: 0.9937 | D Loss: 1.1822 | LR: 0.037625 | Momentum: 0.5640\n",
      "[Epoch 82/300] Batch 800 | G Loss: 0.8719 | D Loss: 1.1256 | LR: 0.037610 | Momentum: 0.5640\n",
      "[Epoch 83/300] Batch 0 | G Loss: 0.9330 | D Loss: 1.2187 | LR: 0.037600 | Momentum: 0.5648\n",
      "[Epoch 83/300] Batch 100 | G Loss: 0.9793 | D Loss: 1.1440 | LR: 0.037584 | Momentum: 0.5648\n",
      "[Epoch 83/300] Batch 200 | G Loss: 0.9931 | D Loss: 1.2052 | LR: 0.037569 | Momentum: 0.5648\n",
      "[Epoch 83/300] Batch 300 | G Loss: 0.9514 | D Loss: 1.1205 | LR: 0.037554 | Momentum: 0.5648\n",
      "[Epoch 83/300] Batch 400 | G Loss: 0.9643 | D Loss: 1.2124 | LR: 0.037539 | Momentum: 0.5648\n",
      "[Epoch 83/300] Batch 500 | G Loss: 0.9492 | D Loss: 1.2681 | LR: 0.037524 | Momentum: 0.5648\n",
      "[Epoch 83/300] Batch 600 | G Loss: 0.9062 | D Loss: 1.2048 | LR: 0.037509 | Momentum: 0.5648\n",
      "[Epoch 83/300] Batch 700 | G Loss: 0.9158 | D Loss: 1.1686 | LR: 0.037494 | Momentum: 0.5648\n",
      "[Epoch 83/300] Batch 800 | G Loss: 0.9791 | D Loss: 1.1109 | LR: 0.037479 | Momentum: 0.5648\n",
      "[Epoch 84/300] Batch 0 | G Loss: 0.9233 | D Loss: 1.2581 | LR: 0.037469 | Momentum: 0.5656\n",
      "[Epoch 84/300] Batch 100 | G Loss: 0.9009 | D Loss: 1.2148 | LR: 0.037454 | Momentum: 0.5656\n",
      "[Epoch 84/300] Batch 200 | G Loss: 0.9535 | D Loss: 1.1835 | LR: 0.037439 | Momentum: 0.5656\n",
      "[Epoch 84/300] Batch 300 | G Loss: 0.9429 | D Loss: 1.1086 | LR: 0.037424 | Momentum: 0.5656\n",
      "[Epoch 84/300] Batch 400 | G Loss: 0.9529 | D Loss: 1.2540 | LR: 0.037409 | Momentum: 0.5656\n",
      "[Epoch 84/300] Batch 500 | G Loss: 0.9670 | D Loss: 1.2134 | LR: 0.037394 | Momentum: 0.5656\n",
      "[Epoch 84/300] Batch 600 | G Loss: 0.9741 | D Loss: 1.1184 | LR: 0.037379 | Momentum: 0.5656\n",
      "[Epoch 84/300] Batch 700 | G Loss: 1.0182 | D Loss: 1.0455 | LR: 0.037364 | Momentum: 0.5656\n",
      "[Epoch 84/300] Batch 800 | G Loss: 0.9550 | D Loss: 1.2075 | LR: 0.037349 | Momentum: 0.5656\n",
      "[Epoch 85/300] Batch 0 | G Loss: 0.9306 | D Loss: 1.1365 | LR: 0.037339 | Momentum: 0.5664\n",
      "[Epoch 85/300] Batch 100 | G Loss: 0.9616 | D Loss: 1.1920 | LR: 0.037324 | Momentum: 0.5664\n",
      "[Epoch 85/300] Batch 200 | G Loss: 0.9670 | D Loss: 1.0749 | LR: 0.037309 | Momentum: 0.5664\n",
      "[Epoch 85/300] Batch 300 | G Loss: 0.9225 | D Loss: 1.1838 | LR: 0.037294 | Momentum: 0.5664\n",
      "[Epoch 85/300] Batch 400 | G Loss: 0.9339 | D Loss: 1.1068 | LR: 0.037279 | Momentum: 0.5664\n",
      "[Epoch 85/300] Batch 500 | G Loss: 0.9217 | D Loss: 1.2294 | LR: 0.037264 | Momentum: 0.5664\n",
      "[Epoch 85/300] Batch 600 | G Loss: 1.0348 | D Loss: 1.2142 | LR: 0.037250 | Momentum: 0.5664\n",
      "[Epoch 85/300] Batch 700 | G Loss: 0.8738 | D Loss: 1.2902 | LR: 0.037235 | Momentum: 0.5664\n",
      "[Epoch 85/300] Batch 800 | G Loss: 0.8829 | D Loss: 1.2004 | LR: 0.037220 | Momentum: 0.5664\n",
      "[Epoch 86/300] Batch 0 | G Loss: 0.9666 | D Loss: 1.1454 | LR: 0.037209 | Momentum: 0.5672\n",
      "[Epoch 86/300] Batch 100 | G Loss: 0.9372 | D Loss: 1.1140 | LR: 0.037195 | Momentum: 0.5672\n",
      "[Epoch 86/300] Batch 200 | G Loss: 0.8591 | D Loss: 1.1181 | LR: 0.037180 | Momentum: 0.5672\n",
      "[Epoch 86/300] Batch 300 | G Loss: 0.9286 | D Loss: 1.1986 | LR: 0.037165 | Momentum: 0.5672\n",
      "[Epoch 86/300] Batch 400 | G Loss: 0.9721 | D Loss: 1.1974 | LR: 0.037150 | Momentum: 0.5672\n",
      "[Epoch 86/300] Batch 500 | G Loss: 1.0126 | D Loss: 1.1624 | LR: 0.037135 | Momentum: 0.5672\n",
      "[Epoch 86/300] Batch 600 | G Loss: 0.9700 | D Loss: 1.3003 | LR: 0.037120 | Momentum: 0.5672\n",
      "[Epoch 86/300] Batch 700 | G Loss: 0.9832 | D Loss: 1.1932 | LR: 0.037105 | Momentum: 0.5672\n",
      "[Epoch 86/300] Batch 800 | G Loss: 1.0152 | D Loss: 1.1798 | LR: 0.037091 | Momentum: 0.5672\n",
      "[Epoch 87/300] Batch 0 | G Loss: 1.0620 | D Loss: 1.2107 | LR: 0.037080 | Momentum: 0.5680\n",
      "[Epoch 87/300] Batch 100 | G Loss: 0.9076 | D Loss: 1.1394 | LR: 0.037066 | Momentum: 0.5680\n",
      "[Epoch 87/300] Batch 200 | G Loss: 0.8833 | D Loss: 1.1484 | LR: 0.037051 | Momentum: 0.5680\n",
      "[Epoch 87/300] Batch 300 | G Loss: 0.9960 | D Loss: 1.2520 | LR: 0.037036 | Momentum: 0.5680\n",
      "[Epoch 87/300] Batch 400 | G Loss: 0.8427 | D Loss: 1.2057 | LR: 0.037021 | Momentum: 0.5680\n",
      "[Epoch 87/300] Batch 500 | G Loss: 0.9542 | D Loss: 1.1250 | LR: 0.037006 | Momentum: 0.5680\n",
      "[Epoch 87/300] Batch 600 | G Loss: 1.0125 | D Loss: 1.2547 | LR: 0.036991 | Momentum: 0.5680\n",
      "[Epoch 87/300] Batch 700 | G Loss: 0.9216 | D Loss: 1.1441 | LR: 0.036977 | Momentum: 0.5680\n",
      "[Epoch 87/300] Batch 800 | G Loss: 0.9392 | D Loss: 1.2310 | LR: 0.036962 | Momentum: 0.5680\n",
      "[Epoch 88/300] Batch 0 | G Loss: 0.8831 | D Loss: 1.2062 | LR: 0.036952 | Momentum: 0.5688\n",
      "[Epoch 88/300] Batch 100 | G Loss: 0.9621 | D Loss: 1.2305 | LR: 0.036937 | Momentum: 0.5688\n",
      "[Epoch 88/300] Batch 200 | G Loss: 0.9767 | D Loss: 1.1694 | LR: 0.036922 | Momentum: 0.5688\n",
      "[Epoch 88/300] Batch 300 | G Loss: 0.9513 | D Loss: 1.1184 | LR: 0.036907 | Momentum: 0.5688\n",
      "[Epoch 88/300] Batch 400 | G Loss: 0.9532 | D Loss: 1.0982 | LR: 0.036893 | Momentum: 0.5688\n",
      "[Epoch 88/300] Batch 500 | G Loss: 0.9406 | D Loss: 1.1181 | LR: 0.036878 | Momentum: 0.5688\n",
      "[Epoch 88/300] Batch 600 | G Loss: 0.9012 | D Loss: 1.2474 | LR: 0.036863 | Momentum: 0.5688\n",
      "[Epoch 88/300] Batch 700 | G Loss: 0.9104 | D Loss: 1.2138 | LR: 0.036848 | Momentum: 0.5688\n",
      "[Epoch 88/300] Batch 800 | G Loss: 0.9509 | D Loss: 1.1932 | LR: 0.036834 | Momentum: 0.5688\n",
      "[Epoch 89/300] Batch 0 | G Loss: 0.9104 | D Loss: 1.1295 | LR: 0.036823 | Momentum: 0.5696\n",
      "[Epoch 89/300] Batch 100 | G Loss: 0.9168 | D Loss: 1.1899 | LR: 0.036809 | Momentum: 0.5696\n",
      "[Epoch 89/300] Batch 200 | G Loss: 0.9430 | D Loss: 1.1470 | LR: 0.036794 | Momentum: 0.5696\n",
      "[Epoch 89/300] Batch 300 | G Loss: 0.9295 | D Loss: 1.1395 | LR: 0.036779 | Momentum: 0.5696\n",
      "[Epoch 89/300] Batch 400 | G Loss: 0.8682 | D Loss: 1.1663 | LR: 0.036765 | Momentum: 0.5696\n",
      "[Epoch 89/300] Batch 500 | G Loss: 0.8884 | D Loss: 1.1701 | LR: 0.036750 | Momentum: 0.5696\n",
      "[Epoch 89/300] Batch 600 | G Loss: 0.8227 | D Loss: 1.2750 | LR: 0.036735 | Momentum: 0.5696\n",
      "[Epoch 89/300] Batch 700 | G Loss: 0.9122 | D Loss: 1.1403 | LR: 0.036721 | Momentum: 0.5696\n",
      "[Epoch 89/300] Batch 800 | G Loss: 0.9609 | D Loss: 1.2005 | LR: 0.036706 | Momentum: 0.5696\n",
      "[Epoch 90/300] Batch 0 | G Loss: 0.9382 | D Loss: 1.2171 | LR: 0.036696 | Momentum: 0.5704\n",
      "[Epoch 90/300] Batch 100 | G Loss: 0.9631 | D Loss: 1.1341 | LR: 0.036681 | Momentum: 0.5704\n",
      "[Epoch 90/300] Batch 200 | G Loss: 0.9956 | D Loss: 1.0888 | LR: 0.036666 | Momentum: 0.5704\n",
      "[Epoch 90/300] Batch 300 | G Loss: 0.9840 | D Loss: 1.2718 | LR: 0.036652 | Momentum: 0.5704\n",
      "[Epoch 90/300] Batch 400 | G Loss: 0.8666 | D Loss: 1.2407 | LR: 0.036637 | Momentum: 0.5704\n",
      "[Epoch 90/300] Batch 500 | G Loss: 1.0014 | D Loss: 1.3029 | LR: 0.036622 | Momentum: 0.5704\n",
      "[Epoch 90/300] Batch 600 | G Loss: 0.8971 | D Loss: 1.0434 | LR: 0.036608 | Momentum: 0.5704\n",
      "[Epoch 90/300] Batch 700 | G Loss: 0.9581 | D Loss: 1.1658 | LR: 0.036593 | Momentum: 0.5704\n",
      "[Epoch 90/300] Batch 800 | G Loss: 0.9235 | D Loss: 1.1787 | LR: 0.036578 | Momentum: 0.5704\n",
      "[Epoch 91/300] Batch 0 | G Loss: 1.0456 | D Loss: 1.2143 | LR: 0.036568 | Momentum: 0.5712\n",
      "[Epoch 91/300] Batch 100 | G Loss: 0.9952 | D Loss: 1.2960 | LR: 0.036554 | Momentum: 0.5712\n",
      "[Epoch 91/300] Batch 200 | G Loss: 0.9945 | D Loss: 1.0747 | LR: 0.036539 | Momentum: 0.5712\n",
      "[Epoch 91/300] Batch 300 | G Loss: 0.9751 | D Loss: 1.1603 | LR: 0.036525 | Momentum: 0.5712\n",
      "[Epoch 91/300] Batch 400 | G Loss: 1.0020 | D Loss: 1.1314 | LR: 0.036510 | Momentum: 0.5712\n",
      "[Epoch 91/300] Batch 500 | G Loss: 0.9173 | D Loss: 1.1680 | LR: 0.036495 | Momentum: 0.5712\n",
      "[Epoch 91/300] Batch 600 | G Loss: 0.9767 | D Loss: 1.4000 | LR: 0.036481 | Momentum: 0.5712\n",
      "[Epoch 91/300] Batch 700 | G Loss: 0.8757 | D Loss: 1.1418 | LR: 0.036466 | Momentum: 0.5712\n",
      "[Epoch 91/300] Batch 800 | G Loss: 1.0450 | D Loss: 1.1503 | LR: 0.036452 | Momentum: 0.5712\n",
      "[Epoch 92/300] Batch 0 | G Loss: 0.8691 | D Loss: 1.2951 | LR: 0.036441 | Momentum: 0.5720\n",
      "[Epoch 92/300] Batch 100 | G Loss: 0.9918 | D Loss: 1.2438 | LR: 0.036427 | Momentum: 0.5720\n",
      "[Epoch 92/300] Batch 200 | G Loss: 0.9634 | D Loss: 1.2226 | LR: 0.036412 | Momentum: 0.5720\n",
      "[Epoch 92/300] Batch 300 | G Loss: 0.9635 | D Loss: 1.2436 | LR: 0.036398 | Momentum: 0.5720\n",
      "[Epoch 92/300] Batch 400 | G Loss: 0.9716 | D Loss: 1.3374 | LR: 0.036383 | Momentum: 0.5720\n",
      "[Epoch 92/300] Batch 500 | G Loss: 0.9250 | D Loss: 1.2664 | LR: 0.036369 | Momentum: 0.5720\n",
      "[Epoch 92/300] Batch 600 | G Loss: 0.9089 | D Loss: 1.1651 | LR: 0.036354 | Momentum: 0.5720\n",
      "[Epoch 92/300] Batch 700 | G Loss: 0.9518 | D Loss: 1.2885 | LR: 0.036340 | Momentum: 0.5720\n",
      "[Epoch 92/300] Batch 800 | G Loss: 0.9174 | D Loss: 1.2228 | LR: 0.036325 | Momentum: 0.5720\n",
      "[Epoch 93/300] Batch 0 | G Loss: 0.9414 | D Loss: 1.2337 | LR: 0.036315 | Momentum: 0.5728\n",
      "[Epoch 93/300] Batch 100 | G Loss: 1.0140 | D Loss: 1.1522 | LR: 0.036301 | Momentum: 0.5728\n",
      "[Epoch 93/300] Batch 200 | G Loss: 0.9102 | D Loss: 1.2156 | LR: 0.036286 | Momentum: 0.5728\n",
      "[Epoch 93/300] Batch 300 | G Loss: 1.1302 | D Loss: 1.1569 | LR: 0.036271 | Momentum: 0.5728\n",
      "[Epoch 93/300] Batch 400 | G Loss: 0.9751 | D Loss: 1.1987 | LR: 0.036257 | Momentum: 0.5728\n",
      "[Epoch 93/300] Batch 500 | G Loss: 0.8870 | D Loss: 1.0803 | LR: 0.036242 | Momentum: 0.5728\n",
      "[Epoch 93/300] Batch 600 | G Loss: 0.9866 | D Loss: 1.1633 | LR: 0.036228 | Momentum: 0.5728\n",
      "[Epoch 93/300] Batch 700 | G Loss: 1.0109 | D Loss: 1.1739 | LR: 0.036213 | Momentum: 0.5728\n",
      "[Epoch 93/300] Batch 800 | G Loss: 0.9239 | D Loss: 1.1758 | LR: 0.036199 | Momentum: 0.5728\n",
      "[Epoch 94/300] Batch 0 | G Loss: 0.8424 | D Loss: 1.1756 | LR: 0.036189 | Momentum: 0.5736\n",
      "[Epoch 94/300] Batch 100 | G Loss: 0.9978 | D Loss: 1.3003 | LR: 0.036175 | Momentum: 0.5736\n",
      "[Epoch 94/300] Batch 200 | G Loss: 0.9675 | D Loss: 1.1956 | LR: 0.036160 | Momentum: 0.5736\n",
      "[Epoch 94/300] Batch 300 | G Loss: 0.9667 | D Loss: 1.2167 | LR: 0.036146 | Momentum: 0.5736\n",
      "[Epoch 94/300] Batch 400 | G Loss: 0.8971 | D Loss: 1.2718 | LR: 0.036131 | Momentum: 0.5736\n",
      "[Epoch 94/300] Batch 500 | G Loss: 0.9443 | D Loss: 1.2202 | LR: 0.036117 | Momentum: 0.5736\n",
      "[Epoch 94/300] Batch 600 | G Loss: 0.8780 | D Loss: 1.1799 | LR: 0.036102 | Momentum: 0.5736\n",
      "[Epoch 94/300] Batch 700 | G Loss: 0.8874 | D Loss: 1.1855 | LR: 0.036088 | Momentum: 0.5736\n",
      "[Epoch 94/300] Batch 800 | G Loss: 0.9098 | D Loss: 1.2343 | LR: 0.036073 | Momentum: 0.5736\n",
      "[Epoch 95/300] Batch 0 | G Loss: 0.9507 | D Loss: 1.1898 | LR: 0.036063 | Momentum: 0.5744\n",
      "[Epoch 95/300] Batch 100 | G Loss: 0.9367 | D Loss: 1.1912 | LR: 0.036049 | Momentum: 0.5744\n",
      "[Epoch 95/300] Batch 200 | G Loss: 0.9932 | D Loss: 1.1922 | LR: 0.036035 | Momentum: 0.5744\n",
      "[Epoch 95/300] Batch 300 | G Loss: 0.9374 | D Loss: 1.2755 | LR: 0.036020 | Momentum: 0.5744\n",
      "[Epoch 95/300] Batch 400 | G Loss: 0.9646 | D Loss: 1.2717 | LR: 0.036006 | Momentum: 0.5744\n",
      "[Epoch 95/300] Batch 500 | G Loss: 1.0172 | D Loss: 1.1365 | LR: 0.035991 | Momentum: 0.5744\n",
      "[Epoch 95/300] Batch 600 | G Loss: 0.9184 | D Loss: 1.2500 | LR: 0.035977 | Momentum: 0.5744\n",
      "[Epoch 95/300] Batch 700 | G Loss: 0.9444 | D Loss: 1.1534 | LR: 0.035963 | Momentum: 0.5744\n",
      "[Epoch 95/300] Batch 800 | G Loss: 0.9327 | D Loss: 1.2137 | LR: 0.035948 | Momentum: 0.5744\n",
      "[Epoch 96/300] Batch 0 | G Loss: 0.9174 | D Loss: 1.1446 | LR: 0.035938 | Momentum: 0.5752\n",
      "[Epoch 96/300] Batch 100 | G Loss: 0.9846 | D Loss: 1.1571 | LR: 0.035924 | Momentum: 0.5752\n",
      "[Epoch 96/300] Batch 200 | G Loss: 0.9432 | D Loss: 1.2604 | LR: 0.035910 | Momentum: 0.5752\n",
      "[Epoch 96/300] Batch 300 | G Loss: 0.9366 | D Loss: 1.2129 | LR: 0.035895 | Momentum: 0.5752\n",
      "[Epoch 96/300] Batch 400 | G Loss: 0.9751 | D Loss: 1.2143 | LR: 0.035881 | Momentum: 0.5752\n",
      "[Epoch 96/300] Batch 500 | G Loss: 0.9586 | D Loss: 1.2171 | LR: 0.035866 | Momentum: 0.5752\n",
      "[Epoch 96/300] Batch 600 | G Loss: 0.9471 | D Loss: 1.1229 | LR: 0.035852 | Momentum: 0.5752\n",
      "[Epoch 96/300] Batch 700 | G Loss: 0.9874 | D Loss: 1.1680 | LR: 0.035838 | Momentum: 0.5752\n",
      "[Epoch 96/300] Batch 800 | G Loss: 0.9610 | D Loss: 1.1905 | LR: 0.035823 | Momentum: 0.5752\n",
      "[Epoch 97/300] Batch 0 | G Loss: 0.9274 | D Loss: 1.2157 | LR: 0.035814 | Momentum: 0.5760\n",
      "[Epoch 97/300] Batch 100 | G Loss: 0.9655 | D Loss: 1.2257 | LR: 0.035799 | Momentum: 0.5760\n",
      "[Epoch 97/300] Batch 200 | G Loss: 0.9058 | D Loss: 1.2195 | LR: 0.035785 | Momentum: 0.5760\n",
      "[Epoch 97/300] Batch 300 | G Loss: 0.9038 | D Loss: 1.1166 | LR: 0.035771 | Momentum: 0.5760\n",
      "[Epoch 97/300] Batch 400 | G Loss: 1.0177 | D Loss: 1.0940 | LR: 0.035756 | Momentum: 0.5760\n",
      "[Epoch 97/300] Batch 500 | G Loss: 0.8822 | D Loss: 1.2210 | LR: 0.035742 | Momentum: 0.5760\n",
      "[Epoch 97/300] Batch 600 | G Loss: 0.9586 | D Loss: 1.1981 | LR: 0.035728 | Momentum: 0.5760\n",
      "[Epoch 97/300] Batch 700 | G Loss: 0.9275 | D Loss: 1.2559 | LR: 0.035713 | Momentum: 0.5760\n",
      "[Epoch 97/300] Batch 800 | G Loss: 0.8870 | D Loss: 1.1259 | LR: 0.035699 | Momentum: 0.5760\n",
      "[Epoch 98/300] Batch 0 | G Loss: 0.8892 | D Loss: 1.2768 | LR: 0.035689 | Momentum: 0.5768\n",
      "[Epoch 98/300] Batch 100 | G Loss: 0.9737 | D Loss: 1.2075 | LR: 0.035675 | Momentum: 0.5768\n",
      "[Epoch 98/300] Batch 200 | G Loss: 0.9931 | D Loss: 1.2130 | LR: 0.035661 | Momentum: 0.5768\n",
      "[Epoch 98/300] Batch 300 | G Loss: 0.9303 | D Loss: 1.2019 | LR: 0.035647 | Momentum: 0.5768\n",
      "[Epoch 98/300] Batch 400 | G Loss: 0.8874 | D Loss: 1.1356 | LR: 0.035632 | Momentum: 0.5768\n",
      "[Epoch 98/300] Batch 500 | G Loss: 0.9678 | D Loss: 1.0675 | LR: 0.035618 | Momentum: 0.5768\n",
      "[Epoch 98/300] Batch 600 | G Loss: 0.9077 | D Loss: 1.1457 | LR: 0.035604 | Momentum: 0.5768\n",
      "[Epoch 98/300] Batch 700 | G Loss: 0.9500 | D Loss: 1.1546 | LR: 0.035590 | Momentum: 0.5768\n",
      "[Epoch 98/300] Batch 800 | G Loss: 0.9631 | D Loss: 1.2215 | LR: 0.035575 | Momentum: 0.5768\n",
      "[Epoch 99/300] Batch 0 | G Loss: 0.9578 | D Loss: 1.1057 | LR: 0.035565 | Momentum: 0.5776\n",
      "[Epoch 99/300] Batch 100 | G Loss: 0.9295 | D Loss: 1.1338 | LR: 0.035551 | Momentum: 0.5776\n",
      "[Epoch 99/300] Batch 200 | G Loss: 0.8954 | D Loss: 1.1684 | LR: 0.035537 | Momentum: 0.5776\n",
      "[Epoch 99/300] Batch 300 | G Loss: 0.9910 | D Loss: 1.1563 | LR: 0.035523 | Momentum: 0.5776\n",
      "[Epoch 99/300] Batch 400 | G Loss: 0.9687 | D Loss: 1.1307 | LR: 0.035509 | Momentum: 0.5776\n",
      "[Epoch 99/300] Batch 500 | G Loss: 0.9092 | D Loss: 1.1336 | LR: 0.035494 | Momentum: 0.5776\n",
      "[Epoch 99/300] Batch 600 | G Loss: 0.9248 | D Loss: 1.2127 | LR: 0.035480 | Momentum: 0.5776\n",
      "[Epoch 99/300] Batch 700 | G Loss: 0.9031 | D Loss: 1.2226 | LR: 0.035466 | Momentum: 0.5776\n",
      "[Epoch 99/300] Batch 800 | G Loss: 0.9302 | D Loss: 1.2025 | LR: 0.035452 | Momentum: 0.5776\n",
      "[Epoch 100/300] Batch 0 | G Loss: 0.9188 | D Loss: 1.0860 | LR: 0.035442 | Momentum: 0.5784\n",
      "[Epoch 100/300] Batch 100 | G Loss: 0.9400 | D Loss: 1.2761 | LR: 0.035428 | Momentum: 0.5784\n",
      "[Epoch 100/300] Batch 200 | G Loss: 0.8883 | D Loss: 1.2620 | LR: 0.035414 | Momentum: 0.5784\n",
      "[Epoch 100/300] Batch 300 | G Loss: 0.8932 | D Loss: 1.1741 | LR: 0.035400 | Momentum: 0.5784\n",
      "[Epoch 100/300] Batch 400 | G Loss: 0.8714 | D Loss: 1.2667 | LR: 0.035385 | Momentum: 0.5784\n",
      "[Epoch 100/300] Batch 500 | G Loss: 0.9162 | D Loss: 1.1254 | LR: 0.035371 | Momentum: 0.5784\n",
      "[Epoch 100/300] Batch 600 | G Loss: 0.9290 | D Loss: 1.1199 | LR: 0.035357 | Momentum: 0.5784\n",
      "[Epoch 100/300] Batch 700 | G Loss: 0.9620 | D Loss: 1.2212 | LR: 0.035343 | Momentum: 0.5784\n",
      "[Epoch 100/300] Batch 800 | G Loss: 0.8903 | D Loss: 1.0885 | LR: 0.035329 | Momentum: 0.5784\n",
      "[Epoch 101/300] Batch 0 | G Loss: 0.9835 | D Loss: 1.1222 | LR: 0.035319 | Momentum: 0.5792\n",
      "[Epoch 101/300] Batch 100 | G Loss: 0.9049 | D Loss: 1.1493 | LR: 0.035305 | Momentum: 0.5792\n",
      "[Epoch 101/300] Batch 200 | G Loss: 1.0033 | D Loss: 1.1756 | LR: 0.035291 | Momentum: 0.5792\n",
      "[Epoch 101/300] Batch 300 | G Loss: 0.9158 | D Loss: 1.1834 | LR: 0.035277 | Momentum: 0.5792\n",
      "[Epoch 101/300] Batch 400 | G Loss: 0.9909 | D Loss: 1.2202 | LR: 0.035263 | Momentum: 0.5792\n",
      "[Epoch 101/300] Batch 500 | G Loss: 1.0442 | D Loss: 1.1658 | LR: 0.035249 | Momentum: 0.5792\n",
      "[Epoch 101/300] Batch 600 | G Loss: 0.9620 | D Loss: 1.1554 | LR: 0.035234 | Momentum: 0.5792\n",
      "[Epoch 101/300] Batch 700 | G Loss: 1.0109 | D Loss: 1.1992 | LR: 0.035220 | Momentum: 0.5792\n",
      "[Epoch 101/300] Batch 800 | G Loss: 0.9385 | D Loss: 1.0847 | LR: 0.035206 | Momentum: 0.5792\n",
      "[Epoch 102/300] Batch 0 | G Loss: 0.9905 | D Loss: 1.1513 | LR: 0.035197 | Momentum: 0.5800\n",
      "[Epoch 102/300] Batch 100 | G Loss: 0.9617 | D Loss: 1.1372 | LR: 0.035182 | Momentum: 0.5800\n",
      "[Epoch 102/300] Batch 200 | G Loss: 0.9019 | D Loss: 1.2241 | LR: 0.035168 | Momentum: 0.5800\n",
      "[Epoch 102/300] Batch 300 | G Loss: 0.9436 | D Loss: 1.2336 | LR: 0.035154 | Momentum: 0.5800\n",
      "[Epoch 102/300] Batch 400 | G Loss: 0.8923 | D Loss: 1.1247 | LR: 0.035140 | Momentum: 0.5800\n",
      "[Epoch 102/300] Batch 500 | G Loss: 0.8458 | D Loss: 1.2789 | LR: 0.035126 | Momentum: 0.5800\n",
      "[Epoch 102/300] Batch 600 | G Loss: 0.9210 | D Loss: 1.1153 | LR: 0.035112 | Momentum: 0.5800\n",
      "[Epoch 102/300] Batch 700 | G Loss: 0.9142 | D Loss: 1.1467 | LR: 0.035098 | Momentum: 0.5800\n",
      "[Epoch 102/300] Batch 800 | G Loss: 0.9323 | D Loss: 1.1135 | LR: 0.035084 | Momentum: 0.5800\n",
      "[Epoch 103/300] Batch 0 | G Loss: 0.9131 | D Loss: 1.1622 | LR: 0.035074 | Momentum: 0.5808\n",
      "[Epoch 103/300] Batch 100 | G Loss: 0.9120 | D Loss: 1.1001 | LR: 0.035060 | Momentum: 0.5808\n",
      "[Epoch 103/300] Batch 200 | G Loss: 0.9540 | D Loss: 1.0909 | LR: 0.035046 | Momentum: 0.5808\n",
      "[Epoch 103/300] Batch 300 | G Loss: 0.9153 | D Loss: 1.2149 | LR: 0.035032 | Momentum: 0.5808\n",
      "[Epoch 103/300] Batch 400 | G Loss: 1.0097 | D Loss: 1.1149 | LR: 0.035018 | Momentum: 0.5808\n",
      "[Epoch 103/300] Batch 500 | G Loss: 0.9955 | D Loss: 1.1745 | LR: 0.035004 | Momentum: 0.5808\n",
      "[Epoch 103/300] Batch 600 | G Loss: 0.9844 | D Loss: 1.2927 | LR: 0.034990 | Momentum: 0.5808\n",
      "[Epoch 103/300] Batch 700 | G Loss: 0.9282 | D Loss: 1.2043 | LR: 0.034976 | Momentum: 0.5808\n",
      "[Epoch 103/300] Batch 800 | G Loss: 0.9583 | D Loss: 1.2236 | LR: 0.034962 | Momentum: 0.5808\n",
      "[Epoch 104/300] Batch 0 | G Loss: 0.8913 | D Loss: 1.1838 | LR: 0.034953 | Momentum: 0.5816\n",
      "[Epoch 104/300] Batch 100 | G Loss: 1.0028 | D Loss: 1.2468 | LR: 0.034939 | Momentum: 0.5816\n",
      "[Epoch 104/300] Batch 200 | G Loss: 0.9352 | D Loss: 1.0507 | LR: 0.034925 | Momentum: 0.5816\n",
      "[Epoch 104/300] Batch 300 | G Loss: 0.9627 | D Loss: 1.1823 | LR: 0.034911 | Momentum: 0.5816\n",
      "[Epoch 104/300] Batch 400 | G Loss: 0.9022 | D Loss: 1.2086 | LR: 0.034897 | Momentum: 0.5816\n",
      "[Epoch 104/300] Batch 500 | G Loss: 0.9720 | D Loss: 1.1807 | LR: 0.034883 | Momentum: 0.5816\n",
      "[Epoch 104/300] Batch 600 | G Loss: 0.9136 | D Loss: 1.2252 | LR: 0.034869 | Momentum: 0.5816\n",
      "[Epoch 104/300] Batch 700 | G Loss: 0.9641 | D Loss: 1.1246 | LR: 0.034855 | Momentum: 0.5816\n",
      "[Epoch 104/300] Batch 800 | G Loss: 0.8727 | D Loss: 1.2532 | LR: 0.034841 | Momentum: 0.5816\n",
      "[Epoch 105/300] Batch 0 | G Loss: 0.9404 | D Loss: 1.1457 | LR: 0.034831 | Momentum: 0.5824\n",
      "[Epoch 105/300] Batch 100 | G Loss: 0.9303 | D Loss: 1.1453 | LR: 0.034817 | Momentum: 0.5824\n",
      "[Epoch 105/300] Batch 200 | G Loss: 0.9234 | D Loss: 1.1160 | LR: 0.034804 | Momentum: 0.5824\n",
      "[Epoch 105/300] Batch 300 | G Loss: 0.9486 | D Loss: 1.2034 | LR: 0.034790 | Momentum: 0.5824\n",
      "[Epoch 105/300] Batch 400 | G Loss: 0.9495 | D Loss: 1.1262 | LR: 0.034776 | Momentum: 0.5824\n",
      "[Epoch 105/300] Batch 500 | G Loss: 0.9104 | D Loss: 1.2255 | LR: 0.034762 | Momentum: 0.5824\n",
      "[Epoch 105/300] Batch 600 | G Loss: 0.8803 | D Loss: 1.1754 | LR: 0.034748 | Momentum: 0.5824\n",
      "[Epoch 105/300] Batch 700 | G Loss: 0.9008 | D Loss: 1.1512 | LR: 0.034734 | Momentum: 0.5824\n",
      "[Epoch 105/300] Batch 800 | G Loss: 0.9415 | D Loss: 1.1871 | LR: 0.034720 | Momentum: 0.5824\n",
      "[Epoch 106/300] Batch 0 | G Loss: 0.9286 | D Loss: 1.2359 | LR: 0.034711 | Momentum: 0.5832\n",
      "[Epoch 106/300] Batch 100 | G Loss: 0.9045 | D Loss: 1.0846 | LR: 0.034697 | Momentum: 0.5832\n",
      "[Epoch 106/300] Batch 200 | G Loss: 0.8993 | D Loss: 1.1420 | LR: 0.034683 | Momentum: 0.5832\n",
      "[Epoch 106/300] Batch 300 | G Loss: 0.8719 | D Loss: 1.1377 | LR: 0.034669 | Momentum: 0.5832\n",
      "[Epoch 106/300] Batch 400 | G Loss: 0.9098 | D Loss: 1.2878 | LR: 0.034655 | Momentum: 0.5832\n",
      "[Epoch 106/300] Batch 500 | G Loss: 0.9527 | D Loss: 1.3239 | LR: 0.034641 | Momentum: 0.5832\n",
      "[Epoch 106/300] Batch 600 | G Loss: 0.9144 | D Loss: 1.1821 | LR: 0.034627 | Momentum: 0.5832\n",
      "[Epoch 106/300] Batch 700 | G Loss: 0.9932 | D Loss: 1.1755 | LR: 0.034613 | Momentum: 0.5832\n",
      "[Epoch 106/300] Batch 800 | G Loss: 0.9361 | D Loss: 1.2395 | LR: 0.034600 | Momentum: 0.5832\n",
      "[Epoch 107/300] Batch 0 | G Loss: 0.9307 | D Loss: 1.1388 | LR: 0.034590 | Momentum: 0.5840\n",
      "[Epoch 107/300] Batch 100 | G Loss: 0.9751 | D Loss: 1.1528 | LR: 0.034576 | Momentum: 0.5840\n",
      "[Epoch 107/300] Batch 200 | G Loss: 0.9506 | D Loss: 1.1510 | LR: 0.034562 | Momentum: 0.5840\n",
      "[Epoch 107/300] Batch 300 | G Loss: 0.9470 | D Loss: 1.1458 | LR: 0.034549 | Momentum: 0.5840\n",
      "[Epoch 107/300] Batch 400 | G Loss: 1.0026 | D Loss: 1.2087 | LR: 0.034535 | Momentum: 0.5840\n",
      "[Epoch 107/300] Batch 500 | G Loss: 0.9465 | D Loss: 1.1816 | LR: 0.034521 | Momentum: 0.5840\n",
      "[Epoch 107/300] Batch 600 | G Loss: 0.9708 | D Loss: 1.1747 | LR: 0.034507 | Momentum: 0.5840\n",
      "[Epoch 107/300] Batch 700 | G Loss: 0.9831 | D Loss: 1.1883 | LR: 0.034493 | Momentum: 0.5840\n",
      "[Epoch 107/300] Batch 800 | G Loss: 0.8744 | D Loss: 1.1487 | LR: 0.034480 | Momentum: 0.5840\n",
      "[Epoch 108/300] Batch 0 | G Loss: 0.9279 | D Loss: 1.1813 | LR: 0.034470 | Momentum: 0.5848\n",
      "[Epoch 108/300] Batch 100 | G Loss: 0.9697 | D Loss: 1.2149 | LR: 0.034456 | Momentum: 0.5848\n",
      "[Epoch 108/300] Batch 200 | G Loss: 0.9422 | D Loss: 1.1853 | LR: 0.034443 | Momentum: 0.5848\n",
      "[Epoch 108/300] Batch 300 | G Loss: 0.9294 | D Loss: 1.2565 | LR: 0.034429 | Momentum: 0.5848\n",
      "[Epoch 108/300] Batch 400 | G Loss: 0.9860 | D Loss: 1.1682 | LR: 0.034415 | Momentum: 0.5848\n",
      "[Epoch 108/300] Batch 500 | G Loss: 0.8872 | D Loss: 1.1145 | LR: 0.034401 | Momentum: 0.5848\n",
      "[Epoch 108/300] Batch 600 | G Loss: 0.9565 | D Loss: 1.0987 | LR: 0.034387 | Momentum: 0.5848\n",
      "[Epoch 108/300] Batch 700 | G Loss: 0.9068 | D Loss: 1.2004 | LR: 0.034374 | Momentum: 0.5848\n",
      "[Epoch 108/300] Batch 800 | G Loss: 0.9127 | D Loss: 1.2558 | LR: 0.034360 | Momentum: 0.5848\n",
      "[Epoch 109/300] Batch 0 | G Loss: 0.9090 | D Loss: 1.1287 | LR: 0.034350 | Momentum: 0.5856\n",
      "[Epoch 109/300] Batch 100 | G Loss: 0.9770 | D Loss: 1.0810 | LR: 0.034337 | Momentum: 0.5856\n",
      "[Epoch 109/300] Batch 200 | G Loss: 0.9221 | D Loss: 1.2228 | LR: 0.034323 | Momentum: 0.5856\n",
      "[Epoch 109/300] Batch 300 | G Loss: 0.8784 | D Loss: 1.1842 | LR: 0.034309 | Momentum: 0.5856\n",
      "[Epoch 109/300] Batch 400 | G Loss: 0.9866 | D Loss: 1.1724 | LR: 0.034296 | Momentum: 0.5856\n",
      "[Epoch 109/300] Batch 500 | G Loss: 0.9495 | D Loss: 1.1517 | LR: 0.034282 | Momentum: 0.5856\n",
      "[Epoch 109/300] Batch 600 | G Loss: 0.9309 | D Loss: 1.2442 | LR: 0.034268 | Momentum: 0.5856\n",
      "[Epoch 109/300] Batch 700 | G Loss: 0.9711 | D Loss: 1.1523 | LR: 0.034254 | Momentum: 0.5856\n",
      "[Epoch 109/300] Batch 800 | G Loss: 0.8894 | D Loss: 1.2080 | LR: 0.034241 | Momentum: 0.5856\n",
      "[Epoch 110/300] Batch 0 | G Loss: 1.0142 | D Loss: 1.1781 | LR: 0.034231 | Momentum: 0.5864\n",
      "[Epoch 110/300] Batch 100 | G Loss: 1.0316 | D Loss: 1.2013 | LR: 0.034218 | Momentum: 0.5864\n",
      "[Epoch 110/300] Batch 200 | G Loss: 0.9675 | D Loss: 1.1883 | LR: 0.034204 | Momentum: 0.5864\n",
      "[Epoch 110/300] Batch 300 | G Loss: 0.9443 | D Loss: 1.1344 | LR: 0.034190 | Momentum: 0.5864\n",
      "[Epoch 110/300] Batch 400 | G Loss: 0.9225 | D Loss: 1.1966 | LR: 0.034177 | Momentum: 0.5864\n",
      "[Epoch 110/300] Batch 500 | G Loss: 0.9796 | D Loss: 1.1974 | LR: 0.034163 | Momentum: 0.5864\n",
      "[Epoch 110/300] Batch 600 | G Loss: 0.9676 | D Loss: 1.1183 | LR: 0.034149 | Momentum: 0.5864\n",
      "[Epoch 110/300] Batch 700 | G Loss: 0.9245 | D Loss: 1.1541 | LR: 0.034136 | Momentum: 0.5864\n",
      "[Epoch 110/300] Batch 800 | G Loss: 0.8979 | D Loss: 1.2706 | LR: 0.034122 | Momentum: 0.5864\n",
      "[Epoch 111/300] Batch 0 | G Loss: 0.9465 | D Loss: 1.2796 | LR: 0.034112 | Momentum: 0.5872\n",
      "[Epoch 111/300] Batch 100 | G Loss: 1.0046 | D Loss: 1.1474 | LR: 0.034099 | Momentum: 0.5872\n",
      "[Epoch 111/300] Batch 200 | G Loss: 0.9327 | D Loss: 1.1724 | LR: 0.034085 | Momentum: 0.5872\n",
      "[Epoch 111/300] Batch 300 | G Loss: 0.9561 | D Loss: 1.2552 | LR: 0.034072 | Momentum: 0.5872\n",
      "[Epoch 111/300] Batch 400 | G Loss: 0.9053 | D Loss: 1.1868 | LR: 0.034058 | Momentum: 0.5872\n",
      "[Epoch 111/300] Batch 500 | G Loss: 0.9836 | D Loss: 1.1693 | LR: 0.034044 | Momentum: 0.5872\n",
      "[Epoch 111/300] Batch 600 | G Loss: 0.9665 | D Loss: 1.2346 | LR: 0.034031 | Momentum: 0.5872\n",
      "[Epoch 111/300] Batch 700 | G Loss: 0.9878 | D Loss: 1.1437 | LR: 0.034017 | Momentum: 0.5872\n",
      "[Epoch 111/300] Batch 800 | G Loss: 0.9362 | D Loss: 1.2505 | LR: 0.034004 | Momentum: 0.5872\n",
      "[Epoch 112/300] Batch 0 | G Loss: 0.8813 | D Loss: 1.1817 | LR: 0.033994 | Momentum: 0.5880\n",
      "[Epoch 112/300] Batch 100 | G Loss: 1.0006 | D Loss: 1.2316 | LR: 0.033981 | Momentum: 0.5880\n",
      "[Epoch 112/300] Batch 200 | G Loss: 0.9307 | D Loss: 1.1958 | LR: 0.033967 | Momentum: 0.5880\n",
      "[Epoch 112/300] Batch 300 | G Loss: 0.8888 | D Loss: 1.1242 | LR: 0.033953 | Momentum: 0.5880\n",
      "[Epoch 112/300] Batch 400 | G Loss: 1.0285 | D Loss: 1.1732 | LR: 0.033940 | Momentum: 0.5880\n",
      "[Epoch 112/300] Batch 500 | G Loss: 0.9139 | D Loss: 1.1995 | LR: 0.033926 | Momentum: 0.5880\n",
      "[Epoch 112/300] Batch 600 | G Loss: 0.8450 | D Loss: 1.1700 | LR: 0.033913 | Momentum: 0.5880\n",
      "[Epoch 112/300] Batch 700 | G Loss: 0.9370 | D Loss: 1.1044 | LR: 0.033899 | Momentum: 0.5880\n",
      "[Epoch 112/300] Batch 800 | G Loss: 0.8645 | D Loss: 1.2458 | LR: 0.033886 | Momentum: 0.5880\n",
      "[Epoch 113/300] Batch 0 | G Loss: 0.8988 | D Loss: 1.1653 | LR: 0.033876 | Momentum: 0.5888\n",
      "[Epoch 113/300] Batch 100 | G Loss: 0.9148 | D Loss: 1.2585 | LR: 0.033863 | Momentum: 0.5888\n",
      "[Epoch 113/300] Batch 200 | G Loss: 0.9278 | D Loss: 1.2324 | LR: 0.033849 | Momentum: 0.5888\n",
      "[Epoch 113/300] Batch 300 | G Loss: 0.8692 | D Loss: 1.1969 | LR: 0.033836 | Momentum: 0.5888\n",
      "[Epoch 113/300] Batch 400 | G Loss: 0.9661 | D Loss: 1.1543 | LR: 0.033822 | Momentum: 0.5888\n",
      "[Epoch 113/300] Batch 500 | G Loss: 0.9294 | D Loss: 1.1850 | LR: 0.033808 | Momentum: 0.5888\n",
      "[Epoch 113/300] Batch 600 | G Loss: 0.8332 | D Loss: 1.2025 | LR: 0.033795 | Momentum: 0.5888\n",
      "[Epoch 113/300] Batch 700 | G Loss: 0.8842 | D Loss: 1.1535 | LR: 0.033781 | Momentum: 0.5888\n",
      "[Epoch 113/300] Batch 800 | G Loss: 0.9586 | D Loss: 1.1921 | LR: 0.033768 | Momentum: 0.5888\n",
      "[Epoch 114/300] Batch 0 | G Loss: 0.9366 | D Loss: 1.2248 | LR: 0.033759 | Momentum: 0.5896\n",
      "[Epoch 114/300] Batch 100 | G Loss: 0.8564 | D Loss: 1.1469 | LR: 0.033745 | Momentum: 0.5896\n",
      "[Epoch 114/300] Batch 200 | G Loss: 0.9362 | D Loss: 1.2269 | LR: 0.033732 | Momentum: 0.5896\n",
      "[Epoch 114/300] Batch 300 | G Loss: 0.9557 | D Loss: 1.1890 | LR: 0.033718 | Momentum: 0.5896\n",
      "[Epoch 114/300] Batch 400 | G Loss: 1.0345 | D Loss: 1.1508 | LR: 0.033705 | Momentum: 0.5896\n",
      "[Epoch 114/300] Batch 500 | G Loss: 0.9101 | D Loss: 1.1335 | LR: 0.033691 | Momentum: 0.5896\n",
      "[Epoch 114/300] Batch 600 | G Loss: 0.9138 | D Loss: 1.1304 | LR: 0.033678 | Momentum: 0.5896\n",
      "[Epoch 114/300] Batch 700 | G Loss: 0.9017 | D Loss: 1.1694 | LR: 0.033664 | Momentum: 0.5896\n",
      "[Epoch 114/300] Batch 800 | G Loss: 0.9080 | D Loss: 1.1879 | LR: 0.033651 | Momentum: 0.5896\n",
      "[Epoch 115/300] Batch 0 | G Loss: 0.8679 | D Loss: 1.1953 | LR: 0.033641 | Momentum: 0.5904\n",
      "[Epoch 115/300] Batch 100 | G Loss: 0.9444 | D Loss: 1.1960 | LR: 0.033628 | Momentum: 0.5904\n",
      "[Epoch 115/300] Batch 200 | G Loss: 1.0257 | D Loss: 1.2529 | LR: 0.033615 | Momentum: 0.5904\n",
      "[Epoch 115/300] Batch 300 | G Loss: 1.0102 | D Loss: 1.1522 | LR: 0.033601 | Momentum: 0.5904\n",
      "[Epoch 115/300] Batch 400 | G Loss: 0.9469 | D Loss: 1.2273 | LR: 0.033588 | Momentum: 0.5904\n",
      "[Epoch 115/300] Batch 500 | G Loss: 0.8863 | D Loss: 1.2286 | LR: 0.033574 | Momentum: 0.5904\n",
      "[Epoch 115/300] Batch 600 | G Loss: 0.9581 | D Loss: 1.2072 | LR: 0.033561 | Momentum: 0.5904\n",
      "[Epoch 115/300] Batch 700 | G Loss: 0.9464 | D Loss: 1.0918 | LR: 0.033547 | Momentum: 0.5904\n",
      "[Epoch 115/300] Batch 800 | G Loss: 0.9863 | D Loss: 1.1765 | LR: 0.033534 | Momentum: 0.5904\n",
      "[Epoch 116/300] Batch 0 | G Loss: 0.9875 | D Loss: 1.1367 | LR: 0.033525 | Momentum: 0.5912\n",
      "[Epoch 116/300] Batch 100 | G Loss: 0.9615 | D Loss: 1.2216 | LR: 0.033511 | Momentum: 0.5912\n",
      "[Epoch 116/300] Batch 200 | G Loss: 1.0146 | D Loss: 1.1207 | LR: 0.033498 | Momentum: 0.5912\n",
      "[Epoch 116/300] Batch 300 | G Loss: 0.9414 | D Loss: 1.1048 | LR: 0.033485 | Momentum: 0.5912\n",
      "[Epoch 116/300] Batch 400 | G Loss: 0.9871 | D Loss: 1.2478 | LR: 0.033471 | Momentum: 0.5912\n",
      "[Epoch 116/300] Batch 500 | G Loss: 0.9364 | D Loss: 1.1785 | LR: 0.033458 | Momentum: 0.5912\n",
      "[Epoch 116/300] Batch 600 | G Loss: 0.9430 | D Loss: 1.2432 | LR: 0.033444 | Momentum: 0.5912\n",
      "[Epoch 116/300] Batch 700 | G Loss: 0.9248 | D Loss: 1.3090 | LR: 0.033431 | Momentum: 0.5912\n",
      "[Epoch 116/300] Batch 800 | G Loss: 0.8801 | D Loss: 1.2189 | LR: 0.033418 | Momentum: 0.5912\n",
      "[Epoch 117/300] Batch 0 | G Loss: 0.8880 | D Loss: 1.1481 | LR: 0.033408 | Momentum: 0.5920\n",
      "[Epoch 117/300] Batch 100 | G Loss: 1.0046 | D Loss: 1.1269 | LR: 0.033395 | Momentum: 0.5920\n",
      "[Epoch 117/300] Batch 200 | G Loss: 0.9818 | D Loss: 1.2235 | LR: 0.033382 | Momentum: 0.5920\n",
      "[Epoch 117/300] Batch 300 | G Loss: 0.9335 | D Loss: 1.1742 | LR: 0.033368 | Momentum: 0.5920\n",
      "[Epoch 117/300] Batch 400 | G Loss: 0.9217 | D Loss: 1.2351 | LR: 0.033355 | Momentum: 0.5920\n",
      "[Epoch 117/300] Batch 500 | G Loss: 0.9376 | D Loss: 1.1869 | LR: 0.033342 | Momentum: 0.5920\n",
      "[Epoch 117/300] Batch 600 | G Loss: 0.9061 | D Loss: 1.1296 | LR: 0.033328 | Momentum: 0.5920\n",
      "[Epoch 117/300] Batch 700 | G Loss: 0.9445 | D Loss: 1.2514 | LR: 0.033315 | Momentum: 0.5920\n",
      "[Epoch 117/300] Batch 800 | G Loss: 0.9421 | D Loss: 1.2636 | LR: 0.033302 | Momentum: 0.5920\n",
      "[Epoch 118/300] Batch 0 | G Loss: 0.8677 | D Loss: 1.0986 | LR: 0.033292 | Momentum: 0.5928\n",
      "[Epoch 118/300] Batch 100 | G Loss: 0.9511 | D Loss: 1.1870 | LR: 0.033279 | Momentum: 0.5928\n",
      "[Epoch 118/300] Batch 200 | G Loss: 1.0075 | D Loss: 1.1384 | LR: 0.033266 | Momentum: 0.5928\n",
      "[Epoch 118/300] Batch 300 | G Loss: 0.9384 | D Loss: 1.2762 | LR: 0.033253 | Momentum: 0.5928\n",
      "[Epoch 118/300] Batch 400 | G Loss: 0.9076 | D Loss: 1.2410 | LR: 0.033239 | Momentum: 0.5928\n",
      "[Epoch 118/300] Batch 500 | G Loss: 0.9850 | D Loss: 1.1800 | LR: 0.033226 | Momentum: 0.5928\n",
      "[Epoch 118/300] Batch 600 | G Loss: 0.9929 | D Loss: 1.1211 | LR: 0.033213 | Momentum: 0.5928\n",
      "[Epoch 118/300] Batch 700 | G Loss: 0.9664 | D Loss: 1.2454 | LR: 0.033199 | Momentum: 0.5928\n",
      "[Epoch 118/300] Batch 800 | G Loss: 0.8906 | D Loss: 1.1716 | LR: 0.033186 | Momentum: 0.5928\n",
      "[Epoch 119/300] Batch 0 | G Loss: 1.0350 | D Loss: 1.1402 | LR: 0.033177 | Momentum: 0.5936\n",
      "[Epoch 119/300] Batch 100 | G Loss: 0.8984 | D Loss: 1.1931 | LR: 0.033164 | Momentum: 0.5936\n",
      "[Epoch 119/300] Batch 200 | G Loss: 0.9665 | D Loss: 1.1977 | LR: 0.033150 | Momentum: 0.5936\n",
      "[Epoch 119/300] Batch 300 | G Loss: 0.9411 | D Loss: 1.2424 | LR: 0.033137 | Momentum: 0.5936\n",
      "[Epoch 119/300] Batch 400 | G Loss: 0.9754 | D Loss: 1.1711 | LR: 0.033124 | Momentum: 0.5936\n",
      "[Epoch 119/300] Batch 500 | G Loss: 0.9866 | D Loss: 1.1171 | LR: 0.033111 | Momentum: 0.5936\n",
      "[Epoch 119/300] Batch 600 | G Loss: 0.9713 | D Loss: 1.2607 | LR: 0.033097 | Momentum: 0.5936\n",
      "[Epoch 119/300] Batch 700 | G Loss: 0.9492 | D Loss: 1.1531 | LR: 0.033084 | Momentum: 0.5936\n",
      "[Epoch 119/300] Batch 800 | G Loss: 0.8916 | D Loss: 1.2648 | LR: 0.033071 | Momentum: 0.5936\n",
      "[Epoch 120/300] Batch 0 | G Loss: 0.9571 | D Loss: 1.1965 | LR: 0.033062 | Momentum: 0.5944\n",
      "[Epoch 120/300] Batch 100 | G Loss: 0.8949 | D Loss: 1.1778 | LR: 0.033049 | Momentum: 0.5944\n",
      "[Epoch 120/300] Batch 200 | G Loss: 0.9433 | D Loss: 1.1419 | LR: 0.033035 | Momentum: 0.5944\n",
      "[Epoch 120/300] Batch 300 | G Loss: 0.9223 | D Loss: 1.1201 | LR: 0.033022 | Momentum: 0.5944\n",
      "[Epoch 120/300] Batch 400 | G Loss: 0.9307 | D Loss: 1.1983 | LR: 0.033009 | Momentum: 0.5944\n",
      "[Epoch 120/300] Batch 500 | G Loss: 0.9004 | D Loss: 1.1426 | LR: 0.032996 | Momentum: 0.5944\n",
      "[Epoch 120/300] Batch 600 | G Loss: 0.9145 | D Loss: 1.1789 | LR: 0.032983 | Momentum: 0.5944\n",
      "[Epoch 120/300] Batch 700 | G Loss: 0.8931 | D Loss: 1.2031 | LR: 0.032969 | Momentum: 0.5944\n",
      "[Epoch 120/300] Batch 800 | G Loss: 0.9528 | D Loss: 1.1071 | LR: 0.032956 | Momentum: 0.5944\n",
      "[Epoch 121/300] Batch 0 | G Loss: 0.8848 | D Loss: 1.1994 | LR: 0.032947 | Momentum: 0.5952\n",
      "[Epoch 121/300] Batch 100 | G Loss: 0.9086 | D Loss: 1.1932 | LR: 0.032934 | Momentum: 0.5952\n",
      "[Epoch 121/300] Batch 200 | G Loss: 1.0182 | D Loss: 1.1667 | LR: 0.032921 | Momentum: 0.5952\n",
      "[Epoch 121/300] Batch 300 | G Loss: 0.9424 | D Loss: 1.0866 | LR: 0.032908 | Momentum: 0.5952\n",
      "[Epoch 121/300] Batch 400 | G Loss: 0.9267 | D Loss: 1.2544 | LR: 0.032894 | Momentum: 0.5952\n",
      "[Epoch 121/300] Batch 500 | G Loss: 0.9435 | D Loss: 1.2128 | LR: 0.032881 | Momentum: 0.5952\n",
      "[Epoch 121/300] Batch 600 | G Loss: 0.9020 | D Loss: 1.2052 | LR: 0.032868 | Momentum: 0.5952\n",
      "[Epoch 121/300] Batch 700 | G Loss: 0.9705 | D Loss: 1.2524 | LR: 0.032855 | Momentum: 0.5952\n",
      "[Epoch 121/300] Batch 800 | G Loss: 0.9098 | D Loss: 1.3569 | LR: 0.032842 | Momentum: 0.5952\n",
      "[Epoch 122/300] Batch 0 | G Loss: 0.9414 | D Loss: 1.0931 | LR: 0.032833 | Momentum: 0.5960\n",
      "[Epoch 122/300] Batch 100 | G Loss: 0.9662 | D Loss: 1.2104 | LR: 0.032820 | Momentum: 0.5960\n",
      "[Epoch 122/300] Batch 200 | G Loss: 0.9157 | D Loss: 1.1077 | LR: 0.032807 | Momentum: 0.5960\n",
      "[Epoch 122/300] Batch 300 | G Loss: 0.9785 | D Loss: 1.1274 | LR: 0.032793 | Momentum: 0.5960\n",
      "[Epoch 122/300] Batch 400 | G Loss: 0.9697 | D Loss: 1.1590 | LR: 0.032780 | Momentum: 0.5960\n",
      "[Epoch 122/300] Batch 500 | G Loss: 0.9837 | D Loss: 1.2703 | LR: 0.032767 | Momentum: 0.5960\n",
      "[Epoch 122/300] Batch 600 | G Loss: 0.9978 | D Loss: 1.1348 | LR: 0.032754 | Momentum: 0.5960\n",
      "[Epoch 122/300] Batch 700 | G Loss: 0.9104 | D Loss: 1.0841 | LR: 0.032741 | Momentum: 0.5960\n",
      "[Epoch 122/300] Batch 800 | G Loss: 0.9568 | D Loss: 1.1331 | LR: 0.032728 | Momentum: 0.5960\n",
      "[Epoch 123/300] Batch 0 | G Loss: 0.9500 | D Loss: 1.0666 | LR: 0.032719 | Momentum: 0.5968\n",
      "[Epoch 123/300] Batch 100 | G Loss: 1.0070 | D Loss: 1.1403 | LR: 0.032706 | Momentum: 0.5968\n",
      "[Epoch 123/300] Batch 200 | G Loss: 1.0275 | D Loss: 1.1045 | LR: 0.032693 | Momentum: 0.5968\n",
      "[Epoch 123/300] Batch 300 | G Loss: 0.9228 | D Loss: 1.2173 | LR: 0.032680 | Momentum: 0.5968\n",
      "[Epoch 123/300] Batch 400 | G Loss: 0.9324 | D Loss: 1.1872 | LR: 0.032667 | Momentum: 0.5968\n",
      "[Epoch 123/300] Batch 500 | G Loss: 0.9072 | D Loss: 1.2357 | LR: 0.032653 | Momentum: 0.5968\n",
      "[Epoch 123/300] Batch 600 | G Loss: 0.8967 | D Loss: 1.1540 | LR: 0.032640 | Momentum: 0.5968\n",
      "[Epoch 123/300] Batch 700 | G Loss: 0.9972 | D Loss: 1.1625 | LR: 0.032627 | Momentum: 0.5968\n",
      "[Epoch 123/300] Batch 800 | G Loss: 0.9205 | D Loss: 1.1508 | LR: 0.032614 | Momentum: 0.5968\n",
      "[Epoch 124/300] Batch 0 | G Loss: 0.9902 | D Loss: 1.2538 | LR: 0.032605 | Momentum: 0.5976\n",
      "[Epoch 124/300] Batch 100 | G Loss: 0.9676 | D Loss: 1.2197 | LR: 0.032592 | Momentum: 0.5976\n",
      "[Epoch 124/300] Batch 200 | G Loss: 0.9399 | D Loss: 1.2520 | LR: 0.032579 | Momentum: 0.5976\n",
      "[Epoch 124/300] Batch 300 | G Loss: 0.8594 | D Loss: 1.1050 | LR: 0.032566 | Momentum: 0.5976\n",
      "[Epoch 124/300] Batch 400 | G Loss: 0.9766 | D Loss: 1.1677 | LR: 0.032553 | Momentum: 0.5976\n",
      "[Epoch 124/300] Batch 500 | G Loss: 0.9167 | D Loss: 1.1275 | LR: 0.032540 | Momentum: 0.5976\n",
      "[Epoch 124/300] Batch 600 | G Loss: 0.9671 | D Loss: 1.1835 | LR: 0.032527 | Momentum: 0.5976\n",
      "[Epoch 124/300] Batch 700 | G Loss: 0.9158 | D Loss: 1.0915 | LR: 0.032514 | Momentum: 0.5976\n",
      "[Epoch 124/300] Batch 800 | G Loss: 0.8974 | D Loss: 1.1825 | LR: 0.032501 | Momentum: 0.5976\n",
      "[Epoch 125/300] Batch 0 | G Loss: 0.8930 | D Loss: 1.2788 | LR: 0.032492 | Momentum: 0.5984\n",
      "[Epoch 125/300] Batch 100 | G Loss: 0.9464 | D Loss: 1.2239 | LR: 0.032479 | Momentum: 0.5984\n",
      "[Epoch 125/300] Batch 200 | G Loss: 0.9526 | D Loss: 1.1921 | LR: 0.032466 | Momentum: 0.5984\n",
      "[Epoch 125/300] Batch 300 | G Loss: 0.9861 | D Loss: 1.1976 | LR: 0.032453 | Momentum: 0.5984\n",
      "[Epoch 125/300] Batch 400 | G Loss: 0.9599 | D Loss: 1.2472 | LR: 0.032440 | Momentum: 0.5984\n",
      "[Epoch 125/300] Batch 500 | G Loss: 0.9531 | D Loss: 1.1829 | LR: 0.032427 | Momentum: 0.5984\n",
      "[Epoch 125/300] Batch 600 | G Loss: 0.8879 | D Loss: 1.2072 | LR: 0.032414 | Momentum: 0.5984\n",
      "[Epoch 125/300] Batch 700 | G Loss: 0.9547 | D Loss: 1.2215 | LR: 0.032401 | Momentum: 0.5984\n",
      "[Epoch 125/300] Batch 800 | G Loss: 0.8563 | D Loss: 1.2530 | LR: 0.032388 | Momentum: 0.5984\n",
      "[Epoch 126/300] Batch 0 | G Loss: 0.9914 | D Loss: 1.1617 | LR: 0.032379 | Momentum: 0.5992\n",
      "[Epoch 126/300] Batch 100 | G Loss: 0.8763 | D Loss: 1.2589 | LR: 0.032366 | Momentum: 0.5992\n",
      "[Epoch 126/300] Batch 200 | G Loss: 0.9936 | D Loss: 1.1686 | LR: 0.032354 | Momentum: 0.5992\n",
      "[Epoch 126/300] Batch 300 | G Loss: 0.8957 | D Loss: 1.1329 | LR: 0.032341 | Momentum: 0.5992\n",
      "[Epoch 126/300] Batch 400 | G Loss: 0.9682 | D Loss: 1.1741 | LR: 0.032328 | Momentum: 0.5992\n",
      "[Epoch 126/300] Batch 500 | G Loss: 0.9369 | D Loss: 1.2290 | LR: 0.032315 | Momentum: 0.5992\n",
      "[Epoch 126/300] Batch 600 | G Loss: 0.9484 | D Loss: 1.2550 | LR: 0.032302 | Momentum: 0.5992\n",
      "[Epoch 126/300] Batch 700 | G Loss: 0.9350 | D Loss: 1.2114 | LR: 0.032289 | Momentum: 0.5992\n",
      "[Epoch 126/300] Batch 800 | G Loss: 0.9835 | D Loss: 1.2223 | LR: 0.032276 | Momentum: 0.5992\n",
      "[Epoch 127/300] Batch 0 | G Loss: 0.9575 | D Loss: 1.2152 | LR: 0.032267 | Momentum: 0.6000\n",
      "[Epoch 127/300] Batch 100 | G Loss: 0.8744 | D Loss: 1.2881 | LR: 0.032254 | Momentum: 0.6000\n",
      "[Epoch 127/300] Batch 200 | G Loss: 0.9930 | D Loss: 1.2463 | LR: 0.032241 | Momentum: 0.6000\n",
      "[Epoch 127/300] Batch 300 | G Loss: 0.9304 | D Loss: 1.1483 | LR: 0.032228 | Momentum: 0.6000\n",
      "[Epoch 127/300] Batch 400 | G Loss: 0.9153 | D Loss: 1.1756 | LR: 0.032216 | Momentum: 0.6000\n",
      "[Epoch 127/300] Batch 500 | G Loss: 0.9095 | D Loss: 1.2002 | LR: 0.032203 | Momentum: 0.6000\n",
      "[Epoch 127/300] Batch 600 | G Loss: 0.9267 | D Loss: 1.3062 | LR: 0.032190 | Momentum: 0.6000\n",
      "[Epoch 127/300] Batch 700 | G Loss: 1.0228 | D Loss: 1.2797 | LR: 0.032177 | Momentum: 0.6000\n",
      "[Epoch 127/300] Batch 800 | G Loss: 1.0586 | D Loss: 1.1486 | LR: 0.032164 | Momentum: 0.6000\n",
      "[Epoch 128/300] Batch 0 | G Loss: 0.9316 | D Loss: 1.1773 | LR: 0.032155 | Momentum: 0.6008\n",
      "[Epoch 128/300] Batch 100 | G Loss: 0.9156 | D Loss: 1.1488 | LR: 0.032142 | Momentum: 0.6008\n",
      "[Epoch 128/300] Batch 200 | G Loss: 0.9566 | D Loss: 1.2298 | LR: 0.032129 | Momentum: 0.6008\n",
      "[Epoch 128/300] Batch 300 | G Loss: 0.9103 | D Loss: 1.1142 | LR: 0.032117 | Momentum: 0.6008\n",
      "[Epoch 128/300] Batch 400 | G Loss: 0.9304 | D Loss: 1.1673 | LR: 0.032104 | Momentum: 0.6008\n",
      "[Epoch 128/300] Batch 500 | G Loss: 1.0042 | D Loss: 1.2558 | LR: 0.032091 | Momentum: 0.6008\n",
      "[Epoch 128/300] Batch 600 | G Loss: 0.9100 | D Loss: 1.1836 | LR: 0.032078 | Momentum: 0.6008\n",
      "[Epoch 128/300] Batch 700 | G Loss: 1.0442 | D Loss: 1.0923 | LR: 0.032065 | Momentum: 0.6008\n",
      "[Epoch 128/300] Batch 800 | G Loss: 0.8926 | D Loss: 1.0612 | LR: 0.032052 | Momentum: 0.6008\n",
      "[Epoch 129/300] Batch 0 | G Loss: 0.9863 | D Loss: 1.1553 | LR: 0.032044 | Momentum: 0.6016\n",
      "[Epoch 129/300] Batch 100 | G Loss: 0.9185 | D Loss: 1.1015 | LR: 0.032031 | Momentum: 0.6016\n",
      "[Epoch 129/300] Batch 200 | G Loss: 0.9441 | D Loss: 1.1503 | LR: 0.032018 | Momentum: 0.6016\n",
      "[Epoch 129/300] Batch 300 | G Loss: 0.9446 | D Loss: 1.1836 | LR: 0.032005 | Momentum: 0.6016\n",
      "[Epoch 129/300] Batch 400 | G Loss: 0.8584 | D Loss: 1.1831 | LR: 0.031992 | Momentum: 0.6016\n",
      "[Epoch 129/300] Batch 500 | G Loss: 0.9117 | D Loss: 1.1627 | LR: 0.031980 | Momentum: 0.6016\n",
      "[Epoch 129/300] Batch 600 | G Loss: 0.9247 | D Loss: 1.1994 | LR: 0.031967 | Momentum: 0.6016\n",
      "[Epoch 129/300] Batch 700 | G Loss: 0.8909 | D Loss: 1.1849 | LR: 0.031954 | Momentum: 0.6016\n",
      "[Epoch 129/300] Batch 800 | G Loss: 0.9352 | D Loss: 1.1915 | LR: 0.031941 | Momentum: 0.6016\n",
      "[Epoch 130/300] Batch 0 | G Loss: 0.9686 | D Loss: 1.2798 | LR: 0.031932 | Momentum: 0.6024\n",
      "[Epoch 130/300] Batch 100 | G Loss: 0.9813 | D Loss: 1.1266 | LR: 0.031920 | Momentum: 0.6024\n",
      "[Epoch 130/300] Batch 200 | G Loss: 0.9458 | D Loss: 1.1424 | LR: 0.031907 | Momentum: 0.6024\n",
      "[Epoch 130/300] Batch 300 | G Loss: 0.9539 | D Loss: 1.1639 | LR: 0.031894 | Momentum: 0.6024\n",
      "[Epoch 130/300] Batch 400 | G Loss: 0.9656 | D Loss: 1.2429 | LR: 0.031881 | Momentum: 0.6024\n",
      "[Epoch 130/300] Batch 500 | G Loss: 1.0496 | D Loss: 1.2306 | LR: 0.031869 | Momentum: 0.6024\n",
      "[Epoch 130/300] Batch 600 | G Loss: 0.9084 | D Loss: 1.1182 | LR: 0.031856 | Momentum: 0.6024\n",
      "[Epoch 130/300] Batch 700 | G Loss: 0.8972 | D Loss: 1.0999 | LR: 0.031843 | Momentum: 0.6024\n",
      "[Epoch 130/300] Batch 800 | G Loss: 0.9759 | D Loss: 1.1534 | LR: 0.031830 | Momentum: 0.6024\n",
      "[Epoch 131/300] Batch 0 | G Loss: 0.9915 | D Loss: 1.2329 | LR: 0.031822 | Momentum: 0.6032\n",
      "[Epoch 131/300] Batch 100 | G Loss: 0.8932 | D Loss: 1.2304 | LR: 0.031809 | Momentum: 0.6032\n",
      "[Epoch 131/300] Batch 200 | G Loss: 0.9479 | D Loss: 1.1455 | LR: 0.031796 | Momentum: 0.6032\n",
      "[Epoch 131/300] Batch 300 | G Loss: 0.9095 | D Loss: 1.1898 | LR: 0.031783 | Momentum: 0.6032\n",
      "[Epoch 131/300] Batch 400 | G Loss: 0.9365 | D Loss: 1.2768 | LR: 0.031771 | Momentum: 0.6032\n",
      "[Epoch 131/300] Batch 500 | G Loss: 0.9203 | D Loss: 1.1501 | LR: 0.031758 | Momentum: 0.6032\n",
      "[Epoch 131/300] Batch 600 | G Loss: 0.9984 | D Loss: 1.1545 | LR: 0.031745 | Momentum: 0.6032\n",
      "[Epoch 131/300] Batch 700 | G Loss: 0.9483 | D Loss: 1.2485 | LR: 0.031733 | Momentum: 0.6032\n",
      "[Epoch 131/300] Batch 800 | G Loss: 0.9716 | D Loss: 1.1589 | LR: 0.031720 | Momentum: 0.6032\n",
      "[Epoch 132/300] Batch 0 | G Loss: 0.9927 | D Loss: 1.1572 | LR: 0.031711 | Momentum: 0.6040\n",
      "[Epoch 132/300] Batch 100 | G Loss: 0.9207 | D Loss: 1.1374 | LR: 0.031698 | Momentum: 0.6040\n",
      "[Epoch 132/300] Batch 200 | G Loss: 0.9853 | D Loss: 1.1592 | LR: 0.031686 | Momentum: 0.6040\n",
      "[Epoch 132/300] Batch 300 | G Loss: 0.9241 | D Loss: 1.0329 | LR: 0.031673 | Momentum: 0.6040\n",
      "[Epoch 132/300] Batch 400 | G Loss: 0.9019 | D Loss: 1.1732 | LR: 0.031660 | Momentum: 0.6040\n",
      "[Epoch 132/300] Batch 500 | G Loss: 0.9089 | D Loss: 1.2780 | LR: 0.031648 | Momentum: 0.6040\n",
      "[Epoch 132/300] Batch 600 | G Loss: 0.9512 | D Loss: 1.1084 | LR: 0.031635 | Momentum: 0.6040\n",
      "[Epoch 132/300] Batch 700 | G Loss: 0.9294 | D Loss: 1.2234 | LR: 0.031622 | Momentum: 0.6040\n",
      "[Epoch 132/300] Batch 800 | G Loss: 0.9332 | D Loss: 1.1615 | LR: 0.031610 | Momentum: 0.6040\n",
      "[Epoch 133/300] Batch 0 | G Loss: 0.9023 | D Loss: 1.1864 | LR: 0.031601 | Momentum: 0.6048\n",
      "[Epoch 133/300] Batch 100 | G Loss: 0.9456 | D Loss: 1.0519 | LR: 0.031588 | Momentum: 0.6048\n",
      "[Epoch 133/300] Batch 200 | G Loss: 0.9727 | D Loss: 1.1404 | LR: 0.031576 | Momentum: 0.6048\n",
      "[Epoch 133/300] Batch 300 | G Loss: 0.8955 | D Loss: 1.1641 | LR: 0.031563 | Momentum: 0.6048\n",
      "[Epoch 133/300] Batch 400 | G Loss: 0.9199 | D Loss: 1.2235 | LR: 0.031551 | Momentum: 0.6048\n",
      "[Epoch 133/300] Batch 500 | G Loss: 0.8580 | D Loss: 1.1067 | LR: 0.031538 | Momentum: 0.6048\n",
      "[Epoch 133/300] Batch 600 | G Loss: 0.9990 | D Loss: 1.2277 | LR: 0.031525 | Momentum: 0.6048\n",
      "[Epoch 133/300] Batch 700 | G Loss: 1.0234 | D Loss: 1.1752 | LR: 0.031513 | Momentum: 0.6048\n",
      "[Epoch 133/300] Batch 800 | G Loss: 0.9879 | D Loss: 1.1433 | LR: 0.031500 | Momentum: 0.6048\n",
      "[Epoch 134/300] Batch 0 | G Loss: 0.9357 | D Loss: 1.1377 | LR: 0.031491 | Momentum: 0.6056\n",
      "[Epoch 134/300] Batch 100 | G Loss: 0.9552 | D Loss: 1.1236 | LR: 0.031479 | Momentum: 0.6056\n",
      "[Epoch 134/300] Batch 200 | G Loss: 0.8752 | D Loss: 1.1847 | LR: 0.031466 | Momentum: 0.6056\n",
      "[Epoch 134/300] Batch 300 | G Loss: 0.8717 | D Loss: 1.2018 | LR: 0.031454 | Momentum: 0.6056\n",
      "[Epoch 134/300] Batch 400 | G Loss: 0.9232 | D Loss: 1.2572 | LR: 0.031441 | Momentum: 0.6056\n",
      "[Epoch 134/300] Batch 500 | G Loss: 0.8902 | D Loss: 1.2442 | LR: 0.031429 | Momentum: 0.6056\n",
      "[Epoch 134/300] Batch 600 | G Loss: 0.9578 | D Loss: 1.2052 | LR: 0.031416 | Momentum: 0.6056\n",
      "[Epoch 134/300] Batch 700 | G Loss: 0.9402 | D Loss: 1.3267 | LR: 0.031403 | Momentum: 0.6056\n",
      "[Epoch 134/300] Batch 800 | G Loss: 0.9088 | D Loss: 1.1966 | LR: 0.031391 | Momentum: 0.6056\n",
      "[Epoch 135/300] Batch 0 | G Loss: 1.0003 | D Loss: 1.1752 | LR: 0.031382 | Momentum: 0.6064\n",
      "[Epoch 135/300] Batch 100 | G Loss: 0.9966 | D Loss: 1.2307 | LR: 0.031370 | Momentum: 0.6064\n",
      "[Epoch 135/300] Batch 200 | G Loss: 0.9510 | D Loss: 1.1642 | LR: 0.031357 | Momentum: 0.6064\n",
      "[Epoch 135/300] Batch 300 | G Loss: 0.9426 | D Loss: 1.1763 | LR: 0.031345 | Momentum: 0.6064\n",
      "[Epoch 135/300] Batch 400 | G Loss: 0.9048 | D Loss: 1.1375 | LR: 0.031332 | Momentum: 0.6064\n",
      "[Epoch 135/300] Batch 500 | G Loss: 0.9743 | D Loss: 1.1454 | LR: 0.031319 | Momentum: 0.6064\n",
      "[Epoch 135/300] Batch 600 | G Loss: 0.9325 | D Loss: 1.1373 | LR: 0.031307 | Momentum: 0.6064\n",
      "[Epoch 135/300] Batch 700 | G Loss: 0.8847 | D Loss: 1.1092 | LR: 0.031294 | Momentum: 0.6064\n",
      "[Epoch 135/300] Batch 800 | G Loss: 0.9279 | D Loss: 1.2150 | LR: 0.031282 | Momentum: 0.6064\n",
      "[Epoch 136/300] Batch 0 | G Loss: 0.9757 | D Loss: 1.1551 | LR: 0.031273 | Momentum: 0.6072\n",
      "[Epoch 136/300] Batch 100 | G Loss: 0.9309 | D Loss: 1.2697 | LR: 0.031261 | Momentum: 0.6072\n",
      "[Epoch 136/300] Batch 200 | G Loss: 0.9226 | D Loss: 1.2187 | LR: 0.031248 | Momentum: 0.6072\n",
      "[Epoch 136/300] Batch 300 | G Loss: 0.9385 | D Loss: 1.2315 | LR: 0.031236 | Momentum: 0.6072\n",
      "[Epoch 136/300] Batch 400 | G Loss: 0.9367 | D Loss: 1.2244 | LR: 0.031223 | Momentum: 0.6072\n",
      "[Epoch 136/300] Batch 500 | G Loss: 0.8594 | D Loss: 1.1280 | LR: 0.031211 | Momentum: 0.6072\n",
      "[Epoch 136/300] Batch 600 | G Loss: 0.8907 | D Loss: 1.1979 | LR: 0.031198 | Momentum: 0.6072\n",
      "[Epoch 136/300] Batch 700 | G Loss: 0.9713 | D Loss: 1.1805 | LR: 0.031186 | Momentum: 0.6072\n",
      "[Epoch 136/300] Batch 800 | G Loss: 0.9134 | D Loss: 1.2048 | LR: 0.031173 | Momentum: 0.6072\n",
      "[Epoch 137/300] Batch 0 | G Loss: 0.9689 | D Loss: 1.1304 | LR: 0.031165 | Momentum: 0.6080\n",
      "[Epoch 137/300] Batch 100 | G Loss: 1.0950 | D Loss: 1.2511 | LR: 0.031152 | Momentum: 0.6080\n",
      "[Epoch 137/300] Batch 200 | G Loss: 0.9974 | D Loss: 1.1992 | LR: 0.031140 | Momentum: 0.6080\n",
      "[Epoch 137/300] Batch 300 | G Loss: 0.8835 | D Loss: 1.1431 | LR: 0.031127 | Momentum: 0.6080\n",
      "[Epoch 137/300] Batch 400 | G Loss: 0.9231 | D Loss: 1.1798 | LR: 0.031115 | Momentum: 0.6080\n",
      "[Epoch 137/300] Batch 500 | G Loss: 1.0155 | D Loss: 1.2378 | LR: 0.031102 | Momentum: 0.6080\n",
      "[Epoch 137/300] Batch 600 | G Loss: 0.9426 | D Loss: 1.1617 | LR: 0.031090 | Momentum: 0.6080\n",
      "[Epoch 137/300] Batch 700 | G Loss: 1.0352 | D Loss: 1.2761 | LR: 0.031078 | Momentum: 0.6080\n",
      "[Epoch 137/300] Batch 800 | G Loss: 0.9298 | D Loss: 1.1268 | LR: 0.031065 | Momentum: 0.6080\n",
      "[Epoch 138/300] Batch 0 | G Loss: 0.9343 | D Loss: 1.1644 | LR: 0.031057 | Momentum: 0.6088\n",
      "[Epoch 138/300] Batch 100 | G Loss: 1.0230 | D Loss: 1.1788 | LR: 0.031044 | Momentum: 0.6088\n",
      "[Epoch 138/300] Batch 200 | G Loss: 0.9682 | D Loss: 1.2253 | LR: 0.031032 | Momentum: 0.6088\n",
      "[Epoch 138/300] Batch 300 | G Loss: 0.9300 | D Loss: 1.3082 | LR: 0.031019 | Momentum: 0.6088\n",
      "[Epoch 138/300] Batch 400 | G Loss: 0.9555 | D Loss: 1.2395 | LR: 0.031007 | Momentum: 0.6088\n",
      "[Epoch 138/300] Batch 500 | G Loss: 0.9003 | D Loss: 1.1263 | LR: 0.030995 | Momentum: 0.6088\n",
      "[Epoch 138/300] Batch 600 | G Loss: 0.9705 | D Loss: 1.1265 | LR: 0.030982 | Momentum: 0.6088\n",
      "[Epoch 138/300] Batch 700 | G Loss: 0.9365 | D Loss: 1.1374 | LR: 0.030970 | Momentum: 0.6088\n",
      "[Epoch 138/300] Batch 800 | G Loss: 0.8469 | D Loss: 1.1990 | LR: 0.030957 | Momentum: 0.6088\n",
      "[Epoch 139/300] Batch 0 | G Loss: 0.9387 | D Loss: 1.2437 | LR: 0.030949 | Momentum: 0.6096\n",
      "[Epoch 139/300] Batch 100 | G Loss: 0.8691 | D Loss: 1.2081 | LR: 0.030936 | Momentum: 0.6096\n",
      "[Epoch 139/300] Batch 200 | G Loss: 0.9078 | D Loss: 1.2118 | LR: 0.030924 | Momentum: 0.6096\n",
      "[Epoch 139/300] Batch 300 | G Loss: 0.9449 | D Loss: 1.2195 | LR: 0.030912 | Momentum: 0.6096\n",
      "[Epoch 139/300] Batch 400 | G Loss: 1.0072 | D Loss: 1.1419 | LR: 0.030899 | Momentum: 0.6096\n",
      "[Epoch 139/300] Batch 500 | G Loss: 0.9516 | D Loss: 1.1833 | LR: 0.030887 | Momentum: 0.6096\n",
      "[Epoch 139/300] Batch 600 | G Loss: 0.8676 | D Loss: 1.2600 | LR: 0.030875 | Momentum: 0.6096\n",
      "[Epoch 139/300] Batch 700 | G Loss: 0.9010 | D Loss: 1.1008 | LR: 0.030862 | Momentum: 0.6096\n",
      "[Epoch 139/300] Batch 800 | G Loss: 0.9111 | D Loss: 1.1675 | LR: 0.030850 | Momentum: 0.6096\n",
      "[Epoch 140/300] Batch 0 | G Loss: 0.9275 | D Loss: 1.1187 | LR: 0.030841 | Momentum: 0.6104\n",
      "[Epoch 140/300] Batch 100 | G Loss: 0.8657 | D Loss: 1.2356 | LR: 0.030829 | Momentum: 0.6104\n",
      "[Epoch 140/300] Batch 200 | G Loss: 0.9170 | D Loss: 1.1620 | LR: 0.030817 | Momentum: 0.6104\n",
      "[Epoch 140/300] Batch 300 | G Loss: 0.9002 | D Loss: 1.1842 | LR: 0.030804 | Momentum: 0.6104\n",
      "[Epoch 140/300] Batch 400 | G Loss: 0.9451 | D Loss: 1.1114 | LR: 0.030792 | Momentum: 0.6104\n",
      "[Epoch 140/300] Batch 500 | G Loss: 0.9558 | D Loss: 1.1300 | LR: 0.030780 | Momentum: 0.6104\n",
      "[Epoch 140/300] Batch 600 | G Loss: 0.9982 | D Loss: 1.1787 | LR: 0.030768 | Momentum: 0.6104\n",
      "[Epoch 140/300] Batch 700 | G Loss: 0.9075 | D Loss: 1.1684 | LR: 0.030755 | Momentum: 0.6104\n",
      "[Epoch 140/300] Batch 800 | G Loss: 0.9193 | D Loss: 1.1330 | LR: 0.030743 | Momentum: 0.6104\n",
      "[Epoch 141/300] Batch 0 | G Loss: 0.9599 | D Loss: 1.1274 | LR: 0.030734 | Momentum: 0.6112\n",
      "[Epoch 141/300] Batch 100 | G Loss: 0.9974 | D Loss: 1.1778 | LR: 0.030722 | Momentum: 0.6112\n",
      "[Epoch 141/300] Batch 200 | G Loss: 0.9315 | D Loss: 1.1332 | LR: 0.030710 | Momentum: 0.6112\n",
      "[Epoch 141/300] Batch 300 | G Loss: 1.0284 | D Loss: 1.1613 | LR: 0.030698 | Momentum: 0.6112\n",
      "[Epoch 141/300] Batch 400 | G Loss: 0.9081 | D Loss: 1.1802 | LR: 0.030685 | Momentum: 0.6112\n",
      "[Epoch 141/300] Batch 500 | G Loss: 0.8636 | D Loss: 1.1429 | LR: 0.030673 | Momentum: 0.6112\n",
      "[Epoch 141/300] Batch 600 | G Loss: 0.9266 | D Loss: 1.2638 | LR: 0.030661 | Momentum: 0.6112\n",
      "[Epoch 141/300] Batch 700 | G Loss: 0.9445 | D Loss: 1.2243 | LR: 0.030649 | Momentum: 0.6112\n",
      "[Epoch 141/300] Batch 800 | G Loss: 1.0526 | D Loss: 1.1319 | LR: 0.030636 | Momentum: 0.6112\n",
      "[Epoch 142/300] Batch 0 | G Loss: 0.9432 | D Loss: 1.1491 | LR: 0.030628 | Momentum: 0.6120\n",
      "[Epoch 142/300] Batch 100 | G Loss: 0.9864 | D Loss: 1.2356 | LR: 0.030616 | Momentum: 0.6120\n",
      "[Epoch 142/300] Batch 200 | G Loss: 0.9137 | D Loss: 1.1795 | LR: 0.030603 | Momentum: 0.6120\n",
      "[Epoch 142/300] Batch 300 | G Loss: 0.9197 | D Loss: 1.1986 | LR: 0.030591 | Momentum: 0.6120\n",
      "[Epoch 142/300] Batch 400 | G Loss: 0.8627 | D Loss: 1.2175 | LR: 0.030579 | Momentum: 0.6120\n",
      "[Epoch 142/300] Batch 500 | G Loss: 0.8853 | D Loss: 1.1682 | LR: 0.030567 | Momentum: 0.6120\n",
      "[Epoch 142/300] Batch 600 | G Loss: 0.8967 | D Loss: 1.1335 | LR: 0.030554 | Momentum: 0.6120\n",
      "[Epoch 142/300] Batch 700 | G Loss: 0.9084 | D Loss: 1.1637 | LR: 0.030542 | Momentum: 0.6120\n",
      "[Epoch 142/300] Batch 800 | G Loss: 0.9140 | D Loss: 1.1421 | LR: 0.030530 | Momentum: 0.6120\n",
      "[Epoch 143/300] Batch 0 | G Loss: 0.9766 | D Loss: 1.1118 | LR: 0.030522 | Momentum: 0.6128\n",
      "[Epoch 143/300] Batch 100 | G Loss: 0.8989 | D Loss: 1.1466 | LR: 0.030509 | Momentum: 0.6128\n",
      "[Epoch 143/300] Batch 200 | G Loss: 0.9441 | D Loss: 1.1636 | LR: 0.030497 | Momentum: 0.6128\n",
      "[Epoch 143/300] Batch 300 | G Loss: 0.9444 | D Loss: 1.1800 | LR: 0.030485 | Momentum: 0.6128\n",
      "[Epoch 143/300] Batch 400 | G Loss: 0.9716 | D Loss: 1.1724 | LR: 0.030473 | Momentum: 0.6128\n",
      "[Epoch 143/300] Batch 500 | G Loss: 0.9052 | D Loss: 1.2260 | LR: 0.030461 | Momentum: 0.6128\n",
      "[Epoch 143/300] Batch 600 | G Loss: 0.9061 | D Loss: 1.1172 | LR: 0.030448 | Momentum: 0.6128\n",
      "[Epoch 143/300] Batch 700 | G Loss: 0.9320 | D Loss: 1.1708 | LR: 0.030436 | Momentum: 0.6128\n",
      "[Epoch 143/300] Batch 800 | G Loss: 0.9095 | D Loss: 1.2408 | LR: 0.030424 | Momentum: 0.6128\n",
      "[Epoch 144/300] Batch 0 | G Loss: 0.9004 | D Loss: 1.2298 | LR: 0.030416 | Momentum: 0.6136\n",
      "[Epoch 144/300] Batch 100 | G Loss: 1.0319 | D Loss: 1.0904 | LR: 0.030403 | Momentum: 0.6136\n",
      "[Epoch 144/300] Batch 200 | G Loss: 0.9110 | D Loss: 1.2654 | LR: 0.030391 | Momentum: 0.6136\n",
      "[Epoch 144/300] Batch 300 | G Loss: 0.9764 | D Loss: 1.1526 | LR: 0.030379 | Momentum: 0.6136\n",
      "[Epoch 144/300] Batch 400 | G Loss: 0.9255 | D Loss: 1.1838 | LR: 0.030367 | Momentum: 0.6136\n",
      "[Epoch 144/300] Batch 500 | G Loss: 1.0240 | D Loss: 1.1778 | LR: 0.030355 | Momentum: 0.6136\n",
      "[Epoch 144/300] Batch 600 | G Loss: 0.8993 | D Loss: 1.2039 | LR: 0.030343 | Momentum: 0.6136\n",
      "[Epoch 144/300] Batch 700 | G Loss: 0.9202 | D Loss: 1.2003 | LR: 0.030331 | Momentum: 0.6136\n",
      "[Epoch 144/300] Batch 800 | G Loss: 0.9215 | D Loss: 1.1882 | LR: 0.030318 | Momentum: 0.6136\n",
      "[Epoch 145/300] Batch 0 | G Loss: 0.9773 | D Loss: 1.2100 | LR: 0.030310 | Momentum: 0.6144\n",
      "[Epoch 145/300] Batch 100 | G Loss: 0.9484 | D Loss: 1.1488 | LR: 0.030298 | Momentum: 0.6144\n",
      "[Epoch 145/300] Batch 200 | G Loss: 0.9085 | D Loss: 1.1542 | LR: 0.030286 | Momentum: 0.6144\n",
      "[Epoch 145/300] Batch 300 | G Loss: 0.9376 | D Loss: 1.2265 | LR: 0.030274 | Momentum: 0.6144\n",
      "[Epoch 145/300] Batch 400 | G Loss: 0.9608 | D Loss: 1.1183 | LR: 0.030262 | Momentum: 0.6144\n",
      "[Epoch 145/300] Batch 500 | G Loss: 0.9184 | D Loss: 1.1807 | LR: 0.030250 | Momentum: 0.6144\n",
      "[Epoch 145/300] Batch 600 | G Loss: 0.9664 | D Loss: 1.1934 | LR: 0.030237 | Momentum: 0.6144\n",
      "[Epoch 145/300] Batch 700 | G Loss: 0.9637 | D Loss: 1.1641 | LR: 0.030225 | Momentum: 0.6144\n",
      "[Epoch 145/300] Batch 800 | G Loss: 0.8856 | D Loss: 1.2051 | LR: 0.030213 | Momentum: 0.6144\n",
      "[Epoch 146/300] Batch 0 | G Loss: 0.9131 | D Loss: 1.2354 | LR: 0.030205 | Momentum: 0.6152\n",
      "[Epoch 146/300] Batch 100 | G Loss: 0.9522 | D Loss: 1.1582 | LR: 0.030193 | Momentum: 0.6152\n",
      "[Epoch 146/300] Batch 200 | G Loss: 0.9378 | D Loss: 1.2260 | LR: 0.030181 | Momentum: 0.6152\n",
      "[Epoch 146/300] Batch 300 | G Loss: 0.9764 | D Loss: 1.1809 | LR: 0.030169 | Momentum: 0.6152\n",
      "[Epoch 146/300] Batch 400 | G Loss: 0.8716 | D Loss: 1.1696 | LR: 0.030157 | Momentum: 0.6152\n",
      "[Epoch 146/300] Batch 500 | G Loss: 0.9494 | D Loss: 1.1490 | LR: 0.030145 | Momentum: 0.6152\n",
      "[Epoch 146/300] Batch 600 | G Loss: 0.9188 | D Loss: 1.2535 | LR: 0.030132 | Momentum: 0.6152\n",
      "[Epoch 146/300] Batch 700 | G Loss: 0.9246 | D Loss: 1.2004 | LR: 0.030120 | Momentum: 0.6152\n",
      "[Epoch 146/300] Batch 800 | G Loss: 0.9096 | D Loss: 1.1347 | LR: 0.030108 | Momentum: 0.6152\n",
      "[Epoch 147/300] Batch 0 | G Loss: 0.9094 | D Loss: 1.1265 | LR: 0.030100 | Momentum: 0.6160\n",
      "[Epoch 147/300] Batch 100 | G Loss: 0.9921 | D Loss: 1.1775 | LR: 0.030088 | Momentum: 0.6160\n",
      "[Epoch 147/300] Batch 200 | G Loss: 0.9019 | D Loss: 1.1978 | LR: 0.030076 | Momentum: 0.6160\n",
      "[Epoch 147/300] Batch 300 | G Loss: 0.9521 | D Loss: 1.1990 | LR: 0.030064 | Momentum: 0.6160\n",
      "[Epoch 147/300] Batch 400 | G Loss: 0.9937 | D Loss: 1.1856 | LR: 0.030052 | Momentum: 0.6160\n",
      "[Epoch 147/300] Batch 500 | G Loss: 0.9381 | D Loss: 1.1655 | LR: 0.030040 | Momentum: 0.6160\n",
      "[Epoch 147/300] Batch 600 | G Loss: 1.0049 | D Loss: 1.1913 | LR: 0.030028 | Momentum: 0.6160\n",
      "[Epoch 147/300] Batch 700 | G Loss: 0.9650 | D Loss: 1.2241 | LR: 0.030016 | Momentum: 0.6160\n",
      "[Epoch 147/300] Batch 800 | G Loss: 0.9432 | D Loss: 1.2028 | LR: 0.030004 | Momentum: 0.6160\n",
      "[Epoch 148/300] Batch 0 | G Loss: 0.8787 | D Loss: 1.2067 | LR: 0.029996 | Momentum: 0.6168\n",
      "[Epoch 148/300] Batch 100 | G Loss: 0.9024 | D Loss: 1.1895 | LR: 0.029984 | Momentum: 0.6168\n",
      "[Epoch 148/300] Batch 200 | G Loss: 0.9682 | D Loss: 1.2124 | LR: 0.029972 | Momentum: 0.6168\n",
      "[Epoch 148/300] Batch 300 | G Loss: 1.0266 | D Loss: 1.2535 | LR: 0.029960 | Momentum: 0.6168\n",
      "[Epoch 148/300] Batch 400 | G Loss: 0.9653 | D Loss: 1.1247 | LR: 0.029948 | Momentum: 0.6168\n",
      "[Epoch 148/300] Batch 500 | G Loss: 0.9029 | D Loss: 1.2844 | LR: 0.029936 | Momentum: 0.6168\n",
      "[Epoch 148/300] Batch 600 | G Loss: 0.9656 | D Loss: 1.1949 | LR: 0.029924 | Momentum: 0.6168\n",
      "[Epoch 148/300] Batch 700 | G Loss: 1.1385 | D Loss: 1.2192 | LR: 0.029912 | Momentum: 0.6168\n",
      "[Epoch 148/300] Batch 800 | G Loss: 0.9600 | D Loss: 1.1341 | LR: 0.029900 | Momentum: 0.6168\n",
      "[Epoch 149/300] Batch 0 | G Loss: 1.0025 | D Loss: 1.1593 | LR: 0.029892 | Momentum: 0.6176\n",
      "[Epoch 149/300] Batch 100 | G Loss: 0.9506 | D Loss: 1.1430 | LR: 0.029880 | Momentum: 0.6176\n",
      "[Epoch 149/300] Batch 200 | G Loss: 0.9492 | D Loss: 1.1688 | LR: 0.029868 | Momentum: 0.6176\n",
      "[Epoch 149/300] Batch 300 | G Loss: 0.9694 | D Loss: 1.2490 | LR: 0.029856 | Momentum: 0.6176\n",
      "[Epoch 149/300] Batch 400 | G Loss: 0.9696 | D Loss: 1.0957 | LR: 0.029844 | Momentum: 0.6176\n",
      "[Epoch 149/300] Batch 500 | G Loss: 0.9023 | D Loss: 1.1855 | LR: 0.029832 | Momentum: 0.6176\n",
      "[Epoch 149/300] Batch 600 | G Loss: 0.9544 | D Loss: 1.1203 | LR: 0.029820 | Momentum: 0.6176\n",
      "[Epoch 149/300] Batch 700 | G Loss: 0.8971 | D Loss: 1.1537 | LR: 0.029808 | Momentum: 0.6176\n",
      "[Epoch 149/300] Batch 800 | G Loss: 0.9680 | D Loss: 1.1729 | LR: 0.029796 | Momentum: 0.6176\n",
      "[Epoch 150/300] Batch 0 | G Loss: 0.9252 | D Loss: 1.1177 | LR: 0.029788 | Momentum: 0.6184\n",
      "[Epoch 150/300] Batch 100 | G Loss: 0.9542 | D Loss: 1.1900 | LR: 0.029776 | Momentum: 0.6184\n",
      "[Epoch 150/300] Batch 200 | G Loss: 0.9456 | D Loss: 1.2123 | LR: 0.029764 | Momentum: 0.6184\n",
      "[Epoch 150/300] Batch 300 | G Loss: 0.9257 | D Loss: 1.1858 | LR: 0.029752 | Momentum: 0.6184\n",
      "[Epoch 150/300] Batch 400 | G Loss: 0.8471 | D Loss: 1.0912 | LR: 0.029740 | Momentum: 0.6184\n",
      "[Epoch 150/300] Batch 500 | G Loss: 0.9570 | D Loss: 1.1493 | LR: 0.029728 | Momentum: 0.6184\n",
      "[Epoch 150/300] Batch 600 | G Loss: 0.9558 | D Loss: 1.1522 | LR: 0.029716 | Momentum: 0.6184\n",
      "[Epoch 150/300] Batch 700 | G Loss: 0.9730 | D Loss: 1.2049 | LR: 0.029705 | Momentum: 0.6184\n",
      "[Epoch 150/300] Batch 800 | G Loss: 0.9456 | D Loss: 1.2261 | LR: 0.029693 | Momentum: 0.6184\n",
      "[Epoch 151/300] Batch 0 | G Loss: 0.9128 | D Loss: 1.2292 | LR: 0.029684 | Momentum: 0.6192\n",
      "[Epoch 151/300] Batch 100 | G Loss: 0.9197 | D Loss: 1.2520 | LR: 0.029673 | Momentum: 0.6192\n",
      "[Epoch 151/300] Batch 200 | G Loss: 0.9716 | D Loss: 1.1359 | LR: 0.029661 | Momentum: 0.6192\n",
      "[Epoch 151/300] Batch 300 | G Loss: 0.8956 | D Loss: 1.1935 | LR: 0.029649 | Momentum: 0.6192\n",
      "[Epoch 151/300] Batch 400 | G Loss: 0.8911 | D Loss: 1.1630 | LR: 0.029637 | Momentum: 0.6192\n",
      "[Epoch 151/300] Batch 500 | G Loss: 0.8542 | D Loss: 1.2084 | LR: 0.029625 | Momentum: 0.6192\n",
      "[Epoch 151/300] Batch 600 | G Loss: 0.9309 | D Loss: 1.2919 | LR: 0.029613 | Momentum: 0.6192\n",
      "[Epoch 151/300] Batch 700 | G Loss: 0.9557 | D Loss: 1.1583 | LR: 0.029601 | Momentum: 0.6192\n",
      "[Epoch 151/300] Batch 800 | G Loss: 0.9696 | D Loss: 1.1302 | LR: 0.029590 | Momentum: 0.6192\n",
      "[Epoch 152/300] Batch 0 | G Loss: 0.9521 | D Loss: 1.1161 | LR: 0.029581 | Momentum: 0.6200\n",
      "[Epoch 152/300] Batch 100 | G Loss: 0.9277 | D Loss: 1.2572 | LR: 0.029570 | Momentum: 0.6200\n",
      "[Epoch 152/300] Batch 200 | G Loss: 0.8619 | D Loss: 1.2370 | LR: 0.029558 | Momentum: 0.6200\n",
      "[Epoch 152/300] Batch 300 | G Loss: 0.8931 | D Loss: 1.2345 | LR: 0.029546 | Momentum: 0.6200\n",
      "[Epoch 152/300] Batch 400 | G Loss: 0.9670 | D Loss: 1.1681 | LR: 0.029534 | Momentum: 0.6200\n",
      "[Epoch 152/300] Batch 500 | G Loss: 0.9331 | D Loss: 1.0740 | LR: 0.029522 | Momentum: 0.6200\n",
      "[Epoch 152/300] Batch 600 | G Loss: 0.8805 | D Loss: 1.1706 | LR: 0.029511 | Momentum: 0.6200\n",
      "[Epoch 152/300] Batch 700 | G Loss: 0.9285 | D Loss: 1.1785 | LR: 0.029499 | Momentum: 0.6200\n",
      "[Epoch 152/300] Batch 800 | G Loss: 0.9744 | D Loss: 1.0787 | LR: 0.029487 | Momentum: 0.6200\n",
      "[Epoch 153/300] Batch 0 | G Loss: 0.9221 | D Loss: 1.1843 | LR: 0.029479 | Momentum: 0.6208\n",
      "[Epoch 153/300] Batch 100 | G Loss: 0.9514 | D Loss: 1.1650 | LR: 0.029467 | Momentum: 0.6208\n",
      "[Epoch 153/300] Batch 200 | G Loss: 0.9166 | D Loss: 1.2073 | LR: 0.029455 | Momentum: 0.6208\n",
      "[Epoch 153/300] Batch 300 | G Loss: 0.9142 | D Loss: 1.1899 | LR: 0.029443 | Momentum: 0.6208\n",
      "[Epoch 153/300] Batch 400 | G Loss: 1.0001 | D Loss: 1.0446 | LR: 0.029432 | Momentum: 0.6208\n",
      "[Epoch 153/300] Batch 500 | G Loss: 1.0104 | D Loss: 1.1490 | LR: 0.029420 | Momentum: 0.6208\n",
      "[Epoch 153/300] Batch 600 | G Loss: 1.0088 | D Loss: 1.1569 | LR: 0.029408 | Momentum: 0.6208\n",
      "[Epoch 153/300] Batch 700 | G Loss: 0.9162 | D Loss: 1.2590 | LR: 0.029396 | Momentum: 0.6208\n",
      "[Epoch 153/300] Batch 800 | G Loss: 0.9345 | D Loss: 1.1541 | LR: 0.029385 | Momentum: 0.6208\n",
      "[Epoch 154/300] Batch 0 | G Loss: 0.8750 | D Loss: 1.1114 | LR: 0.029377 | Momentum: 0.6216\n",
      "[Epoch 154/300] Batch 100 | G Loss: 0.9227 | D Loss: 1.1372 | LR: 0.029365 | Momentum: 0.6216\n",
      "[Epoch 154/300] Batch 200 | G Loss: 0.9576 | D Loss: 1.1579 | LR: 0.029353 | Momentum: 0.6216\n",
      "[Epoch 154/300] Batch 300 | G Loss: 0.9732 | D Loss: 1.1958 | LR: 0.029341 | Momentum: 0.6216\n",
      "[Epoch 154/300] Batch 400 | G Loss: 0.9383 | D Loss: 1.1671 | LR: 0.029330 | Momentum: 0.6216\n",
      "[Epoch 154/300] Batch 500 | G Loss: 1.0274 | D Loss: 1.1525 | LR: 0.029318 | Momentum: 0.6216\n",
      "[Epoch 154/300] Batch 600 | G Loss: 0.9436 | D Loss: 1.0903 | LR: 0.029306 | Momentum: 0.6216\n",
      "[Epoch 154/300] Batch 700 | G Loss: 0.9953 | D Loss: 1.1068 | LR: 0.029294 | Momentum: 0.6216\n",
      "[Epoch 154/300] Batch 800 | G Loss: 0.9643 | D Loss: 1.1316 | LR: 0.029283 | Momentum: 0.6216\n",
      "[Epoch 155/300] Batch 0 | G Loss: 0.9281 | D Loss: 1.1536 | LR: 0.029275 | Momentum: 0.6224\n",
      "[Epoch 155/300] Batch 100 | G Loss: 0.9266 | D Loss: 1.0691 | LR: 0.029263 | Momentum: 0.6224\n",
      "[Epoch 155/300] Batch 200 | G Loss: 0.9694 | D Loss: 1.1309 | LR: 0.029251 | Momentum: 0.6224\n",
      "[Epoch 155/300] Batch 300 | G Loss: 0.9290 | D Loss: 1.2187 | LR: 0.029239 | Momentum: 0.6224\n",
      "[Epoch 155/300] Batch 400 | G Loss: 0.9781 | D Loss: 1.1687 | LR: 0.029228 | Momentum: 0.6224\n",
      "[Epoch 155/300] Batch 500 | G Loss: 0.9308 | D Loss: 1.2108 | LR: 0.029216 | Momentum: 0.6224\n",
      "[Epoch 155/300] Batch 600 | G Loss: 0.9184 | D Loss: 1.2194 | LR: 0.029204 | Momentum: 0.6224\n",
      "[Epoch 155/300] Batch 700 | G Loss: 0.9281 | D Loss: 1.2297 | LR: 0.029193 | Momentum: 0.6224\n",
      "[Epoch 155/300] Batch 800 | G Loss: 0.9870 | D Loss: 1.2711 | LR: 0.029181 | Momentum: 0.6224\n",
      "[Epoch 156/300] Batch 0 | G Loss: 0.8789 | D Loss: 1.1156 | LR: 0.029173 | Momentum: 0.6232\n",
      "[Epoch 156/300] Batch 100 | G Loss: 0.9541 | D Loss: 1.1997 | LR: 0.029161 | Momentum: 0.6232\n",
      "[Epoch 156/300] Batch 200 | G Loss: 0.9463 | D Loss: 1.3118 | LR: 0.029150 | Momentum: 0.6232\n",
      "[Epoch 156/300] Batch 300 | G Loss: 0.8845 | D Loss: 1.2088 | LR: 0.029138 | Momentum: 0.6232\n",
      "[Epoch 156/300] Batch 400 | G Loss: 0.9627 | D Loss: 1.2244 | LR: 0.029126 | Momentum: 0.6232\n",
      "[Epoch 156/300] Batch 500 | G Loss: 0.9886 | D Loss: 1.3204 | LR: 0.029115 | Momentum: 0.6232\n",
      "[Epoch 156/300] Batch 600 | G Loss: 0.9892 | D Loss: 1.2253 | LR: 0.029103 | Momentum: 0.6232\n",
      "[Epoch 156/300] Batch 700 | G Loss: 0.9532 | D Loss: 1.1868 | LR: 0.029091 | Momentum: 0.6232\n",
      "[Epoch 156/300] Batch 800 | G Loss: 0.9287 | D Loss: 1.1394 | LR: 0.029080 | Momentum: 0.6232\n",
      "[Epoch 157/300] Batch 0 | G Loss: 1.0049 | D Loss: 1.1428 | LR: 0.029072 | Momentum: 0.6240\n",
      "[Epoch 157/300] Batch 100 | G Loss: 0.9159 | D Loss: 1.1248 | LR: 0.029060 | Momentum: 0.6240\n",
      "[Epoch 157/300] Batch 200 | G Loss: 0.9643 | D Loss: 1.1477 | LR: 0.029049 | Momentum: 0.6240\n",
      "[Epoch 157/300] Batch 300 | G Loss: 0.9030 | D Loss: 1.1934 | LR: 0.029037 | Momentum: 0.6240\n",
      "[Epoch 157/300] Batch 400 | G Loss: 0.9267 | D Loss: 1.2316 | LR: 0.029025 | Momentum: 0.6240\n",
      "[Epoch 157/300] Batch 500 | G Loss: 0.9032 | D Loss: 1.3060 | LR: 0.029014 | Momentum: 0.6240\n",
      "[Epoch 157/300] Batch 600 | G Loss: 1.0203 | D Loss: 1.1311 | LR: 0.029002 | Momentum: 0.6240\n",
      "[Epoch 157/300] Batch 700 | G Loss: 0.9423 | D Loss: 1.1770 | LR: 0.028990 | Momentum: 0.6240\n",
      "[Epoch 157/300] Batch 800 | G Loss: 0.9303 | D Loss: 1.1231 | LR: 0.028979 | Momentum: 0.6240\n",
      "[Epoch 158/300] Batch 0 | G Loss: 0.9309 | D Loss: 1.1318 | LR: 0.028971 | Momentum: 0.6248\n",
      "[Epoch 158/300] Batch 100 | G Loss: 0.9329 | D Loss: 1.1335 | LR: 0.028959 | Momentum: 0.6248\n",
      "[Epoch 158/300] Batch 200 | G Loss: 0.9705 | D Loss: 1.1741 | LR: 0.028948 | Momentum: 0.6248\n",
      "[Epoch 158/300] Batch 300 | G Loss: 0.8775 | D Loss: 1.0884 | LR: 0.028936 | Momentum: 0.6248\n",
      "[Epoch 158/300] Batch 400 | G Loss: 0.8856 | D Loss: 1.2293 | LR: 0.028925 | Momentum: 0.6248\n",
      "[Epoch 158/300] Batch 500 | G Loss: 0.8605 | D Loss: 1.2484 | LR: 0.028913 | Momentum: 0.6248\n",
      "[Epoch 158/300] Batch 600 | G Loss: 0.8935 | D Loss: 1.2761 | LR: 0.028901 | Momentum: 0.6248\n",
      "[Epoch 158/300] Batch 700 | G Loss: 0.8575 | D Loss: 1.1682 | LR: 0.028890 | Momentum: 0.6248\n",
      "[Epoch 158/300] Batch 800 | G Loss: 0.9018 | D Loss: 1.2686 | LR: 0.028878 | Momentum: 0.6248\n",
      "[Epoch 159/300] Batch 0 | G Loss: 0.9186 | D Loss: 1.2124 | LR: 0.028870 | Momentum: 0.6256\n",
      "[Epoch 159/300] Batch 100 | G Loss: 0.9081 | D Loss: 1.1137 | LR: 0.028859 | Momentum: 0.6256\n",
      "[Epoch 159/300] Batch 200 | G Loss: 0.9797 | D Loss: 1.1937 | LR: 0.028847 | Momentum: 0.6256\n",
      "[Epoch 159/300] Batch 300 | G Loss: 0.9505 | D Loss: 1.1692 | LR: 0.028836 | Momentum: 0.6256\n",
      "[Epoch 159/300] Batch 400 | G Loss: 0.9058 | D Loss: 1.1372 | LR: 0.028824 | Momentum: 0.6256\n",
      "[Epoch 159/300] Batch 500 | G Loss: 0.9485 | D Loss: 1.1702 | LR: 0.028813 | Momentum: 0.6256\n",
      "[Epoch 159/300] Batch 600 | G Loss: 0.8982 | D Loss: 1.1893 | LR: 0.028801 | Momentum: 0.6256\n",
      "[Epoch 159/300] Batch 700 | G Loss: 0.9467 | D Loss: 1.0958 | LR: 0.028790 | Momentum: 0.6256\n",
      "[Epoch 159/300] Batch 800 | G Loss: 0.9404 | D Loss: 1.1966 | LR: 0.028778 | Momentum: 0.6256\n",
      "[Epoch 160/300] Batch 0 | G Loss: 0.9392 | D Loss: 1.2698 | LR: 0.028770 | Momentum: 0.6264\n",
      "[Epoch 160/300] Batch 100 | G Loss: 0.9579 | D Loss: 1.1760 | LR: 0.028759 | Momentum: 0.6264\n",
      "[Epoch 160/300] Batch 200 | G Loss: 0.9315 | D Loss: 1.2465 | LR: 0.028747 | Momentum: 0.6264\n",
      "[Epoch 160/300] Batch 300 | G Loss: 0.9235 | D Loss: 1.1611 | LR: 0.028736 | Momentum: 0.6264\n",
      "[Epoch 160/300] Batch 400 | G Loss: 0.9729 | D Loss: 1.1741 | LR: 0.028724 | Momentum: 0.6264\n",
      "[Epoch 160/300] Batch 500 | G Loss: 0.9662 | D Loss: 1.1475 | LR: 0.028713 | Momentum: 0.6264\n",
      "[Epoch 160/300] Batch 600 | G Loss: 1.0001 | D Loss: 1.2810 | LR: 0.028701 | Momentum: 0.6264\n",
      "[Epoch 160/300] Batch 700 | G Loss: 0.9085 | D Loss: 1.2420 | LR: 0.028690 | Momentum: 0.6264\n",
      "[Epoch 160/300] Batch 800 | G Loss: 0.9203 | D Loss: 1.2522 | LR: 0.028678 | Momentum: 0.6264\n",
      "[Epoch 161/300] Batch 0 | G Loss: 0.9527 | D Loss: 1.1665 | LR: 0.028670 | Momentum: 0.6272\n",
      "[Epoch 161/300] Batch 100 | G Loss: 0.9653 | D Loss: 1.1852 | LR: 0.028659 | Momentum: 0.6272\n",
      "[Epoch 161/300] Batch 200 | G Loss: 0.9870 | D Loss: 1.1458 | LR: 0.028647 | Momentum: 0.6272\n",
      "[Epoch 161/300] Batch 300 | G Loss: 0.9198 | D Loss: 1.1954 | LR: 0.028636 | Momentum: 0.6272\n",
      "[Epoch 161/300] Batch 400 | G Loss: 1.0016 | D Loss: 1.1871 | LR: 0.028625 | Momentum: 0.6272\n",
      "[Epoch 161/300] Batch 500 | G Loss: 0.9482 | D Loss: 1.1750 | LR: 0.028613 | Momentum: 0.6272\n",
      "[Epoch 161/300] Batch 600 | G Loss: 0.8992 | D Loss: 1.1930 | LR: 0.028602 | Momentum: 0.6272\n",
      "[Epoch 161/300] Batch 700 | G Loss: 0.9519 | D Loss: 1.0816 | LR: 0.028590 | Momentum: 0.6272\n",
      "[Epoch 161/300] Batch 800 | G Loss: 0.9832 | D Loss: 1.0985 | LR: 0.028579 | Momentum: 0.6272\n",
      "[Epoch 162/300] Batch 0 | G Loss: 0.9476 | D Loss: 1.2228 | LR: 0.028571 | Momentum: 0.6280\n",
      "[Epoch 162/300] Batch 100 | G Loss: 0.9415 | D Loss: 1.0557 | LR: 0.028559 | Momentum: 0.6280\n",
      "[Epoch 162/300] Batch 200 | G Loss: 0.9579 | D Loss: 1.1988 | LR: 0.028548 | Momentum: 0.6280\n",
      "[Epoch 162/300] Batch 300 | G Loss: 0.8524 | D Loss: 1.1677 | LR: 0.028537 | Momentum: 0.6280\n",
      "[Epoch 162/300] Batch 400 | G Loss: 0.9695 | D Loss: 1.1940 | LR: 0.028525 | Momentum: 0.6280\n",
      "[Epoch 162/300] Batch 500 | G Loss: 0.9223 | D Loss: 1.1320 | LR: 0.028514 | Momentum: 0.6280\n",
      "[Epoch 162/300] Batch 600 | G Loss: 0.9175 | D Loss: 1.2077 | LR: 0.028502 | Momentum: 0.6280\n",
      "[Epoch 162/300] Batch 700 | G Loss: 0.9866 | D Loss: 1.1616 | LR: 0.028491 | Momentum: 0.6280\n",
      "[Epoch 162/300] Batch 800 | G Loss: 0.9376 | D Loss: 1.2271 | LR: 0.028480 | Momentum: 0.6280\n",
      "[Epoch 163/300] Batch 0 | G Loss: 0.9129 | D Loss: 1.1670 | LR: 0.028472 | Momentum: 0.6288\n",
      "[Epoch 163/300] Batch 100 | G Loss: 1.0137 | D Loss: 1.1944 | LR: 0.028460 | Momentum: 0.6288\n",
      "[Epoch 163/300] Batch 200 | G Loss: 0.8707 | D Loss: 1.1747 | LR: 0.028449 | Momentum: 0.6288\n",
      "[Epoch 163/300] Batch 300 | G Loss: 0.9735 | D Loss: 1.2878 | LR: 0.028438 | Momentum: 0.6288\n",
      "[Epoch 163/300] Batch 400 | G Loss: 0.9583 | D Loss: 1.1116 | LR: 0.028426 | Momentum: 0.6288\n",
      "[Epoch 163/300] Batch 500 | G Loss: 0.9070 | D Loss: 1.1597 | LR: 0.028415 | Momentum: 0.6288\n",
      "[Epoch 163/300] Batch 600 | G Loss: 0.9965 | D Loss: 1.1086 | LR: 0.028403 | Momentum: 0.6288\n",
      "[Epoch 163/300] Batch 700 | G Loss: 0.9054 | D Loss: 1.2560 | LR: 0.028392 | Momentum: 0.6288\n",
      "[Epoch 163/300] Batch 800 | G Loss: 0.9516 | D Loss: 1.1239 | LR: 0.028381 | Momentum: 0.6288\n",
      "[Epoch 164/300] Batch 0 | G Loss: 0.9733 | D Loss: 1.1269 | LR: 0.028373 | Momentum: 0.6296\n",
      "[Epoch 164/300] Batch 100 | G Loss: 1.0128 | D Loss: 1.1099 | LR: 0.028362 | Momentum: 0.6296\n",
      "[Epoch 164/300] Batch 200 | G Loss: 0.9009 | D Loss: 1.1074 | LR: 0.028350 | Momentum: 0.6296\n",
      "[Epoch 164/300] Batch 300 | G Loss: 0.9185 | D Loss: 1.1545 | LR: 0.028339 | Momentum: 0.6296\n",
      "[Epoch 164/300] Batch 400 | G Loss: 0.9750 | D Loss: 1.3148 | LR: 0.028328 | Momentum: 0.6296\n",
      "[Epoch 164/300] Batch 500 | G Loss: 0.9441 | D Loss: 1.1165 | LR: 0.028316 | Momentum: 0.6296\n",
      "[Epoch 164/300] Batch 600 | G Loss: 0.9392 | D Loss: 1.1537 | LR: 0.028305 | Momentum: 0.6296\n",
      "[Epoch 164/300] Batch 700 | G Loss: 0.9074 | D Loss: 1.1438 | LR: 0.028294 | Momentum: 0.6296\n",
      "[Epoch 164/300] Batch 800 | G Loss: 0.9299 | D Loss: 1.2451 | LR: 0.028282 | Momentum: 0.6296\n",
      "[Epoch 165/300] Batch 0 | G Loss: 0.9497 | D Loss: 1.0768 | LR: 0.028274 | Momentum: 0.6304\n",
      "[Epoch 165/300] Batch 100 | G Loss: 0.9523 | D Loss: 1.1648 | LR: 0.028263 | Momentum: 0.6304\n",
      "[Epoch 165/300] Batch 200 | G Loss: 0.9450 | D Loss: 1.2071 | LR: 0.028252 | Momentum: 0.6304\n",
      "[Epoch 165/300] Batch 300 | G Loss: 0.9007 | D Loss: 1.1561 | LR: 0.028241 | Momentum: 0.6304\n",
      "[Epoch 165/300] Batch 400 | G Loss: 0.9455 | D Loss: 1.0980 | LR: 0.028229 | Momentum: 0.6304\n",
      "[Epoch 165/300] Batch 500 | G Loss: 0.9795 | D Loss: 1.1907 | LR: 0.028218 | Momentum: 0.6304\n",
      "[Epoch 165/300] Batch 600 | G Loss: 0.9872 | D Loss: 1.2243 | LR: 0.028207 | Momentum: 0.6304\n",
      "[Epoch 165/300] Batch 700 | G Loss: 0.9088 | D Loss: 1.1427 | LR: 0.028195 | Momentum: 0.6304\n",
      "[Epoch 165/300] Batch 800 | G Loss: 0.9003 | D Loss: 1.1219 | LR: 0.028184 | Momentum: 0.6304\n",
      "[Epoch 166/300] Batch 0 | G Loss: 1.0163 | D Loss: 1.1568 | LR: 0.028176 | Momentum: 0.6312\n",
      "[Epoch 166/300] Batch 100 | G Loss: 0.9668 | D Loss: 1.2168 | LR: 0.028165 | Momentum: 0.6312\n",
      "[Epoch 166/300] Batch 200 | G Loss: 0.9283 | D Loss: 1.2919 | LR: 0.028154 | Momentum: 0.6312\n",
      "[Epoch 166/300] Batch 300 | G Loss: 0.9747 | D Loss: 1.1355 | LR: 0.028143 | Momentum: 0.6312\n",
      "[Epoch 166/300] Batch 400 | G Loss: 0.9698 | D Loss: 1.1160 | LR: 0.028131 | Momentum: 0.6312\n",
      "[Epoch 166/300] Batch 500 | G Loss: 0.9195 | D Loss: 1.1947 | LR: 0.028120 | Momentum: 0.6312\n",
      "[Epoch 166/300] Batch 600 | G Loss: 0.9461 | D Loss: 1.2337 | LR: 0.028109 | Momentum: 0.6312\n",
      "[Epoch 166/300] Batch 700 | G Loss: 0.9796 | D Loss: 1.3256 | LR: 0.028098 | Momentum: 0.6312\n",
      "[Epoch 166/300] Batch 800 | G Loss: 0.9091 | D Loss: 1.0938 | LR: 0.028086 | Momentum: 0.6312\n",
      "[Epoch 167/300] Batch 0 | G Loss: 0.9386 | D Loss: 1.0649 | LR: 0.028079 | Momentum: 0.6320\n",
      "[Epoch 167/300] Batch 100 | G Loss: 0.9572 | D Loss: 1.1617 | LR: 0.028067 | Momentum: 0.6320\n",
      "[Epoch 167/300] Batch 200 | G Loss: 0.9544 | D Loss: 1.1226 | LR: 0.028056 | Momentum: 0.6320\n",
      "[Epoch 167/300] Batch 300 | G Loss: 0.9453 | D Loss: 1.1828 | LR: 0.028045 | Momentum: 0.6320\n",
      "[Epoch 167/300] Batch 400 | G Loss: 0.9353 | D Loss: 1.1129 | LR: 0.028034 | Momentum: 0.6320\n",
      "[Epoch 167/300] Batch 500 | G Loss: 0.9224 | D Loss: 1.1493 | LR: 0.028023 | Momentum: 0.6320\n",
      "[Epoch 167/300] Batch 600 | G Loss: 0.9244 | D Loss: 1.1894 | LR: 0.028011 | Momentum: 0.6320\n",
      "[Epoch 167/300] Batch 700 | G Loss: 0.9363 | D Loss: 1.1014 | LR: 0.028000 | Momentum: 0.6320\n",
      "[Epoch 167/300] Batch 800 | G Loss: 0.9463 | D Loss: 1.1930 | LR: 0.027989 | Momentum: 0.6320\n",
      "[Epoch 168/300] Batch 0 | G Loss: 0.8858 | D Loss: 1.1206 | LR: 0.027981 | Momentum: 0.6328\n",
      "[Epoch 168/300] Batch 100 | G Loss: 0.9087 | D Loss: 1.1136 | LR: 0.027970 | Momentum: 0.6328\n",
      "[Epoch 168/300] Batch 200 | G Loss: 0.9990 | D Loss: 1.1166 | LR: 0.027959 | Momentum: 0.6328\n",
      "[Epoch 168/300] Batch 300 | G Loss: 0.9486 | D Loss: 1.1977 | LR: 0.027948 | Momentum: 0.6328\n",
      "[Epoch 168/300] Batch 400 | G Loss: 0.9733 | D Loss: 1.1636 | LR: 0.027936 | Momentum: 0.6328\n",
      "[Epoch 168/300] Batch 500 | G Loss: 0.9352 | D Loss: 1.2320 | LR: 0.027925 | Momentum: 0.6328\n",
      "[Epoch 168/300] Batch 600 | G Loss: 0.9331 | D Loss: 1.2467 | LR: 0.027914 | Momentum: 0.6328\n",
      "[Epoch 168/300] Batch 700 | G Loss: 0.9163 | D Loss: 1.0872 | LR: 0.027903 | Momentum: 0.6328\n",
      "[Epoch 168/300] Batch 800 | G Loss: 0.9409 | D Loss: 1.1297 | LR: 0.027892 | Momentum: 0.6328\n",
      "[Epoch 169/300] Batch 0 | G Loss: 0.9179 | D Loss: 1.2197 | LR: 0.027884 | Momentum: 0.6336\n",
      "[Epoch 169/300] Batch 100 | G Loss: 0.8995 | D Loss: 1.1366 | LR: 0.027873 | Momentum: 0.6336\n",
      "[Epoch 169/300] Batch 200 | G Loss: 0.9008 | D Loss: 1.2477 | LR: 0.027862 | Momentum: 0.6336\n",
      "[Epoch 169/300] Batch 300 | G Loss: 1.0099 | D Loss: 1.1758 | LR: 0.027851 | Momentum: 0.6336\n",
      "[Epoch 169/300] Batch 400 | G Loss: 0.9392 | D Loss: 1.0938 | LR: 0.027840 | Momentum: 0.6336\n",
      "[Epoch 169/300] Batch 500 | G Loss: 0.9748 | D Loss: 1.1688 | LR: 0.027828 | Momentum: 0.6336\n",
      "[Epoch 169/300] Batch 600 | G Loss: 0.9812 | D Loss: 1.1755 | LR: 0.027817 | Momentum: 0.6336\n",
      "[Epoch 169/300] Batch 700 | G Loss: 0.9371 | D Loss: 1.2488 | LR: 0.027806 | Momentum: 0.6336\n",
      "[Epoch 169/300] Batch 800 | G Loss: 0.9625 | D Loss: 1.1312 | LR: 0.027795 | Momentum: 0.6336\n",
      "[Epoch 170/300] Batch 0 | G Loss: 0.9136 | D Loss: 1.1626 | LR: 0.027787 | Momentum: 0.6344\n",
      "[Epoch 170/300] Batch 100 | G Loss: 0.9524 | D Loss: 1.1962 | LR: 0.027776 | Momentum: 0.6344\n",
      "[Epoch 170/300] Batch 200 | G Loss: 0.9460 | D Loss: 1.1681 | LR: 0.027765 | Momentum: 0.6344\n",
      "[Epoch 170/300] Batch 300 | G Loss: 0.9897 | D Loss: 1.1436 | LR: 0.027754 | Momentum: 0.6344\n",
      "[Epoch 170/300] Batch 400 | G Loss: 0.9915 | D Loss: 1.2058 | LR: 0.027743 | Momentum: 0.6344\n",
      "[Epoch 170/300] Batch 500 | G Loss: 0.8782 | D Loss: 1.1189 | LR: 0.027732 | Momentum: 0.6344\n",
      "[Epoch 170/300] Batch 600 | G Loss: 0.9460 | D Loss: 1.2426 | LR: 0.027721 | Momentum: 0.6344\n",
      "[Epoch 170/300] Batch 700 | G Loss: 0.9274 | D Loss: 1.1478 | LR: 0.027710 | Momentum: 0.6344\n",
      "[Epoch 170/300] Batch 800 | G Loss: 0.9858 | D Loss: 1.2610 | LR: 0.027699 | Momentum: 0.6344\n",
      "[Epoch 171/300] Batch 0 | G Loss: 0.9332 | D Loss: 1.2122 | LR: 0.027691 | Momentum: 0.6352\n",
      "[Epoch 171/300] Batch 100 | G Loss: 0.9766 | D Loss: 1.1430 | LR: 0.027680 | Momentum: 0.6352\n",
      "[Epoch 171/300] Batch 200 | G Loss: 0.9750 | D Loss: 1.1765 | LR: 0.027669 | Momentum: 0.6352\n",
      "[Epoch 171/300] Batch 300 | G Loss: 0.9660 | D Loss: 1.1415 | LR: 0.027658 | Momentum: 0.6352\n",
      "[Epoch 171/300] Batch 400 | G Loss: 0.9601 | D Loss: 1.1406 | LR: 0.027647 | Momentum: 0.6352\n",
      "[Epoch 171/300] Batch 500 | G Loss: 1.0267 | D Loss: 1.1379 | LR: 0.027636 | Momentum: 0.6352\n",
      "[Epoch 171/300] Batch 600 | G Loss: 0.9591 | D Loss: 1.1770 | LR: 0.027625 | Momentum: 0.6352\n",
      "[Epoch 171/300] Batch 700 | G Loss: 0.9653 | D Loss: 1.2333 | LR: 0.027613 | Momentum: 0.6352\n",
      "[Epoch 171/300] Batch 800 | G Loss: 0.9681 | D Loss: 1.2597 | LR: 0.027602 | Momentum: 0.6352\n",
      "[Epoch 172/300] Batch 0 | G Loss: 0.9380 | D Loss: 1.1418 | LR: 0.027595 | Momentum: 0.6360\n",
      "[Epoch 172/300] Batch 100 | G Loss: 0.9970 | D Loss: 1.1778 | LR: 0.027584 | Momentum: 0.6360\n",
      "[Epoch 172/300] Batch 200 | G Loss: 0.9807 | D Loss: 1.1150 | LR: 0.027573 | Momentum: 0.6360\n",
      "[Epoch 172/300] Batch 300 | G Loss: 0.8744 | D Loss: 1.0839 | LR: 0.027562 | Momentum: 0.6360\n",
      "[Epoch 172/300] Batch 400 | G Loss: 0.8826 | D Loss: 1.2052 | LR: 0.027551 | Momentum: 0.6360\n",
      "[Epoch 172/300] Batch 500 | G Loss: 0.8951 | D Loss: 1.1379 | LR: 0.027540 | Momentum: 0.6360\n",
      "[Epoch 172/300] Batch 600 | G Loss: 0.9335 | D Loss: 1.1378 | LR: 0.027529 | Momentum: 0.6360\n",
      "[Epoch 172/300] Batch 700 | G Loss: 0.9324 | D Loss: 1.1931 | LR: 0.027518 | Momentum: 0.6360\n",
      "[Epoch 172/300] Batch 800 | G Loss: 0.9750 | D Loss: 1.1478 | LR: 0.027507 | Momentum: 0.6360\n",
      "[Epoch 173/300] Batch 0 | G Loss: 0.9092 | D Loss: 1.1045 | LR: 0.027499 | Momentum: 0.6368\n",
      "[Epoch 173/300] Batch 100 | G Loss: 0.9556 | D Loss: 1.2144 | LR: 0.027488 | Momentum: 0.6368\n",
      "[Epoch 173/300] Batch 200 | G Loss: 0.9502 | D Loss: 1.2195 | LR: 0.027477 | Momentum: 0.6368\n",
      "[Epoch 173/300] Batch 300 | G Loss: 0.9236 | D Loss: 1.1698 | LR: 0.027466 | Momentum: 0.6368\n",
      "[Epoch 173/300] Batch 400 | G Loss: 0.9049 | D Loss: 1.2382 | LR: 0.027455 | Momentum: 0.6368\n",
      "[Epoch 173/300] Batch 500 | G Loss: 0.9275 | D Loss: 1.2115 | LR: 0.027444 | Momentum: 0.6368\n",
      "[Epoch 173/300] Batch 600 | G Loss: 0.9101 | D Loss: 1.2235 | LR: 0.027433 | Momentum: 0.6368\n",
      "[Epoch 173/300] Batch 700 | G Loss: 0.8974 | D Loss: 1.2365 | LR: 0.027422 | Momentum: 0.6368\n",
      "[Epoch 173/300] Batch 800 | G Loss: 0.9858 | D Loss: 1.2271 | LR: 0.027411 | Momentum: 0.6368\n",
      "[Epoch 174/300] Batch 0 | G Loss: 1.0108 | D Loss: 1.1382 | LR: 0.027404 | Momentum: 0.6376\n",
      "[Epoch 174/300] Batch 100 | G Loss: 0.9059 | D Loss: 1.1541 | LR: 0.027393 | Momentum: 0.6376\n",
      "[Epoch 174/300] Batch 200 | G Loss: 0.9520 | D Loss: 1.1081 | LR: 0.027382 | Momentum: 0.6376\n",
      "[Epoch 174/300] Batch 300 | G Loss: 0.9590 | D Loss: 1.2093 | LR: 0.027371 | Momentum: 0.6376\n",
      "[Epoch 174/300] Batch 400 | G Loss: 0.8764 | D Loss: 1.2094 | LR: 0.027360 | Momentum: 0.6376\n",
      "[Epoch 174/300] Batch 500 | G Loss: 0.9981 | D Loss: 1.2475 | LR: 0.027349 | Momentum: 0.6376\n",
      "[Epoch 174/300] Batch 600 | G Loss: 0.9306 | D Loss: 1.1177 | LR: 0.027338 | Momentum: 0.6376\n",
      "[Epoch 174/300] Batch 700 | G Loss: 0.9626 | D Loss: 1.2386 | LR: 0.027327 | Momentum: 0.6376\n",
      "[Epoch 174/300] Batch 800 | G Loss: 0.9477 | D Loss: 1.1545 | LR: 0.027316 | Momentum: 0.6376\n",
      "[Epoch 175/300] Batch 0 | G Loss: 0.9635 | D Loss: 1.1340 | LR: 0.027309 | Momentum: 0.6384\n",
      "[Epoch 175/300] Batch 100 | G Loss: 0.9257 | D Loss: 1.1484 | LR: 0.027298 | Momentum: 0.6384\n",
      "[Epoch 175/300] Batch 200 | G Loss: 0.9181 | D Loss: 1.2275 | LR: 0.027287 | Momentum: 0.6384\n",
      "[Epoch 175/300] Batch 300 | G Loss: 0.9400 | D Loss: 1.2004 | LR: 0.027276 | Momentum: 0.6384\n",
      "[Epoch 175/300] Batch 400 | G Loss: 0.9307 | D Loss: 1.2247 | LR: 0.027265 | Momentum: 0.6384\n",
      "[Epoch 175/300] Batch 500 | G Loss: 0.9295 | D Loss: 1.1999 | LR: 0.027254 | Momentum: 0.6384\n",
      "[Epoch 175/300] Batch 600 | G Loss: 1.0445 | D Loss: 1.1978 | LR: 0.027243 | Momentum: 0.6384\n",
      "[Epoch 175/300] Batch 700 | G Loss: 0.8949 | D Loss: 1.1863 | LR: 0.027232 | Momentum: 0.6384\n",
      "[Epoch 175/300] Batch 800 | G Loss: 0.9545 | D Loss: 1.2497 | LR: 0.027221 | Momentum: 0.6384\n",
      "[Epoch 176/300] Batch 0 | G Loss: 0.9449 | D Loss: 1.0899 | LR: 0.027214 | Momentum: 0.6392\n",
      "[Epoch 176/300] Batch 100 | G Loss: 0.9331 | D Loss: 1.1404 | LR: 0.027203 | Momentum: 0.6392\n",
      "[Epoch 176/300] Batch 200 | G Loss: 0.9697 | D Loss: 1.2011 | LR: 0.027192 | Momentum: 0.6392\n",
      "[Epoch 176/300] Batch 300 | G Loss: 0.9892 | D Loss: 1.2573 | LR: 0.027181 | Momentum: 0.6392\n",
      "[Epoch 176/300] Batch 400 | G Loss: 0.8950 | D Loss: 1.2242 | LR: 0.027170 | Momentum: 0.6392\n",
      "[Epoch 176/300] Batch 500 | G Loss: 0.8950 | D Loss: 1.1929 | LR: 0.027159 | Momentum: 0.6392\n",
      "[Epoch 176/300] Batch 600 | G Loss: 0.9731 | D Loss: 1.2011 | LR: 0.027149 | Momentum: 0.6392\n",
      "[Epoch 176/300] Batch 700 | G Loss: 0.9261 | D Loss: 1.1514 | LR: 0.027138 | Momentum: 0.6392\n",
      "[Epoch 176/300] Batch 800 | G Loss: 0.9567 | D Loss: 1.1448 | LR: 0.027127 | Momentum: 0.6392\n",
      "[Epoch 177/300] Batch 0 | G Loss: 0.9662 | D Loss: 1.2820 | LR: 0.027119 | Momentum: 0.6400\n",
      "[Epoch 177/300] Batch 100 | G Loss: 0.9774 | D Loss: 1.1874 | LR: 0.027109 | Momentum: 0.6400\n",
      "[Epoch 177/300] Batch 200 | G Loss: 0.8902 | D Loss: 1.1721 | LR: 0.027098 | Momentum: 0.6400\n",
      "[Epoch 177/300] Batch 300 | G Loss: 0.9226 | D Loss: 1.1758 | LR: 0.027087 | Momentum: 0.6400\n",
      "[Epoch 177/300] Batch 400 | G Loss: 0.9069 | D Loss: 1.1438 | LR: 0.027076 | Momentum: 0.6400\n",
      "[Epoch 177/300] Batch 500 | G Loss: 0.8765 | D Loss: 1.1628 | LR: 0.027065 | Momentum: 0.6400\n",
      "[Epoch 177/300] Batch 600 | G Loss: 0.9589 | D Loss: 1.1348 | LR: 0.027054 | Momentum: 0.6400\n",
      "[Epoch 177/300] Batch 700 | G Loss: 0.9543 | D Loss: 1.2129 | LR: 0.027044 | Momentum: 0.6400\n",
      "[Epoch 177/300] Batch 800 | G Loss: 0.9772 | D Loss: 1.2469 | LR: 0.027033 | Momentum: 0.6400\n",
      "[Epoch 178/300] Batch 0 | G Loss: 0.8810 | D Loss: 1.2707 | LR: 0.027025 | Momentum: 0.6408\n",
      "[Epoch 178/300] Batch 100 | G Loss: 0.9709 | D Loss: 1.1107 | LR: 0.027014 | Momentum: 0.6408\n",
      "[Epoch 178/300] Batch 200 | G Loss: 0.9147 | D Loss: 1.2599 | LR: 0.027004 | Momentum: 0.6408\n",
      "[Epoch 178/300] Batch 300 | G Loss: 0.9334 | D Loss: 1.0984 | LR: 0.026993 | Momentum: 0.6408\n",
      "[Epoch 178/300] Batch 400 | G Loss: 0.9653 | D Loss: 1.0987 | LR: 0.026982 | Momentum: 0.6408\n",
      "[Epoch 178/300] Batch 500 | G Loss: 0.9037 | D Loss: 1.1145 | LR: 0.026971 | Momentum: 0.6408\n",
      "[Epoch 178/300] Batch 600 | G Loss: 0.9690 | D Loss: 1.1078 | LR: 0.026960 | Momentum: 0.6408\n",
      "[Epoch 178/300] Batch 700 | G Loss: 0.9413 | D Loss: 1.1040 | LR: 0.026950 | Momentum: 0.6408\n",
      "[Epoch 178/300] Batch 800 | G Loss: 0.9448 | D Loss: 1.1812 | LR: 0.026939 | Momentum: 0.6408\n",
      "[Epoch 179/300] Batch 0 | G Loss: 0.9593 | D Loss: 1.2174 | LR: 0.026931 | Momentum: 0.6416\n",
      "[Epoch 179/300] Batch 100 | G Loss: 0.8691 | D Loss: 1.0577 | LR: 0.026921 | Momentum: 0.6416\n",
      "[Epoch 179/300] Batch 200 | G Loss: 1.0166 | D Loss: 1.1765 | LR: 0.026910 | Momentum: 0.6416\n",
      "[Epoch 179/300] Batch 300 | G Loss: 0.9238 | D Loss: 1.2368 | LR: 0.026899 | Momentum: 0.6416\n",
      "[Epoch 179/300] Batch 400 | G Loss: 0.9640 | D Loss: 1.1892 | LR: 0.026888 | Momentum: 0.6416\n",
      "[Epoch 179/300] Batch 500 | G Loss: 0.9369 | D Loss: 1.1038 | LR: 0.026878 | Momentum: 0.6416\n",
      "[Epoch 179/300] Batch 600 | G Loss: 0.9693 | D Loss: 1.1612 | LR: 0.026867 | Momentum: 0.6416\n",
      "[Epoch 179/300] Batch 700 | G Loss: 0.9440 | D Loss: 1.0902 | LR: 0.026856 | Momentum: 0.6416\n",
      "[Epoch 179/300] Batch 800 | G Loss: 0.9420 | D Loss: 1.1454 | LR: 0.026845 | Momentum: 0.6416\n",
      "[Epoch 180/300] Batch 0 | G Loss: 0.9507 | D Loss: 0.9660 | LR: 0.026838 | Momentum: 0.6424\n",
      "[Epoch 180/300] Batch 100 | G Loss: 0.9403 | D Loss: 1.2843 | LR: 0.026827 | Momentum: 0.6424\n",
      "[Epoch 180/300] Batch 200 | G Loss: 0.8981 | D Loss: 1.1047 | LR: 0.026817 | Momentum: 0.6424\n",
      "[Epoch 180/300] Batch 300 | G Loss: 0.9476 | D Loss: 1.1909 | LR: 0.026806 | Momentum: 0.6424\n",
      "[Epoch 180/300] Batch 400 | G Loss: 0.9080 | D Loss: 1.2356 | LR: 0.026795 | Momentum: 0.6424\n",
      "[Epoch 180/300] Batch 500 | G Loss: 0.9651 | D Loss: 1.1692 | LR: 0.026784 | Momentum: 0.6424\n",
      "[Epoch 180/300] Batch 600 | G Loss: 0.9189 | D Loss: 1.1396 | LR: 0.026774 | Momentum: 0.6424\n",
      "[Epoch 180/300] Batch 700 | G Loss: 0.9342 | D Loss: 1.2328 | LR: 0.026763 | Momentum: 0.6424\n",
      "[Epoch 180/300] Batch 800 | G Loss: 0.9032 | D Loss: 1.0465 | LR: 0.026752 | Momentum: 0.6424\n",
      "[Epoch 181/300] Batch 0 | G Loss: 0.9117 | D Loss: 1.2277 | LR: 0.026745 | Momentum: 0.6432\n",
      "[Epoch 181/300] Batch 100 | G Loss: 0.9678 | D Loss: 1.1514 | LR: 0.026734 | Momentum: 0.6432\n",
      "[Epoch 181/300] Batch 200 | G Loss: 0.9310 | D Loss: 1.1927 | LR: 0.026724 | Momentum: 0.6432\n",
      "[Epoch 181/300] Batch 300 | G Loss: 0.9091 | D Loss: 1.2338 | LR: 0.026713 | Momentum: 0.6432\n",
      "[Epoch 181/300] Batch 400 | G Loss: 0.9816 | D Loss: 1.1948 | LR: 0.026702 | Momentum: 0.6432\n",
      "[Epoch 181/300] Batch 500 | G Loss: 0.9039 | D Loss: 1.1823 | LR: 0.026691 | Momentum: 0.6432\n",
      "[Epoch 181/300] Batch 600 | G Loss: 0.9052 | D Loss: 1.1701 | LR: 0.026681 | Momentum: 0.6432\n",
      "[Epoch 181/300] Batch 700 | G Loss: 0.9371 | D Loss: 1.0922 | LR: 0.026670 | Momentum: 0.6432\n",
      "[Epoch 181/300] Batch 800 | G Loss: 1.0034 | D Loss: 1.2503 | LR: 0.026659 | Momentum: 0.6432\n",
      "[Epoch 182/300] Batch 0 | G Loss: 0.9378 | D Loss: 1.0950 | LR: 0.026652 | Momentum: 0.6440\n",
      "[Epoch 182/300] Batch 100 | G Loss: 0.9345 | D Loss: 1.2670 | LR: 0.026641 | Momentum: 0.6440\n",
      "[Epoch 182/300] Batch 200 | G Loss: 0.8638 | D Loss: 1.2679 | LR: 0.026631 | Momentum: 0.6440\n",
      "[Epoch 182/300] Batch 300 | G Loss: 0.9302 | D Loss: 1.2201 | LR: 0.026620 | Momentum: 0.6440\n",
      "[Epoch 182/300] Batch 400 | G Loss: 0.9813 | D Loss: 1.2013 | LR: 0.026609 | Momentum: 0.6440\n",
      "[Epoch 182/300] Batch 500 | G Loss: 0.8945 | D Loss: 1.2047 | LR: 0.026599 | Momentum: 0.6440\n",
      "[Epoch 182/300] Batch 600 | G Loss: 0.9451 | D Loss: 1.2186 | LR: 0.026588 | Momentum: 0.6440\n",
      "[Epoch 182/300] Batch 700 | G Loss: 0.9534 | D Loss: 1.1964 | LR: 0.026578 | Momentum: 0.6440\n",
      "[Epoch 182/300] Batch 800 | G Loss: 0.9204 | D Loss: 1.1401 | LR: 0.026567 | Momentum: 0.6440\n",
      "[Epoch 183/300] Batch 0 | G Loss: 0.9436 | D Loss: 1.2296 | LR: 0.026560 | Momentum: 0.6448\n",
      "[Epoch 183/300] Batch 100 | G Loss: 0.9467 | D Loss: 1.1748 | LR: 0.026549 | Momentum: 0.6448\n",
      "[Epoch 183/300] Batch 200 | G Loss: 0.9746 | D Loss: 1.2009 | LR: 0.026538 | Momentum: 0.6448\n",
      "[Epoch 183/300] Batch 300 | G Loss: 0.9281 | D Loss: 1.1428 | LR: 0.026528 | Momentum: 0.6448\n",
      "[Epoch 183/300] Batch 400 | G Loss: 0.9177 | D Loss: 1.1065 | LR: 0.026517 | Momentum: 0.6448\n",
      "[Epoch 183/300] Batch 500 | G Loss: 0.8833 | D Loss: 1.2379 | LR: 0.026507 | Momentum: 0.6448\n",
      "[Epoch 183/300] Batch 600 | G Loss: 0.9360 | D Loss: 1.1392 | LR: 0.026496 | Momentum: 0.6448\n",
      "[Epoch 183/300] Batch 700 | G Loss: 0.9142 | D Loss: 1.1240 | LR: 0.026485 | Momentum: 0.6448\n",
      "[Epoch 183/300] Batch 800 | G Loss: 0.9045 | D Loss: 1.2783 | LR: 0.026475 | Momentum: 0.6448\n",
      "[Epoch 184/300] Batch 0 | G Loss: 0.8632 | D Loss: 1.0508 | LR: 0.026467 | Momentum: 0.6456\n",
      "[Epoch 184/300] Batch 100 | G Loss: 0.9576 | D Loss: 1.1125 | LR: 0.026457 | Momentum: 0.6456\n",
      "[Epoch 184/300] Batch 200 | G Loss: 0.9057 | D Loss: 1.1644 | LR: 0.026446 | Momentum: 0.6456\n",
      "[Epoch 184/300] Batch 300 | G Loss: 0.9310 | D Loss: 1.2500 | LR: 0.026436 | Momentum: 0.6456\n",
      "[Epoch 184/300] Batch 400 | G Loss: 0.9595 | D Loss: 1.1249 | LR: 0.026425 | Momentum: 0.6456\n",
      "[Epoch 184/300] Batch 500 | G Loss: 0.9406 | D Loss: 1.2282 | LR: 0.026415 | Momentum: 0.6456\n",
      "[Epoch 184/300] Batch 600 | G Loss: 0.9384 | D Loss: 1.1764 | LR: 0.026404 | Momentum: 0.6456\n",
      "[Epoch 184/300] Batch 700 | G Loss: 0.9107 | D Loss: 1.2464 | LR: 0.026393 | Momentum: 0.6456\n",
      "[Epoch 184/300] Batch 800 | G Loss: 0.9211 | D Loss: 1.1243 | LR: 0.026383 | Momentum: 0.6456\n",
      "[Epoch 185/300] Batch 0 | G Loss: 0.9842 | D Loss: 1.2559 | LR: 0.026376 | Momentum: 0.6464\n",
      "[Epoch 185/300] Batch 100 | G Loss: 0.9192 | D Loss: 1.2545 | LR: 0.026365 | Momentum: 0.6464\n",
      "[Epoch 185/300] Batch 200 | G Loss: 0.8938 | D Loss: 1.2235 | LR: 0.026355 | Momentum: 0.6464\n",
      "[Epoch 185/300] Batch 300 | G Loss: 0.9786 | D Loss: 1.1973 | LR: 0.026344 | Momentum: 0.6464\n",
      "[Epoch 185/300] Batch 400 | G Loss: 0.9163 | D Loss: 1.1433 | LR: 0.026333 | Momentum: 0.6464\n",
      "[Epoch 185/300] Batch 500 | G Loss: 0.9663 | D Loss: 1.1830 | LR: 0.026323 | Momentum: 0.6464\n",
      "[Epoch 185/300] Batch 600 | G Loss: 0.9652 | D Loss: 1.1463 | LR: 0.026312 | Momentum: 0.6464\n",
      "[Epoch 185/300] Batch 700 | G Loss: 0.8948 | D Loss: 1.2185 | LR: 0.026302 | Momentum: 0.6464\n",
      "[Epoch 185/300] Batch 800 | G Loss: 0.8714 | D Loss: 1.2423 | LR: 0.026291 | Momentum: 0.6464\n",
      "[Epoch 186/300] Batch 0 | G Loss: 0.9705 | D Loss: 1.2401 | LR: 0.026284 | Momentum: 0.6472\n",
      "[Epoch 186/300] Batch 100 | G Loss: 0.9331 | D Loss: 1.2318 | LR: 0.026274 | Momentum: 0.6472\n",
      "[Epoch 186/300] Batch 200 | G Loss: 0.9093 | D Loss: 1.1844 | LR: 0.026263 | Momentum: 0.6472\n",
      "[Epoch 186/300] Batch 300 | G Loss: 0.9916 | D Loss: 1.1805 | LR: 0.026253 | Momentum: 0.6472\n",
      "[Epoch 186/300] Batch 400 | G Loss: 0.9669 | D Loss: 1.1975 | LR: 0.026242 | Momentum: 0.6472\n",
      "[Epoch 186/300] Batch 500 | G Loss: 0.9257 | D Loss: 1.2564 | LR: 0.026232 | Momentum: 0.6472\n",
      "[Epoch 186/300] Batch 600 | G Loss: 0.8962 | D Loss: 1.2222 | LR: 0.026221 | Momentum: 0.6472\n",
      "[Epoch 186/300] Batch 700 | G Loss: 0.9726 | D Loss: 1.1362 | LR: 0.026211 | Momentum: 0.6472\n",
      "[Epoch 186/300] Batch 800 | G Loss: 0.9850 | D Loss: 1.2300 | LR: 0.026200 | Momentum: 0.6472\n",
      "[Epoch 187/300] Batch 0 | G Loss: 0.9401 | D Loss: 1.2056 | LR: 0.026193 | Momentum: 0.6480\n",
      "[Epoch 187/300] Batch 100 | G Loss: 0.9561 | D Loss: 1.2343 | LR: 0.026182 | Momentum: 0.6480\n",
      "[Epoch 187/300] Batch 200 | G Loss: 0.9257 | D Loss: 1.1162 | LR: 0.026172 | Momentum: 0.6480\n",
      "[Epoch 187/300] Batch 300 | G Loss: 0.9240 | D Loss: 1.2158 | LR: 0.026161 | Momentum: 0.6480\n",
      "[Epoch 187/300] Batch 400 | G Loss: 0.9369 | D Loss: 1.1927 | LR: 0.026151 | Momentum: 0.6480\n",
      "[Epoch 187/300] Batch 500 | G Loss: 0.9905 | D Loss: 1.0689 | LR: 0.026141 | Momentum: 0.6480\n",
      "[Epoch 187/300] Batch 600 | G Loss: 0.9993 | D Loss: 1.1115 | LR: 0.026130 | Momentum: 0.6480\n",
      "[Epoch 187/300] Batch 700 | G Loss: 0.9930 | D Loss: 1.1472 | LR: 0.026120 | Momentum: 0.6480\n",
      "[Epoch 187/300] Batch 800 | G Loss: 0.9298 | D Loss: 1.1332 | LR: 0.026109 | Momentum: 0.6480\n",
      "[Epoch 188/300] Batch 0 | G Loss: 0.8647 | D Loss: 1.1818 | LR: 0.026102 | Momentum: 0.6488\n",
      "[Epoch 188/300] Batch 100 | G Loss: 0.9410 | D Loss: 1.1611 | LR: 0.026092 | Momentum: 0.6488\n",
      "[Epoch 188/300] Batch 200 | G Loss: 0.9925 | D Loss: 1.1431 | LR: 0.026081 | Momentum: 0.6488\n",
      "[Epoch 188/300] Batch 300 | G Loss: 0.8923 | D Loss: 1.1055 | LR: 0.026071 | Momentum: 0.6488\n",
      "[Epoch 188/300] Batch 400 | G Loss: 0.9927 | D Loss: 1.1195 | LR: 0.026060 | Momentum: 0.6488\n",
      "[Epoch 188/300] Batch 500 | G Loss: 0.9779 | D Loss: 1.1709 | LR: 0.026050 | Momentum: 0.6488\n",
      "[Epoch 188/300] Batch 600 | G Loss: 0.9451 | D Loss: 1.1680 | LR: 0.026039 | Momentum: 0.6488\n",
      "[Epoch 188/300] Batch 700 | G Loss: 0.9674 | D Loss: 1.1479 | LR: 0.026029 | Momentum: 0.6488\n",
      "[Epoch 188/300] Batch 800 | G Loss: 0.9092 | D Loss: 1.2287 | LR: 0.026019 | Momentum: 0.6488\n",
      "[Epoch 189/300] Batch 0 | G Loss: 0.9252 | D Loss: 1.1945 | LR: 0.026011 | Momentum: 0.6496\n",
      "[Epoch 189/300] Batch 100 | G Loss: 0.8477 | D Loss: 1.1197 | LR: 0.026001 | Momentum: 0.6496\n",
      "[Epoch 189/300] Batch 200 | G Loss: 0.9143 | D Loss: 1.0979 | LR: 0.025991 | Momentum: 0.6496\n",
      "[Epoch 189/300] Batch 300 | G Loss: 0.9450 | D Loss: 1.1304 | LR: 0.025980 | Momentum: 0.6496\n",
      "[Epoch 189/300] Batch 400 | G Loss: 0.9282 | D Loss: 1.2002 | LR: 0.025970 | Momentum: 0.6496\n",
      "[Epoch 189/300] Batch 500 | G Loss: 1.0000 | D Loss: 1.1899 | LR: 0.025959 | Momentum: 0.6496\n",
      "[Epoch 189/300] Batch 600 | G Loss: 0.8704 | D Loss: 1.1971 | LR: 0.025949 | Momentum: 0.6496\n",
      "[Epoch 189/300] Batch 700 | G Loss: 0.9618 | D Loss: 1.1803 | LR: 0.025939 | Momentum: 0.6496\n",
      "[Epoch 189/300] Batch 800 | G Loss: 0.9369 | D Loss: 1.1614 | LR: 0.025928 | Momentum: 0.6496\n",
      "[Epoch 190/300] Batch 0 | G Loss: 0.9332 | D Loss: 1.1377 | LR: 0.025921 | Momentum: 0.6504\n",
      "[Epoch 190/300] Batch 100 | G Loss: 0.9695 | D Loss: 1.1557 | LR: 0.025911 | Momentum: 0.6504\n",
      "[Epoch 190/300] Batch 200 | G Loss: 0.9678 | D Loss: 1.1473 | LR: 0.025900 | Momentum: 0.6504\n",
      "[Epoch 190/300] Batch 300 | G Loss: 0.9179 | D Loss: 1.1993 | LR: 0.025890 | Momentum: 0.6504\n",
      "[Epoch 190/300] Batch 400 | G Loss: 0.9335 | D Loss: 1.2013 | LR: 0.025880 | Momentum: 0.6504\n",
      "[Epoch 190/300] Batch 500 | G Loss: 0.9441 | D Loss: 1.1581 | LR: 0.025869 | Momentum: 0.6504\n",
      "[Epoch 190/300] Batch 600 | G Loss: 0.9323 | D Loss: 1.2059 | LR: 0.025859 | Momentum: 0.6504\n",
      "[Epoch 190/300] Batch 700 | G Loss: 0.9229 | D Loss: 1.1452 | LR: 0.025849 | Momentum: 0.6504\n",
      "[Epoch 190/300] Batch 800 | G Loss: 1.0184 | D Loss: 1.2110 | LR: 0.025838 | Momentum: 0.6504\n",
      "[Epoch 191/300] Batch 0 | G Loss: 1.0247 | D Loss: 1.1578 | LR: 0.025831 | Momentum: 0.6512\n",
      "[Epoch 191/300] Batch 100 | G Loss: 0.9423 | D Loss: 1.1890 | LR: 0.025821 | Momentum: 0.6512\n",
      "[Epoch 191/300] Batch 200 | G Loss: 0.9356 | D Loss: 1.1267 | LR: 0.025811 | Momentum: 0.6512\n",
      "[Epoch 191/300] Batch 300 | G Loss: 0.9783 | D Loss: 1.1467 | LR: 0.025800 | Momentum: 0.6512\n",
      "[Epoch 191/300] Batch 400 | G Loss: 0.9554 | D Loss: 1.1315 | LR: 0.025790 | Momentum: 0.6512\n",
      "[Epoch 191/300] Batch 500 | G Loss: 0.9345 | D Loss: 1.1852 | LR: 0.025780 | Momentum: 0.6512\n",
      "[Epoch 191/300] Batch 600 | G Loss: 0.9684 | D Loss: 1.1672 | LR: 0.025769 | Momentum: 0.6512\n",
      "[Epoch 191/300] Batch 700 | G Loss: 0.9070 | D Loss: 1.1928 | LR: 0.025759 | Momentum: 0.6512\n",
      "[Epoch 191/300] Batch 800 | G Loss: 0.9623 | D Loss: 1.2114 | LR: 0.025749 | Momentum: 0.6512\n",
      "[Epoch 192/300] Batch 0 | G Loss: 0.9807 | D Loss: 1.1912 | LR: 0.025742 | Momentum: 0.6520\n",
      "[Epoch 192/300] Batch 100 | G Loss: 0.9820 | D Loss: 1.2589 | LR: 0.025731 | Momentum: 0.6520\n",
      "[Epoch 192/300] Batch 200 | G Loss: 0.9909 | D Loss: 1.2620 | LR: 0.025721 | Momentum: 0.6520\n",
      "[Epoch 192/300] Batch 300 | G Loss: 1.0101 | D Loss: 1.1033 | LR: 0.025711 | Momentum: 0.6520\n",
      "[Epoch 192/300] Batch 400 | G Loss: 0.9672 | D Loss: 1.2504 | LR: 0.025700 | Momentum: 0.6520\n",
      "[Epoch 192/300] Batch 500 | G Loss: 0.9345 | D Loss: 1.2706 | LR: 0.025690 | Momentum: 0.6520\n",
      "[Epoch 192/300] Batch 600 | G Loss: 0.9312 | D Loss: 1.1854 | LR: 0.025680 | Momentum: 0.6520\n",
      "[Epoch 192/300] Batch 700 | G Loss: 1.0165 | D Loss: 1.0889 | LR: 0.025670 | Momentum: 0.6520\n",
      "[Epoch 192/300] Batch 800 | G Loss: 0.9292 | D Loss: 1.2488 | LR: 0.025659 | Momentum: 0.6520\n",
      "[Epoch 193/300] Batch 0 | G Loss: 0.8975 | D Loss: 1.2431 | LR: 0.025652 | Momentum: 0.6528\n",
      "[Epoch 193/300] Batch 100 | G Loss: 0.9810 | D Loss: 1.0922 | LR: 0.025642 | Momentum: 0.6528\n",
      "[Epoch 193/300] Batch 200 | G Loss: 0.9019 | D Loss: 1.2387 | LR: 0.025632 | Momentum: 0.6528\n",
      "[Epoch 193/300] Batch 300 | G Loss: 0.9369 | D Loss: 1.1456 | LR: 0.025622 | Momentum: 0.6528\n",
      "[Epoch 193/300] Batch 400 | G Loss: 0.8930 | D Loss: 1.1843 | LR: 0.025611 | Momentum: 0.6528\n",
      "[Epoch 193/300] Batch 500 | G Loss: 0.9118 | D Loss: 1.1414 | LR: 0.025601 | Momentum: 0.6528\n",
      "[Epoch 193/300] Batch 600 | G Loss: 1.0141 | D Loss: 1.2993 | LR: 0.025591 | Momentum: 0.6528\n",
      "[Epoch 193/300] Batch 700 | G Loss: 0.9375 | D Loss: 1.0853 | LR: 0.025581 | Momentum: 0.6528\n",
      "[Epoch 193/300] Batch 800 | G Loss: 1.0016 | D Loss: 1.1995 | LR: 0.025570 | Momentum: 0.6528\n",
      "[Epoch 194/300] Batch 0 | G Loss: 0.9815 | D Loss: 1.1844 | LR: 0.025563 | Momentum: 0.6536\n",
      "[Epoch 194/300] Batch 100 | G Loss: 0.9025 | D Loss: 1.1226 | LR: 0.025553 | Momentum: 0.6536\n",
      "[Epoch 194/300] Batch 200 | G Loss: 0.9211 | D Loss: 1.1736 | LR: 0.025543 | Momentum: 0.6536\n",
      "[Epoch 194/300] Batch 300 | G Loss: 0.9357 | D Loss: 1.1112 | LR: 0.025533 | Momentum: 0.6536\n",
      "[Epoch 194/300] Batch 400 | G Loss: 0.9354 | D Loss: 1.1713 | LR: 0.025522 | Momentum: 0.6536\n",
      "[Epoch 194/300] Batch 500 | G Loss: 1.0068 | D Loss: 1.3326 | LR: 0.025512 | Momentum: 0.6536\n",
      "[Epoch 194/300] Batch 600 | G Loss: 0.9053 | D Loss: 1.1775 | LR: 0.025502 | Momentum: 0.6536\n",
      "[Epoch 194/300] Batch 700 | G Loss: 0.9281 | D Loss: 1.2640 | LR: 0.025492 | Momentum: 0.6536\n",
      "[Epoch 194/300] Batch 800 | G Loss: 0.9442 | D Loss: 1.1826 | LR: 0.025482 | Momentum: 0.6536\n",
      "[Epoch 195/300] Batch 0 | G Loss: 0.9620 | D Loss: 1.0888 | LR: 0.025475 | Momentum: 0.6544\n",
      "[Epoch 195/300] Batch 100 | G Loss: 0.9111 | D Loss: 1.1614 | LR: 0.025464 | Momentum: 0.6544\n",
      "[Epoch 195/300] Batch 200 | G Loss: 0.9398 | D Loss: 1.2017 | LR: 0.025454 | Momentum: 0.6544\n",
      "[Epoch 195/300] Batch 300 | G Loss: 0.8982 | D Loss: 1.1445 | LR: 0.025444 | Momentum: 0.6544\n",
      "[Epoch 195/300] Batch 400 | G Loss: 0.9375 | D Loss: 1.1119 | LR: 0.025434 | Momentum: 0.6544\n",
      "[Epoch 195/300] Batch 500 | G Loss: 0.9880 | D Loss: 1.1160 | LR: 0.025424 | Momentum: 0.6544\n",
      "[Epoch 195/300] Batch 600 | G Loss: 0.9129 | D Loss: 1.2575 | LR: 0.025413 | Momentum: 0.6544\n",
      "[Epoch 195/300] Batch 700 | G Loss: 0.9716 | D Loss: 1.2042 | LR: 0.025403 | Momentum: 0.6544\n",
      "[Epoch 195/300] Batch 800 | G Loss: 0.9227 | D Loss: 1.1199 | LR: 0.025393 | Momentum: 0.6544\n",
      "[Epoch 196/300] Batch 0 | G Loss: 0.9438 | D Loss: 1.1688 | LR: 0.025386 | Momentum: 0.6552\n",
      "[Epoch 196/300] Batch 100 | G Loss: 0.9330 | D Loss: 1.2004 | LR: 0.025376 | Momentum: 0.6552\n",
      "[Epoch 196/300] Batch 200 | G Loss: 0.9773 | D Loss: 1.0530 | LR: 0.025366 | Momentum: 0.6552\n",
      "[Epoch 196/300] Batch 300 | G Loss: 0.9428 | D Loss: 1.1310 | LR: 0.025356 | Momentum: 0.6552\n",
      "[Epoch 196/300] Batch 400 | G Loss: 0.9389 | D Loss: 1.1198 | LR: 0.025346 | Momentum: 0.6552\n",
      "[Epoch 196/300] Batch 500 | G Loss: 0.9083 | D Loss: 1.2556 | LR: 0.025335 | Momentum: 0.6552\n",
      "[Epoch 196/300] Batch 600 | G Loss: 1.0066 | D Loss: 1.1325 | LR: 0.025325 | Momentum: 0.6552\n",
      "[Epoch 196/300] Batch 700 | G Loss: 0.9909 | D Loss: 1.1370 | LR: 0.025315 | Momentum: 0.6552\n",
      "[Epoch 196/300] Batch 800 | G Loss: 1.0007 | D Loss: 1.1560 | LR: 0.025305 | Momentum: 0.6552\n",
      "[Epoch 197/300] Batch 0 | G Loss: 0.9536 | D Loss: 1.1498 | LR: 0.025298 | Momentum: 0.6560\n",
      "[Epoch 197/300] Batch 100 | G Loss: 0.8473 | D Loss: 1.2481 | LR: 0.025288 | Momentum: 0.6560\n",
      "[Epoch 197/300] Batch 200 | G Loss: 0.9176 | D Loss: 1.2494 | LR: 0.025278 | Momentum: 0.6560\n",
      "[Epoch 197/300] Batch 300 | G Loss: 0.9838 | D Loss: 1.0737 | LR: 0.025268 | Momentum: 0.6560\n",
      "[Epoch 197/300] Batch 400 | G Loss: 0.9335 | D Loss: 1.1347 | LR: 0.025258 | Momentum: 0.6560\n",
      "[Epoch 197/300] Batch 500 | G Loss: 0.9456 | D Loss: 1.2078 | LR: 0.025248 | Momentum: 0.6560\n",
      "[Epoch 197/300] Batch 600 | G Loss: 0.9487 | D Loss: 1.1912 | LR: 0.025237 | Momentum: 0.6560\n",
      "[Epoch 197/300] Batch 700 | G Loss: 0.8891 | D Loss: 1.1287 | LR: 0.025227 | Momentum: 0.6560\n",
      "[Epoch 197/300] Batch 800 | G Loss: 0.9032 | D Loss: 1.1860 | LR: 0.025217 | Momentum: 0.6560\n",
      "[Epoch 198/300] Batch 0 | G Loss: 0.9206 | D Loss: 1.0913 | LR: 0.025210 | Momentum: 0.6568\n",
      "[Epoch 198/300] Batch 100 | G Loss: 0.9698 | D Loss: 1.2006 | LR: 0.025200 | Momentum: 0.6568\n",
      "[Epoch 198/300] Batch 200 | G Loss: 0.9109 | D Loss: 1.2706 | LR: 0.025190 | Momentum: 0.6568\n",
      "[Epoch 198/300] Batch 300 | G Loss: 0.9235 | D Loss: 1.1445 | LR: 0.025180 | Momentum: 0.6568\n",
      "[Epoch 198/300] Batch 400 | G Loss: 0.9289 | D Loss: 1.1331 | LR: 0.025170 | Momentum: 0.6568\n",
      "[Epoch 198/300] Batch 500 | G Loss: 0.9549 | D Loss: 1.2165 | LR: 0.025160 | Momentum: 0.6568\n",
      "[Epoch 198/300] Batch 600 | G Loss: 0.9372 | D Loss: 1.2004 | LR: 0.025150 | Momentum: 0.6568\n",
      "[Epoch 198/300] Batch 700 | G Loss: 0.9720 | D Loss: 1.1801 | LR: 0.025140 | Momentum: 0.6568\n",
      "[Epoch 198/300] Batch 800 | G Loss: 1.0113 | D Loss: 1.2237 | LR: 0.025130 | Momentum: 0.6568\n",
      "[Epoch 199/300] Batch 0 | G Loss: 0.9041 | D Loss: 1.1336 | LR: 0.025123 | Momentum: 0.6576\n",
      "[Epoch 199/300] Batch 100 | G Loss: 1.0078 | D Loss: 1.1411 | LR: 0.025113 | Momentum: 0.6576\n",
      "[Epoch 199/300] Batch 200 | G Loss: 0.9433 | D Loss: 1.2249 | LR: 0.025103 | Momentum: 0.6576\n",
      "[Epoch 199/300] Batch 300 | G Loss: 0.9750 | D Loss: 1.2262 | LR: 0.025093 | Momentum: 0.6576\n",
      "[Epoch 199/300] Batch 400 | G Loss: 0.9434 | D Loss: 1.2137 | LR: 0.025083 | Momentum: 0.6576\n",
      "[Epoch 199/300] Batch 500 | G Loss: 0.9167 | D Loss: 1.1933 | LR: 0.025073 | Momentum: 0.6576\n",
      "[Epoch 199/300] Batch 600 | G Loss: 0.9404 | D Loss: 1.2503 | LR: 0.025063 | Momentum: 0.6576\n",
      "[Epoch 199/300] Batch 700 | G Loss: 1.0133 | D Loss: 1.1260 | LR: 0.025053 | Momentum: 0.6576\n",
      "[Epoch 199/300] Batch 800 | G Loss: 0.9418 | D Loss: 1.1848 | LR: 0.025043 | Momentum: 0.6576\n",
      "[Epoch 200/300] Batch 0 | G Loss: 1.0175 | D Loss: 1.0967 | LR: 0.025036 | Momentum: 0.6584\n",
      "[Epoch 200/300] Batch 100 | G Loss: 0.9340 | D Loss: 1.0796 | LR: 0.025026 | Momentum: 0.6584\n",
      "[Epoch 200/300] Batch 200 | G Loss: 0.9319 | D Loss: 1.0979 | LR: 0.025016 | Momentum: 0.6584\n",
      "[Epoch 200/300] Batch 300 | G Loss: 0.8949 | D Loss: 1.1962 | LR: 0.025006 | Momentum: 0.6584\n",
      "[Epoch 200/300] Batch 400 | G Loss: 0.9035 | D Loss: 1.2180 | LR: 0.024996 | Momentum: 0.6584\n",
      "[Epoch 200/300] Batch 500 | G Loss: 0.9569 | D Loss: 1.2331 | LR: 0.024986 | Momentum: 0.6584\n",
      "[Epoch 200/300] Batch 600 | G Loss: 0.9298 | D Loss: 1.1674 | LR: 0.024976 | Momentum: 0.6584\n",
      "[Epoch 200/300] Batch 700 | G Loss: 0.9376 | D Loss: 1.1231 | LR: 0.024966 | Momentum: 0.6584\n",
      "[Epoch 200/300] Batch 800 | G Loss: 0.9283 | D Loss: 1.1661 | LR: 0.024956 | Momentum: 0.6584\n",
      "[Epoch 201/300] Batch 0 | G Loss: 0.9199 | D Loss: 1.1772 | LR: 0.024949 | Momentum: 0.6592\n",
      "[Epoch 201/300] Batch 100 | G Loss: 0.9414 | D Loss: 1.1673 | LR: 0.024939 | Momentum: 0.6592\n",
      "[Epoch 201/300] Batch 200 | G Loss: 0.9537 | D Loss: 1.2092 | LR: 0.024929 | Momentum: 0.6592\n",
      "[Epoch 201/300] Batch 300 | G Loss: 0.9565 | D Loss: 1.2119 | LR: 0.024919 | Momentum: 0.6592\n",
      "[Epoch 201/300] Batch 400 | G Loss: 0.9368 | D Loss: 1.2560 | LR: 0.024909 | Momentum: 0.6592\n",
      "[Epoch 201/300] Batch 500 | G Loss: 0.8903 | D Loss: 1.2309 | LR: 0.024899 | Momentum: 0.6592\n",
      "[Epoch 201/300] Batch 600 | G Loss: 0.9327 | D Loss: 1.2731 | LR: 0.024889 | Momentum: 0.6592\n",
      "[Epoch 201/300] Batch 700 | G Loss: 0.9606 | D Loss: 1.1360 | LR: 0.024879 | Momentum: 0.6592\n",
      "[Epoch 201/300] Batch 800 | G Loss: 0.9593 | D Loss: 1.3055 | LR: 0.024869 | Momentum: 0.6592\n",
      "[Epoch 202/300] Batch 0 | G Loss: 0.9864 | D Loss: 1.1194 | LR: 0.024862 | Momentum: 0.6600\n",
      "[Epoch 202/300] Batch 100 | G Loss: 0.9373 | D Loss: 1.1494 | LR: 0.024852 | Momentum: 0.6600\n",
      "[Epoch 202/300] Batch 200 | G Loss: 0.9511 | D Loss: 1.2762 | LR: 0.024842 | Momentum: 0.6600\n",
      "[Epoch 202/300] Batch 300 | G Loss: 0.9489 | D Loss: 1.1832 | LR: 0.024832 | Momentum: 0.6600\n",
      "[Epoch 202/300] Batch 400 | G Loss: 0.9764 | D Loss: 1.1764 | LR: 0.024822 | Momentum: 0.6600\n",
      "[Epoch 202/300] Batch 500 | G Loss: 0.9204 | D Loss: 1.2203 | LR: 0.024813 | Momentum: 0.6600\n",
      "[Epoch 202/300] Batch 600 | G Loss: 0.9484 | D Loss: 1.1774 | LR: 0.024803 | Momentum: 0.6600\n",
      "[Epoch 202/300] Batch 700 | G Loss: 0.9068 | D Loss: 1.0975 | LR: 0.024793 | Momentum: 0.6600\n",
      "[Epoch 202/300] Batch 800 | G Loss: 0.9209 | D Loss: 1.2228 | LR: 0.024783 | Momentum: 0.6600\n",
      "[Epoch 203/300] Batch 0 | G Loss: 0.9613 | D Loss: 1.1840 | LR: 0.024776 | Momentum: 0.6608\n",
      "[Epoch 203/300] Batch 100 | G Loss: 0.8699 | D Loss: 1.1331 | LR: 0.024766 | Momentum: 0.6608\n",
      "[Epoch 203/300] Batch 200 | G Loss: 0.9407 | D Loss: 1.1192 | LR: 0.024756 | Momentum: 0.6608\n",
      "[Epoch 203/300] Batch 300 | G Loss: 0.8837 | D Loss: 1.1553 | LR: 0.024746 | Momentum: 0.6608\n",
      "[Epoch 203/300] Batch 400 | G Loss: 0.9211 | D Loss: 1.2131 | LR: 0.024736 | Momentum: 0.6608\n",
      "[Epoch 203/300] Batch 500 | G Loss: 0.9270 | D Loss: 1.1161 | LR: 0.024726 | Momentum: 0.6608\n",
      "[Epoch 203/300] Batch 600 | G Loss: 0.9760 | D Loss: 1.2539 | LR: 0.024717 | Momentum: 0.6608\n",
      "[Epoch 203/300] Batch 700 | G Loss: 0.9436 | D Loss: 1.2865 | LR: 0.024707 | Momentum: 0.6608\n",
      "[Epoch 203/300] Batch 800 | G Loss: 0.9689 | D Loss: 1.2902 | LR: 0.024697 | Momentum: 0.6608\n",
      "[Epoch 204/300] Batch 0 | G Loss: 0.9927 | D Loss: 1.0526 | LR: 0.024690 | Momentum: 0.6616\n",
      "[Epoch 204/300] Batch 100 | G Loss: 0.9590 | D Loss: 1.1163 | LR: 0.024680 | Momentum: 0.6616\n",
      "[Epoch 204/300] Batch 200 | G Loss: 0.9140 | D Loss: 1.2447 | LR: 0.024670 | Momentum: 0.6616\n",
      "[Epoch 204/300] Batch 300 | G Loss: 0.9400 | D Loss: 1.1632 | LR: 0.024660 | Momentum: 0.6616\n",
      "[Epoch 204/300] Batch 400 | G Loss: 0.9887 | D Loss: 1.1748 | LR: 0.024650 | Momentum: 0.6616\n",
      "[Epoch 204/300] Batch 500 | G Loss: 0.9213 | D Loss: 1.2694 | LR: 0.024641 | Momentum: 0.6616\n",
      "[Epoch 204/300] Batch 600 | G Loss: 0.8686 | D Loss: 1.0819 | LR: 0.024631 | Momentum: 0.6616\n",
      "[Epoch 204/300] Batch 700 | G Loss: 0.9315 | D Loss: 1.1455 | LR: 0.024621 | Momentum: 0.6616\n",
      "[Epoch 204/300] Batch 800 | G Loss: 0.9441 | D Loss: 1.1983 | LR: 0.024611 | Momentum: 0.6616\n",
      "[Epoch 205/300] Batch 0 | G Loss: 0.9256 | D Loss: 1.3060 | LR: 0.024604 | Momentum: 0.6624\n",
      "[Epoch 205/300] Batch 100 | G Loss: 0.9376 | D Loss: 1.2141 | LR: 0.024594 | Momentum: 0.6624\n",
      "[Epoch 205/300] Batch 200 | G Loss: 0.9738 | D Loss: 1.3093 | LR: 0.024585 | Momentum: 0.6624\n",
      "[Epoch 205/300] Batch 300 | G Loss: 0.9628 | D Loss: 1.0882 | LR: 0.024575 | Momentum: 0.6624\n",
      "[Epoch 205/300] Batch 400 | G Loss: 0.9526 | D Loss: 1.1591 | LR: 0.024565 | Momentum: 0.6624\n",
      "[Epoch 205/300] Batch 500 | G Loss: 0.9349 | D Loss: 1.1821 | LR: 0.024555 | Momentum: 0.6624\n",
      "[Epoch 205/300] Batch 600 | G Loss: 0.9279 | D Loss: 1.1464 | LR: 0.024545 | Momentum: 0.6624\n",
      "[Epoch 205/300] Batch 700 | G Loss: 0.9324 | D Loss: 1.1452 | LR: 0.024535 | Momentum: 0.6624\n",
      "[Epoch 205/300] Batch 800 | G Loss: 0.9421 | D Loss: 1.1282 | LR: 0.024526 | Momentum: 0.6624\n",
      "[Epoch 206/300] Batch 0 | G Loss: 0.9380 | D Loss: 1.0223 | LR: 0.024519 | Momentum: 0.6632\n",
      "[Epoch 206/300] Batch 100 | G Loss: 0.9318 | D Loss: 1.1331 | LR: 0.024509 | Momentum: 0.6632\n",
      "[Epoch 206/300] Batch 200 | G Loss: 0.9452 | D Loss: 1.1068 | LR: 0.024499 | Momentum: 0.6632\n",
      "[Epoch 206/300] Batch 300 | G Loss: 0.9679 | D Loss: 1.0959 | LR: 0.024489 | Momentum: 0.6632\n",
      "[Epoch 206/300] Batch 400 | G Loss: 0.9659 | D Loss: 1.2309 | LR: 0.024480 | Momentum: 0.6632\n",
      "[Epoch 206/300] Batch 500 | G Loss: 0.9804 | D Loss: 1.1078 | LR: 0.024470 | Momentum: 0.6632\n",
      "[Epoch 206/300] Batch 600 | G Loss: 0.9364 | D Loss: 1.1055 | LR: 0.024460 | Momentum: 0.6632\n",
      "[Epoch 206/300] Batch 700 | G Loss: 0.9179 | D Loss: 1.1407 | LR: 0.024450 | Momentum: 0.6632\n",
      "[Epoch 206/300] Batch 800 | G Loss: 0.9489 | D Loss: 1.1133 | LR: 0.024441 | Momentum: 0.6632\n",
      "[Epoch 207/300] Batch 0 | G Loss: 0.9514 | D Loss: 1.2316 | LR: 0.024434 | Momentum: 0.6640\n",
      "[Epoch 207/300] Batch 100 | G Loss: 0.9456 | D Loss: 1.1186 | LR: 0.024424 | Momentum: 0.6640\n",
      "[Epoch 207/300] Batch 200 | G Loss: 0.9625 | D Loss: 1.2776 | LR: 0.024414 | Momentum: 0.6640\n",
      "[Epoch 207/300] Batch 300 | G Loss: 0.9970 | D Loss: 1.1610 | LR: 0.024405 | Momentum: 0.6640\n",
      "[Epoch 207/300] Batch 400 | G Loss: 0.9482 | D Loss: 1.1775 | LR: 0.024395 | Momentum: 0.6640\n",
      "[Epoch 207/300] Batch 500 | G Loss: 0.9169 | D Loss: 1.0940 | LR: 0.024385 | Momentum: 0.6640\n",
      "[Epoch 207/300] Batch 600 | G Loss: 0.9583 | D Loss: 1.2767 | LR: 0.024375 | Momentum: 0.6640\n",
      "[Epoch 207/300] Batch 700 | G Loss: 0.9542 | D Loss: 1.1932 | LR: 0.024366 | Momentum: 0.6640\n",
      "[Epoch 207/300] Batch 800 | G Loss: 0.9615 | D Loss: 1.1562 | LR: 0.024356 | Momentum: 0.6640\n",
      "[Epoch 208/300] Batch 0 | G Loss: 1.0211 | D Loss: 1.2116 | LR: 0.024349 | Momentum: 0.6648\n",
      "[Epoch 208/300] Batch 100 | G Loss: 0.9057 | D Loss: 1.2528 | LR: 0.024339 | Momentum: 0.6648\n",
      "[Epoch 208/300] Batch 200 | G Loss: 0.9727 | D Loss: 1.1204 | LR: 0.024330 | Momentum: 0.6648\n",
      "[Epoch 208/300] Batch 300 | G Loss: 0.9467 | D Loss: 1.1031 | LR: 0.024320 | Momentum: 0.6648\n",
      "[Epoch 208/300] Batch 400 | G Loss: 0.9188 | D Loss: 1.2342 | LR: 0.024310 | Momentum: 0.6648\n",
      "[Epoch 208/300] Batch 500 | G Loss: 0.9695 | D Loss: 1.1953 | LR: 0.024300 | Momentum: 0.6648\n",
      "[Epoch 208/300] Batch 600 | G Loss: 0.9561 | D Loss: 1.1413 | LR: 0.024291 | Momentum: 0.6648\n",
      "[Epoch 208/300] Batch 700 | G Loss: 0.9551 | D Loss: 1.2483 | LR: 0.024281 | Momentum: 0.6648\n",
      "[Epoch 208/300] Batch 800 | G Loss: 1.0066 | D Loss: 1.1751 | LR: 0.024271 | Momentum: 0.6648\n",
      "[Epoch 209/300] Batch 0 | G Loss: 0.9420 | D Loss: 1.1148 | LR: 0.024265 | Momentum: 0.6656\n",
      "[Epoch 209/300] Batch 100 | G Loss: 0.9622 | D Loss: 1.2387 | LR: 0.024255 | Momentum: 0.6656\n",
      "[Epoch 209/300] Batch 200 | G Loss: 0.9449 | D Loss: 1.1875 | LR: 0.024245 | Momentum: 0.6656\n",
      "[Epoch 209/300] Batch 300 | G Loss: 0.9448 | D Loss: 1.1076 | LR: 0.024235 | Momentum: 0.6656\n",
      "[Epoch 209/300] Batch 400 | G Loss: 0.9363 | D Loss: 1.2036 | LR: 0.024226 | Momentum: 0.6656\n",
      "[Epoch 209/300] Batch 500 | G Loss: 0.9401 | D Loss: 1.1170 | LR: 0.024216 | Momentum: 0.6656\n",
      "[Epoch 209/300] Batch 600 | G Loss: 0.9833 | D Loss: 1.2777 | LR: 0.024206 | Momentum: 0.6656\n",
      "[Epoch 209/300] Batch 700 | G Loss: 0.9136 | D Loss: 1.1697 | LR: 0.024197 | Momentum: 0.6656\n",
      "[Epoch 209/300] Batch 800 | G Loss: 0.9672 | D Loss: 1.2138 | LR: 0.024187 | Momentum: 0.6656\n",
      "[Epoch 210/300] Batch 0 | G Loss: 0.9370 | D Loss: 1.2388 | LR: 0.024180 | Momentum: 0.6664\n",
      "[Epoch 210/300] Batch 100 | G Loss: 1.0079 | D Loss: 1.2123 | LR: 0.024171 | Momentum: 0.6664\n",
      "[Epoch 210/300] Batch 200 | G Loss: 0.9911 | D Loss: 1.1400 | LR: 0.024161 | Momentum: 0.6664\n",
      "[Epoch 210/300] Batch 300 | G Loss: 1.0157 | D Loss: 1.1971 | LR: 0.024151 | Momentum: 0.6664\n",
      "[Epoch 210/300] Batch 400 | G Loss: 0.8670 | D Loss: 1.1477 | LR: 0.024142 | Momentum: 0.6664\n",
      "[Epoch 210/300] Batch 500 | G Loss: 0.9177 | D Loss: 1.1730 | LR: 0.024132 | Momentum: 0.6664\n",
      "[Epoch 210/300] Batch 600 | G Loss: 0.9602 | D Loss: 1.1792 | LR: 0.024122 | Momentum: 0.6664\n",
      "[Epoch 210/300] Batch 700 | G Loss: 0.9781 | D Loss: 1.3479 | LR: 0.024113 | Momentum: 0.6664\n",
      "[Epoch 210/300] Batch 800 | G Loss: 0.9611 | D Loss: 1.1851 | LR: 0.024103 | Momentum: 0.6664\n",
      "[Epoch 211/300] Batch 0 | G Loss: 0.9554 | D Loss: 1.2135 | LR: 0.024096 | Momentum: 0.6672\n",
      "[Epoch 211/300] Batch 100 | G Loss: 0.9853 | D Loss: 1.1798 | LR: 0.024087 | Momentum: 0.6672\n",
      "[Epoch 211/300] Batch 200 | G Loss: 0.9406 | D Loss: 1.1748 | LR: 0.024077 | Momentum: 0.6672\n",
      "[Epoch 211/300] Batch 300 | G Loss: 1.0102 | D Loss: 1.0739 | LR: 0.024068 | Momentum: 0.6672\n",
      "[Epoch 211/300] Batch 400 | G Loss: 0.9053 | D Loss: 1.0850 | LR: 0.024058 | Momentum: 0.6672\n",
      "[Epoch 211/300] Batch 500 | G Loss: 0.9002 | D Loss: 1.1134 | LR: 0.024048 | Momentum: 0.6672\n",
      "[Epoch 211/300] Batch 600 | G Loss: 0.9259 | D Loss: 1.1747 | LR: 0.024039 | Momentum: 0.6672\n",
      "[Epoch 211/300] Batch 700 | G Loss: 0.8965 | D Loss: 1.2142 | LR: 0.024029 | Momentum: 0.6672\n",
      "[Epoch 211/300] Batch 800 | G Loss: 0.9177 | D Loss: 1.1812 | LR: 0.024019 | Momentum: 0.6672\n",
      "[Epoch 212/300] Batch 0 | G Loss: 0.9327 | D Loss: 1.1498 | LR: 0.024013 | Momentum: 0.6680\n",
      "[Epoch 212/300] Batch 100 | G Loss: 0.9748 | D Loss: 1.1797 | LR: 0.024003 | Momentum: 0.6680\n",
      "[Epoch 212/300] Batch 200 | G Loss: 0.9270 | D Loss: 1.1518 | LR: 0.023994 | Momentum: 0.6680\n",
      "[Epoch 212/300] Batch 300 | G Loss: 0.9130 | D Loss: 1.1791 | LR: 0.023984 | Momentum: 0.6680\n",
      "[Epoch 212/300] Batch 400 | G Loss: 0.9308 | D Loss: 1.1559 | LR: 0.023974 | Momentum: 0.6680\n",
      "[Epoch 212/300] Batch 500 | G Loss: 0.9701 | D Loss: 1.2174 | LR: 0.023965 | Momentum: 0.6680\n",
      "[Epoch 212/300] Batch 600 | G Loss: 0.9502 | D Loss: 1.2047 | LR: 0.023955 | Momentum: 0.6680\n",
      "[Epoch 212/300] Batch 700 | G Loss: 0.9332 | D Loss: 1.1707 | LR: 0.023946 | Momentum: 0.6680\n",
      "[Epoch 212/300] Batch 800 | G Loss: 0.8638 | D Loss: 1.1899 | LR: 0.023936 | Momentum: 0.6680\n",
      "[Epoch 213/300] Batch 0 | G Loss: 0.9512 | D Loss: 1.1590 | LR: 0.023930 | Momentum: 0.6688\n",
      "[Epoch 213/300] Batch 100 | G Loss: 0.9549 | D Loss: 1.1133 | LR: 0.023920 | Momentum: 0.6688\n",
      "[Epoch 213/300] Batch 200 | G Loss: 0.9430 | D Loss: 1.1646 | LR: 0.023910 | Momentum: 0.6688\n",
      "[Epoch 213/300] Batch 300 | G Loss: 0.9742 | D Loss: 1.0997 | LR: 0.023901 | Momentum: 0.6688\n",
      "[Epoch 213/300] Batch 400 | G Loss: 0.9063 | D Loss: 1.2256 | LR: 0.023891 | Momentum: 0.6688\n",
      "[Epoch 213/300] Batch 500 | G Loss: 0.9256 | D Loss: 1.1869 | LR: 0.023882 | Momentum: 0.6688\n",
      "[Epoch 213/300] Batch 600 | G Loss: 0.9670 | D Loss: 1.1077 | LR: 0.023872 | Momentum: 0.6688\n",
      "[Epoch 213/300] Batch 700 | G Loss: 0.9665 | D Loss: 1.1268 | LR: 0.023863 | Momentum: 0.6688\n",
      "[Epoch 213/300] Batch 800 | G Loss: 0.9449 | D Loss: 1.1539 | LR: 0.023853 | Momentum: 0.6688\n",
      "[Epoch 214/300] Batch 0 | G Loss: 0.9223 | D Loss: 1.2118 | LR: 0.023846 | Momentum: 0.6696\n",
      "[Epoch 214/300] Batch 100 | G Loss: 0.8725 | D Loss: 1.1995 | LR: 0.023837 | Momentum: 0.6696\n",
      "[Epoch 214/300] Batch 200 | G Loss: 0.9354 | D Loss: 1.1794 | LR: 0.023827 | Momentum: 0.6696\n",
      "[Epoch 214/300] Batch 300 | G Loss: 0.9475 | D Loss: 1.1376 | LR: 0.023818 | Momentum: 0.6696\n",
      "[Epoch 214/300] Batch 400 | G Loss: 0.9807 | D Loss: 1.1575 | LR: 0.023808 | Momentum: 0.6696\n",
      "[Epoch 214/300] Batch 500 | G Loss: 0.9774 | D Loss: 1.2578 | LR: 0.023799 | Momentum: 0.6696\n",
      "[Epoch 214/300] Batch 600 | G Loss: 0.9366 | D Loss: 1.1575 | LR: 0.023789 | Momentum: 0.6696\n",
      "[Epoch 214/300] Batch 700 | G Loss: 0.9118 | D Loss: 1.1787 | LR: 0.023780 | Momentum: 0.6696\n",
      "[Epoch 214/300] Batch 800 | G Loss: 0.9550 | D Loss: 1.1065 | LR: 0.023770 | Momentum: 0.6696\n",
      "[Epoch 215/300] Batch 0 | G Loss: 1.1032 | D Loss: 1.2220 | LR: 0.023764 | Momentum: 0.6704\n",
      "[Epoch 215/300] Batch 100 | G Loss: 0.9488 | D Loss: 1.0889 | LR: 0.023754 | Momentum: 0.6704\n",
      "[Epoch 215/300] Batch 200 | G Loss: 1.0377 | D Loss: 1.0973 | LR: 0.023745 | Momentum: 0.6704\n",
      "[Epoch 215/300] Batch 300 | G Loss: 0.9543 | D Loss: 1.1240 | LR: 0.023735 | Momentum: 0.6704\n",
      "[Epoch 215/300] Batch 400 | G Loss: 0.9095 | D Loss: 1.1169 | LR: 0.023726 | Momentum: 0.6704\n",
      "[Epoch 215/300] Batch 500 | G Loss: 0.9530 | D Loss: 1.2194 | LR: 0.023716 | Momentum: 0.6704\n",
      "[Epoch 215/300] Batch 600 | G Loss: 0.9719 | D Loss: 1.1910 | LR: 0.023707 | Momentum: 0.6704\n",
      "[Epoch 215/300] Batch 700 | G Loss: 0.8837 | D Loss: 1.2246 | LR: 0.023697 | Momentum: 0.6704\n",
      "[Epoch 215/300] Batch 800 | G Loss: 0.9371 | D Loss: 1.1403 | LR: 0.023688 | Momentum: 0.6704\n",
      "[Epoch 216/300] Batch 0 | G Loss: 0.9449 | D Loss: 1.1764 | LR: 0.023681 | Momentum: 0.6712\n",
      "[Epoch 216/300] Batch 100 | G Loss: 0.9295 | D Loss: 1.1277 | LR: 0.023672 | Momentum: 0.6712\n",
      "[Epoch 216/300] Batch 200 | G Loss: 0.9946 | D Loss: 1.1209 | LR: 0.023662 | Momentum: 0.6712\n",
      "[Epoch 216/300] Batch 300 | G Loss: 0.9280 | D Loss: 1.2835 | LR: 0.023653 | Momentum: 0.6712\n",
      "[Epoch 216/300] Batch 400 | G Loss: 0.9252 | D Loss: 1.1646 | LR: 0.023643 | Momentum: 0.6712\n",
      "[Epoch 216/300] Batch 500 | G Loss: 0.9676 | D Loss: 1.1110 | LR: 0.023634 | Momentum: 0.6712\n",
      "[Epoch 216/300] Batch 600 | G Loss: 0.9287 | D Loss: 1.1061 | LR: 0.023625 | Momentum: 0.6712\n",
      "[Epoch 216/300] Batch 700 | G Loss: 0.9690 | D Loss: 1.1393 | LR: 0.023615 | Momentum: 0.6712\n",
      "[Epoch 216/300] Batch 800 | G Loss: 1.0065 | D Loss: 1.2007 | LR: 0.023606 | Momentum: 0.6712\n",
      "[Epoch 217/300] Batch 0 | G Loss: 1.0008 | D Loss: 1.1327 | LR: 0.023599 | Momentum: 0.6720\n",
      "[Epoch 217/300] Batch 100 | G Loss: 0.9292 | D Loss: 1.2572 | LR: 0.023590 | Momentum: 0.6720\n",
      "[Epoch 217/300] Batch 200 | G Loss: 1.0303 | D Loss: 1.0958 | LR: 0.023580 | Momentum: 0.6720\n",
      "[Epoch 217/300] Batch 300 | G Loss: 0.9670 | D Loss: 1.2255 | LR: 0.023571 | Momentum: 0.6720\n",
      "[Epoch 217/300] Batch 400 | G Loss: 0.9719 | D Loss: 1.1837 | LR: 0.023561 | Momentum: 0.6720\n",
      "[Epoch 217/300] Batch 500 | G Loss: 0.9929 | D Loss: 1.1550 | LR: 0.023552 | Momentum: 0.6720\n",
      "[Epoch 217/300] Batch 600 | G Loss: 0.9363 | D Loss: 1.2664 | LR: 0.023543 | Momentum: 0.6720\n",
      "[Epoch 217/300] Batch 700 | G Loss: 1.0024 | D Loss: 1.1848 | LR: 0.023533 | Momentum: 0.6720\n",
      "[Epoch 217/300] Batch 800 | G Loss: 0.9783 | D Loss: 1.1953 | LR: 0.023524 | Momentum: 0.6720\n",
      "[Epoch 218/300] Batch 0 | G Loss: 0.9355 | D Loss: 1.1507 | LR: 0.023517 | Momentum: 0.6728\n",
      "[Epoch 218/300] Batch 100 | G Loss: 0.9401 | D Loss: 1.1446 | LR: 0.023508 | Momentum: 0.6728\n",
      "[Epoch 218/300] Batch 200 | G Loss: 0.9498 | D Loss: 1.1460 | LR: 0.023498 | Momentum: 0.6728\n",
      "[Epoch 218/300] Batch 300 | G Loss: 1.0284 | D Loss: 1.2241 | LR: 0.023489 | Momentum: 0.6728\n",
      "[Epoch 218/300] Batch 400 | G Loss: 1.0067 | D Loss: 1.1738 | LR: 0.023480 | Momentum: 0.6728\n",
      "[Epoch 218/300] Batch 500 | G Loss: 0.9913 | D Loss: 1.1117 | LR: 0.023470 | Momentum: 0.6728\n",
      "[Epoch 218/300] Batch 600 | G Loss: 0.9508 | D Loss: 1.1833 | LR: 0.023461 | Momentum: 0.6728\n",
      "[Epoch 218/300] Batch 700 | G Loss: 0.9622 | D Loss: 1.2317 | LR: 0.023451 | Momentum: 0.6728\n",
      "[Epoch 218/300] Batch 800 | G Loss: 1.0047 | D Loss: 1.1515 | LR: 0.023442 | Momentum: 0.6728\n",
      "[Epoch 219/300] Batch 0 | G Loss: 0.9191 | D Loss: 1.1819 | LR: 0.023436 | Momentum: 0.6736\n",
      "[Epoch 219/300] Batch 100 | G Loss: 0.9235 | D Loss: 1.1798 | LR: 0.023426 | Momentum: 0.6736\n",
      "[Epoch 219/300] Batch 200 | G Loss: 0.9330 | D Loss: 1.1623 | LR: 0.023417 | Momentum: 0.6736\n",
      "[Epoch 219/300] Batch 300 | G Loss: 0.9355 | D Loss: 1.1452 | LR: 0.023408 | Momentum: 0.6736\n",
      "[Epoch 219/300] Batch 400 | G Loss: 0.9695 | D Loss: 1.1709 | LR: 0.023398 | Momentum: 0.6736\n",
      "[Epoch 219/300] Batch 500 | G Loss: 0.9168 | D Loss: 1.1493 | LR: 0.023389 | Momentum: 0.6736\n",
      "[Epoch 219/300] Batch 600 | G Loss: 0.9543 | D Loss: 1.0976 | LR: 0.023379 | Momentum: 0.6736\n",
      "[Epoch 219/300] Batch 700 | G Loss: 1.0206 | D Loss: 1.1439 | LR: 0.023370 | Momentum: 0.6736\n",
      "[Epoch 219/300] Batch 800 | G Loss: 1.0120 | D Loss: 1.0789 | LR: 0.023361 | Momentum: 0.6736\n",
      "[Epoch 220/300] Batch 0 | G Loss: 0.9184 | D Loss: 1.1334 | LR: 0.023354 | Momentum: 0.6744\n",
      "[Epoch 220/300] Batch 100 | G Loss: 0.9451 | D Loss: 1.0944 | LR: 0.023345 | Momentum: 0.6744\n",
      "[Epoch 220/300] Batch 200 | G Loss: 0.9262 | D Loss: 1.1614 | LR: 0.023336 | Momentum: 0.6744\n",
      "[Epoch 220/300] Batch 300 | G Loss: 0.9185 | D Loss: 1.1320 | LR: 0.023326 | Momentum: 0.6744\n",
      "[Epoch 220/300] Batch 400 | G Loss: 0.8939 | D Loss: 1.1586 | LR: 0.023317 | Momentum: 0.6744\n",
      "[Epoch 220/300] Batch 500 | G Loss: 0.9825 | D Loss: 1.1741 | LR: 0.023308 | Momentum: 0.6744\n",
      "[Epoch 220/300] Batch 600 | G Loss: 0.9560 | D Loss: 1.2075 | LR: 0.023298 | Momentum: 0.6744\n",
      "[Epoch 220/300] Batch 700 | G Loss: 0.9829 | D Loss: 1.1171 | LR: 0.023289 | Momentum: 0.6744\n",
      "[Epoch 220/300] Batch 800 | G Loss: 0.9262 | D Loss: 1.1388 | LR: 0.023280 | Momentum: 0.6744\n",
      "[Epoch 221/300] Batch 0 | G Loss: 1.0048 | D Loss: 1.2042 | LR: 0.023273 | Momentum: 0.6752\n",
      "[Epoch 221/300] Batch 100 | G Loss: 0.9450 | D Loss: 1.2819 | LR: 0.023264 | Momentum: 0.6752\n",
      "[Epoch 221/300] Batch 200 | G Loss: 0.9007 | D Loss: 1.2138 | LR: 0.023255 | Momentum: 0.6752\n",
      "[Epoch 221/300] Batch 300 | G Loss: 0.9614 | D Loss: 1.1170 | LR: 0.023245 | Momentum: 0.6752\n",
      "[Epoch 221/300] Batch 400 | G Loss: 0.9733 | D Loss: 1.0250 | LR: 0.023236 | Momentum: 0.6752\n",
      "[Epoch 221/300] Batch 500 | G Loss: 0.9379 | D Loss: 1.1379 | LR: 0.023227 | Momentum: 0.6752\n",
      "[Epoch 221/300] Batch 600 | G Loss: 0.8699 | D Loss: 1.1672 | LR: 0.023217 | Momentum: 0.6752\n",
      "[Epoch 221/300] Batch 700 | G Loss: 0.9543 | D Loss: 1.1724 | LR: 0.023208 | Momentum: 0.6752\n",
      "[Epoch 221/300] Batch 800 | G Loss: 0.9896 | D Loss: 1.2661 | LR: 0.023199 | Momentum: 0.6752\n",
      "[Epoch 222/300] Batch 0 | G Loss: 0.8693 | D Loss: 1.1094 | LR: 0.023192 | Momentum: 0.6760\n",
      "[Epoch 222/300] Batch 100 | G Loss: 1.0400 | D Loss: 1.0974 | LR: 0.023183 | Momentum: 0.6760\n",
      "[Epoch 222/300] Batch 200 | G Loss: 0.9445 | D Loss: 1.2014 | LR: 0.023174 | Momentum: 0.6760\n",
      "[Epoch 222/300] Batch 300 | G Loss: 0.9917 | D Loss: 1.2068 | LR: 0.023165 | Momentum: 0.6760\n",
      "[Epoch 222/300] Batch 400 | G Loss: 0.9534 | D Loss: 1.1701 | LR: 0.023155 | Momentum: 0.6760\n",
      "[Epoch 222/300] Batch 500 | G Loss: 0.9564 | D Loss: 1.1500 | LR: 0.023146 | Momentum: 0.6760\n",
      "[Epoch 222/300] Batch 600 | G Loss: 0.9665 | D Loss: 1.1681 | LR: 0.023137 | Momentum: 0.6760\n",
      "[Epoch 222/300] Batch 700 | G Loss: 0.9688 | D Loss: 1.2416 | LR: 0.023128 | Momentum: 0.6760\n",
      "[Epoch 222/300] Batch 800 | G Loss: 0.9775 | D Loss: 1.2199 | LR: 0.023118 | Momentum: 0.6760\n",
      "[Epoch 223/300] Batch 0 | G Loss: 0.9606 | D Loss: 1.1744 | LR: 0.023112 | Momentum: 0.6768\n",
      "[Epoch 223/300] Batch 100 | G Loss: 0.9106 | D Loss: 1.0740 | LR: 0.023103 | Momentum: 0.6768\n",
      "[Epoch 223/300] Batch 200 | G Loss: 0.9166 | D Loss: 1.1032 | LR: 0.023094 | Momentum: 0.6768\n",
      "[Epoch 223/300] Batch 300 | G Loss: 0.9583 | D Loss: 1.2241 | LR: 0.023084 | Momentum: 0.6768\n",
      "[Epoch 223/300] Batch 400 | G Loss: 0.9428 | D Loss: 1.2050 | LR: 0.023075 | Momentum: 0.6768\n",
      "[Epoch 223/300] Batch 500 | G Loss: 0.8922 | D Loss: 1.1566 | LR: 0.023066 | Momentum: 0.6768\n",
      "[Epoch 223/300] Batch 600 | G Loss: 1.0768 | D Loss: 1.1679 | LR: 0.023057 | Momentum: 0.6768\n",
      "[Epoch 223/300] Batch 700 | G Loss: 0.9457 | D Loss: 1.1583 | LR: 0.023047 | Momentum: 0.6768\n",
      "[Epoch 223/300] Batch 800 | G Loss: 0.8398 | D Loss: 1.1585 | LR: 0.023038 | Momentum: 0.6768\n",
      "[Epoch 224/300] Batch 0 | G Loss: 0.9606 | D Loss: 1.1808 | LR: 0.023032 | Momentum: 0.6776\n",
      "[Epoch 224/300] Batch 100 | G Loss: 0.9286 | D Loss: 1.1903 | LR: 0.023023 | Momentum: 0.6776\n",
      "[Epoch 224/300] Batch 200 | G Loss: 1.0481 | D Loss: 1.1432 | LR: 0.023013 | Momentum: 0.6776\n",
      "[Epoch 224/300] Batch 300 | G Loss: 0.9841 | D Loss: 1.1284 | LR: 0.023004 | Momentum: 0.6776\n",
      "[Epoch 224/300] Batch 400 | G Loss: 0.9304 | D Loss: 1.1772 | LR: 0.022995 | Momentum: 0.6776\n",
      "[Epoch 224/300] Batch 500 | G Loss: 0.9577 | D Loss: 1.1003 | LR: 0.022986 | Momentum: 0.6776\n",
      "[Epoch 224/300] Batch 600 | G Loss: 0.9218 | D Loss: 1.1049 | LR: 0.022977 | Momentum: 0.6776\n",
      "[Epoch 224/300] Batch 700 | G Loss: 1.0007 | D Loss: 1.2018 | LR: 0.022967 | Momentum: 0.6776\n",
      "[Epoch 224/300] Batch 800 | G Loss: 0.9049 | D Loss: 1.1446 | LR: 0.022958 | Momentum: 0.6776\n",
      "[Epoch 225/300] Batch 0 | G Loss: 0.9099 | D Loss: 1.1103 | LR: 0.022952 | Momentum: 0.6784\n",
      "[Epoch 225/300] Batch 100 | G Loss: 0.9659 | D Loss: 1.2057 | LR: 0.022943 | Momentum: 0.6784\n",
      "[Epoch 225/300] Batch 200 | G Loss: 0.9497 | D Loss: 1.0736 | LR: 0.022934 | Momentum: 0.6784\n",
      "[Epoch 225/300] Batch 300 | G Loss: 0.9831 | D Loss: 1.1121 | LR: 0.022924 | Momentum: 0.6784\n",
      "[Epoch 225/300] Batch 400 | G Loss: 1.0304 | D Loss: 1.1207 | LR: 0.022915 | Momentum: 0.6784\n",
      "[Epoch 225/300] Batch 500 | G Loss: 0.9357 | D Loss: 1.1502 | LR: 0.022906 | Momentum: 0.6784\n",
      "[Epoch 225/300] Batch 600 | G Loss: 0.9604 | D Loss: 1.1621 | LR: 0.022897 | Momentum: 0.6784\n",
      "[Epoch 225/300] Batch 700 | G Loss: 0.9796 | D Loss: 1.1724 | LR: 0.022888 | Momentum: 0.6784\n",
      "[Epoch 225/300] Batch 800 | G Loss: 0.9279 | D Loss: 1.2417 | LR: 0.022879 | Momentum: 0.6784\n",
      "[Epoch 226/300] Batch 0 | G Loss: 0.9862 | D Loss: 1.1199 | LR: 0.022872 | Momentum: 0.6792\n",
      "[Epoch 226/300] Batch 100 | G Loss: 0.9742 | D Loss: 1.1360 | LR: 0.022863 | Momentum: 0.6792\n",
      "[Epoch 226/300] Batch 200 | G Loss: 0.9855 | D Loss: 1.1478 | LR: 0.022854 | Momentum: 0.6792\n",
      "[Epoch 226/300] Batch 300 | G Loss: 0.9635 | D Loss: 1.1182 | LR: 0.022845 | Momentum: 0.6792\n",
      "[Epoch 226/300] Batch 400 | G Loss: 0.9413 | D Loss: 1.1392 | LR: 0.022836 | Momentum: 0.6792\n",
      "[Epoch 226/300] Batch 500 | G Loss: 0.9258 | D Loss: 1.2043 | LR: 0.022827 | Momentum: 0.6792\n",
      "[Epoch 226/300] Batch 600 | G Loss: 0.9761 | D Loss: 1.2366 | LR: 0.022817 | Momentum: 0.6792\n",
      "[Epoch 226/300] Batch 700 | G Loss: 0.9449 | D Loss: 1.2067 | LR: 0.022808 | Momentum: 0.6792\n",
      "[Epoch 226/300] Batch 800 | G Loss: 1.0159 | D Loss: 1.1855 | LR: 0.022799 | Momentum: 0.6792\n",
      "[Epoch 227/300] Batch 0 | G Loss: 0.9224 | D Loss: 1.1164 | LR: 0.022793 | Momentum: 0.6800\n",
      "[Epoch 227/300] Batch 100 | G Loss: 0.9310 | D Loss: 1.0872 | LR: 0.022784 | Momentum: 0.6800\n",
      "[Epoch 227/300] Batch 200 | G Loss: 0.9603 | D Loss: 1.1181 | LR: 0.022775 | Momentum: 0.6800\n",
      "[Epoch 227/300] Batch 300 | G Loss: 0.9274 | D Loss: 1.1121 | LR: 0.022766 | Momentum: 0.6800\n",
      "[Epoch 227/300] Batch 400 | G Loss: 1.0087 | D Loss: 1.1723 | LR: 0.022756 | Momentum: 0.6800\n",
      "[Epoch 227/300] Batch 500 | G Loss: 0.9516 | D Loss: 1.2092 | LR: 0.022747 | Momentum: 0.6800\n",
      "[Epoch 227/300] Batch 600 | G Loss: 0.9455 | D Loss: 1.1552 | LR: 0.022738 | Momentum: 0.6800\n",
      "[Epoch 227/300] Batch 700 | G Loss: 0.9439 | D Loss: 1.1675 | LR: 0.022729 | Momentum: 0.6800\n",
      "[Epoch 227/300] Batch 800 | G Loss: 0.9727 | D Loss: 1.1608 | LR: 0.022720 | Momentum: 0.6800\n",
      "[Epoch 228/300] Batch 0 | G Loss: 0.9284 | D Loss: 1.2002 | LR: 0.022714 | Momentum: 0.6808\n",
      "[Epoch 228/300] Batch 100 | G Loss: 0.9478 | D Loss: 1.2241 | LR: 0.022705 | Momentum: 0.6808\n",
      "[Epoch 228/300] Batch 200 | G Loss: 0.9800 | D Loss: 1.1696 | LR: 0.022696 | Momentum: 0.6808\n",
      "[Epoch 228/300] Batch 300 | G Loss: 0.9496 | D Loss: 1.1413 | LR: 0.022687 | Momentum: 0.6808\n",
      "[Epoch 228/300] Batch 400 | G Loss: 0.9753 | D Loss: 1.0920 | LR: 0.022677 | Momentum: 0.6808\n",
      "[Epoch 228/300] Batch 500 | G Loss: 0.9173 | D Loss: 1.1581 | LR: 0.022668 | Momentum: 0.6808\n",
      "[Epoch 228/300] Batch 600 | G Loss: 0.9571 | D Loss: 1.1059 | LR: 0.022659 | Momentum: 0.6808\n",
      "[Epoch 228/300] Batch 700 | G Loss: 0.9100 | D Loss: 1.2476 | LR: 0.022650 | Momentum: 0.6808\n",
      "[Epoch 228/300] Batch 800 | G Loss: 1.0141 | D Loss: 1.1079 | LR: 0.022641 | Momentum: 0.6808\n",
      "[Epoch 229/300] Batch 0 | G Loss: 0.9329 | D Loss: 1.2113 | LR: 0.022635 | Momentum: 0.6816\n",
      "[Epoch 229/300] Batch 100 | G Loss: 0.9258 | D Loss: 1.1497 | LR: 0.022626 | Momentum: 0.6816\n",
      "[Epoch 229/300] Batch 200 | G Loss: 0.9182 | D Loss: 1.1448 | LR: 0.022617 | Momentum: 0.6816\n",
      "[Epoch 229/300] Batch 300 | G Loss: 0.9763 | D Loss: 1.1303 | LR: 0.022608 | Momentum: 0.6816\n",
      "[Epoch 229/300] Batch 400 | G Loss: 0.9351 | D Loss: 1.2419 | LR: 0.022599 | Momentum: 0.6816\n",
      "[Epoch 229/300] Batch 500 | G Loss: 0.9945 | D Loss: 1.2374 | LR: 0.022590 | Momentum: 0.6816\n",
      "[Epoch 229/300] Batch 600 | G Loss: 0.9407 | D Loss: 1.1835 | LR: 0.022581 | Momentum: 0.6816\n",
      "[Epoch 229/300] Batch 700 | G Loss: 0.9413 | D Loss: 1.1513 | LR: 0.022572 | Momentum: 0.6816\n",
      "[Epoch 229/300] Batch 800 | G Loss: 0.9508 | D Loss: 1.1630 | LR: 0.022563 | Momentum: 0.6816\n",
      "[Epoch 230/300] Batch 0 | G Loss: 0.9669 | D Loss: 1.1554 | LR: 0.022556 | Momentum: 0.6824\n",
      "[Epoch 230/300] Batch 100 | G Loss: 0.9280 | D Loss: 1.1294 | LR: 0.022547 | Momentum: 0.6824\n",
      "[Epoch 230/300] Batch 200 | G Loss: 0.9807 | D Loss: 1.2074 | LR: 0.022538 | Momentum: 0.6824\n",
      "[Epoch 230/300] Batch 300 | G Loss: 0.9468 | D Loss: 1.1882 | LR: 0.022529 | Momentum: 0.6824\n",
      "[Epoch 230/300] Batch 400 | G Loss: 0.9926 | D Loss: 1.0957 | LR: 0.022520 | Momentum: 0.6824\n",
      "[Epoch 230/300] Batch 500 | G Loss: 0.9589 | D Loss: 1.1249 | LR: 0.022511 | Momentum: 0.6824\n",
      "[Epoch 230/300] Batch 600 | G Loss: 0.9252 | D Loss: 1.1796 | LR: 0.022502 | Momentum: 0.6824\n",
      "[Epoch 230/300] Batch 700 | G Loss: 0.9267 | D Loss: 1.2265 | LR: 0.022493 | Momentum: 0.6824\n",
      "[Epoch 230/300] Batch 800 | G Loss: 0.9789 | D Loss: 1.1156 | LR: 0.022484 | Momentum: 0.6824\n",
      "[Epoch 231/300] Batch 0 | G Loss: 0.9983 | D Loss: 1.2347 | LR: 0.022478 | Momentum: 0.6832\n",
      "[Epoch 231/300] Batch 100 | G Loss: 0.9032 | D Loss: 1.1643 | LR: 0.022469 | Momentum: 0.6832\n",
      "[Epoch 231/300] Batch 200 | G Loss: 0.9357 | D Loss: 1.0952 | LR: 0.022460 | Momentum: 0.6832\n",
      "[Epoch 231/300] Batch 300 | G Loss: 0.9128 | D Loss: 1.2896 | LR: 0.022451 | Momentum: 0.6832\n",
      "[Epoch 231/300] Batch 400 | G Loss: 0.9309 | D Loss: 1.1346 | LR: 0.022442 | Momentum: 0.6832\n",
      "[Epoch 231/300] Batch 500 | G Loss: 0.9470 | D Loss: 1.1154 | LR: 0.022433 | Momentum: 0.6832\n",
      "[Epoch 231/300] Batch 600 | G Loss: 0.9067 | D Loss: 1.2357 | LR: 0.022424 | Momentum: 0.6832\n",
      "[Epoch 231/300] Batch 700 | G Loss: 1.0021 | D Loss: 1.0794 | LR: 0.022415 | Momentum: 0.6832\n",
      "[Epoch 231/300] Batch 800 | G Loss: 0.9661 | D Loss: 1.3326 | LR: 0.022406 | Momentum: 0.6832\n",
      "[Epoch 232/300] Batch 0 | G Loss: 0.9512 | D Loss: 1.1681 | LR: 0.022400 | Momentum: 0.6840\n",
      "[Epoch 232/300] Batch 100 | G Loss: 0.9557 | D Loss: 1.1919 | LR: 0.022391 | Momentum: 0.6840\n",
      "[Epoch 232/300] Batch 200 | G Loss: 0.9417 | D Loss: 1.0950 | LR: 0.022382 | Momentum: 0.6840\n",
      "[Epoch 232/300] Batch 300 | G Loss: 0.9502 | D Loss: 1.1009 | LR: 0.022373 | Momentum: 0.6840\n",
      "[Epoch 232/300] Batch 400 | G Loss: 0.9452 | D Loss: 1.1433 | LR: 0.022364 | Momentum: 0.6840\n",
      "[Epoch 232/300] Batch 500 | G Loss: 0.9542 | D Loss: 1.2119 | LR: 0.022355 | Momentum: 0.6840\n",
      "[Epoch 232/300] Batch 600 | G Loss: 0.9709 | D Loss: 1.1596 | LR: 0.022346 | Momentum: 0.6840\n",
      "[Epoch 232/300] Batch 700 | G Loss: 0.9136 | D Loss: 1.1424 | LR: 0.022338 | Momentum: 0.6840\n",
      "[Epoch 232/300] Batch 800 | G Loss: 1.0105 | D Loss: 1.2369 | LR: 0.022329 | Momentum: 0.6840\n",
      "[Epoch 233/300] Batch 0 | G Loss: 0.9046 | D Loss: 1.1455 | LR: 0.022322 | Momentum: 0.6848\n",
      "[Epoch 233/300] Batch 100 | G Loss: 0.9595 | D Loss: 1.1166 | LR: 0.022314 | Momentum: 0.6848\n",
      "[Epoch 233/300] Batch 200 | G Loss: 0.9989 | D Loss: 1.0701 | LR: 0.022305 | Momentum: 0.6848\n",
      "[Epoch 233/300] Batch 300 | G Loss: 0.9831 | D Loss: 1.1941 | LR: 0.022296 | Momentum: 0.6848\n",
      "[Epoch 233/300] Batch 400 | G Loss: 0.9780 | D Loss: 1.1168 | LR: 0.022287 | Momentum: 0.6848\n",
      "[Epoch 233/300] Batch 500 | G Loss: 0.8776 | D Loss: 1.0879 | LR: 0.022278 | Momentum: 0.6848\n",
      "[Epoch 233/300] Batch 600 | G Loss: 0.9951 | D Loss: 1.1907 | LR: 0.022269 | Momentum: 0.6848\n",
      "[Epoch 233/300] Batch 700 | G Loss: 0.9881 | D Loss: 1.0810 | LR: 0.022260 | Momentum: 0.6848\n",
      "[Epoch 233/300] Batch 800 | G Loss: 0.8907 | D Loss: 1.1226 | LR: 0.022251 | Momentum: 0.6848\n",
      "[Epoch 234/300] Batch 0 | G Loss: 0.9562 | D Loss: 1.1515 | LR: 0.022245 | Momentum: 0.6856\n",
      "[Epoch 234/300] Batch 100 | G Loss: 0.9786 | D Loss: 1.1053 | LR: 0.022236 | Momentum: 0.6856\n",
      "[Epoch 234/300] Batch 200 | G Loss: 0.9012 | D Loss: 1.1988 | LR: 0.022227 | Momentum: 0.6856\n",
      "[Epoch 234/300] Batch 300 | G Loss: 0.9434 | D Loss: 1.1671 | LR: 0.022218 | Momentum: 0.6856\n",
      "[Epoch 234/300] Batch 400 | G Loss: 0.9348 | D Loss: 1.1401 | LR: 0.022209 | Momentum: 0.6856\n",
      "[Epoch 234/300] Batch 500 | G Loss: 0.9646 | D Loss: 1.1798 | LR: 0.022201 | Momentum: 0.6856\n",
      "[Epoch 234/300] Batch 600 | G Loss: 0.9710 | D Loss: 1.2396 | LR: 0.022192 | Momentum: 0.6856\n",
      "[Epoch 234/300] Batch 700 | G Loss: 0.9342 | D Loss: 1.1341 | LR: 0.022183 | Momentum: 0.6856\n",
      "[Epoch 234/300] Batch 800 | G Loss: 0.9719 | D Loss: 1.0436 | LR: 0.022174 | Momentum: 0.6856\n",
      "[Epoch 235/300] Batch 0 | G Loss: 0.9283 | D Loss: 1.1416 | LR: 0.022168 | Momentum: 0.6864\n",
      "[Epoch 235/300] Batch 100 | G Loss: 0.9937 | D Loss: 1.0623 | LR: 0.022159 | Momentum: 0.6864\n",
      "[Epoch 235/300] Batch 200 | G Loss: 1.0360 | D Loss: 1.1378 | LR: 0.022150 | Momentum: 0.6864\n",
      "[Epoch 235/300] Batch 300 | G Loss: 0.9508 | D Loss: 1.0865 | LR: 0.022141 | Momentum: 0.6864\n",
      "[Epoch 235/300] Batch 400 | G Loss: 0.9607 | D Loss: 1.1712 | LR: 0.022132 | Momentum: 0.6864\n",
      "[Epoch 235/300] Batch 500 | G Loss: 0.9995 | D Loss: 1.2305 | LR: 0.022124 | Momentum: 0.6864\n",
      "[Epoch 235/300] Batch 600 | G Loss: 0.9280 | D Loss: 1.1172 | LR: 0.022115 | Momentum: 0.6864\n",
      "[Epoch 235/300] Batch 700 | G Loss: 0.8963 | D Loss: 1.1429 | LR: 0.022106 | Momentum: 0.6864\n",
      "[Epoch 235/300] Batch 800 | G Loss: 0.9660 | D Loss: 1.2052 | LR: 0.022097 | Momentum: 0.6864\n",
      "[Epoch 236/300] Batch 0 | G Loss: 0.8931 | D Loss: 1.1732 | LR: 0.022091 | Momentum: 0.6872\n",
      "[Epoch 236/300] Batch 100 | G Loss: 0.9681 | D Loss: 1.2215 | LR: 0.022082 | Momentum: 0.6872\n",
      "[Epoch 236/300] Batch 200 | G Loss: 0.9370 | D Loss: 1.1583 | LR: 0.022073 | Momentum: 0.6872\n",
      "[Epoch 236/300] Batch 300 | G Loss: 0.9523 | D Loss: 1.2038 | LR: 0.022064 | Momentum: 0.6872\n",
      "[Epoch 236/300] Batch 400 | G Loss: 0.9327 | D Loss: 1.1709 | LR: 0.022056 | Momentum: 0.6872\n",
      "[Epoch 236/300] Batch 500 | G Loss: 0.9395 | D Loss: 1.1350 | LR: 0.022047 | Momentum: 0.6872\n",
      "[Epoch 236/300] Batch 600 | G Loss: 0.9723 | D Loss: 1.1978 | LR: 0.022038 | Momentum: 0.6872\n",
      "[Epoch 236/300] Batch 700 | G Loss: 0.9066 | D Loss: 1.1473 | LR: 0.022029 | Momentum: 0.6872\n",
      "[Epoch 236/300] Batch 800 | G Loss: 0.9186 | D Loss: 1.0641 | LR: 0.022020 | Momentum: 0.6872\n",
      "[Epoch 237/300] Batch 0 | G Loss: 0.9019 | D Loss: 1.1643 | LR: 0.022014 | Momentum: 0.6880\n",
      "[Epoch 237/300] Batch 100 | G Loss: 0.8918 | D Loss: 1.1315 | LR: 0.022005 | Momentum: 0.6880\n",
      "[Epoch 237/300] Batch 200 | G Loss: 0.9000 | D Loss: 1.2055 | LR: 0.021997 | Momentum: 0.6880\n",
      "[Epoch 237/300] Batch 300 | G Loss: 0.8687 | D Loss: 1.2047 | LR: 0.021988 | Momentum: 0.6880\n",
      "[Epoch 237/300] Batch 400 | G Loss: 0.9572 | D Loss: 1.2087 | LR: 0.021979 | Momentum: 0.6880\n",
      "[Epoch 237/300] Batch 500 | G Loss: 0.9654 | D Loss: 1.1080 | LR: 0.021970 | Momentum: 0.6880\n",
      "[Epoch 237/300] Batch 600 | G Loss: 0.9641 | D Loss: 1.2176 | LR: 0.021961 | Momentum: 0.6880\n",
      "[Epoch 237/300] Batch 700 | G Loss: 0.9709 | D Loss: 1.2256 | LR: 0.021953 | Momentum: 0.6880\n",
      "[Epoch 237/300] Batch 800 | G Loss: 0.9687 | D Loss: 1.1058 | LR: 0.021944 | Momentum: 0.6880\n",
      "[Epoch 238/300] Batch 0 | G Loss: 0.9278 | D Loss: 1.0766 | LR: 0.021938 | Momentum: 0.6888\n",
      "[Epoch 238/300] Batch 100 | G Loss: 1.0063 | D Loss: 1.0529 | LR: 0.021929 | Momentum: 0.6888\n",
      "[Epoch 238/300] Batch 200 | G Loss: 0.9611 | D Loss: 1.1695 | LR: 0.021920 | Momentum: 0.6888\n",
      "[Epoch 238/300] Batch 300 | G Loss: 1.0087 | D Loss: 1.1588 | LR: 0.021912 | Momentum: 0.6888\n",
      "[Epoch 238/300] Batch 400 | G Loss: 0.9909 | D Loss: 1.1852 | LR: 0.021903 | Momentum: 0.6888\n",
      "[Epoch 238/300] Batch 500 | G Loss: 0.9536 | D Loss: 1.1547 | LR: 0.021894 | Momentum: 0.6888\n",
      "[Epoch 238/300] Batch 600 | G Loss: 0.9431 | D Loss: 1.1609 | LR: 0.021885 | Momentum: 0.6888\n",
      "[Epoch 238/300] Batch 700 | G Loss: 0.9257 | D Loss: 0.9803 | LR: 0.021876 | Momentum: 0.6888\n",
      "[Epoch 238/300] Batch 800 | G Loss: 0.9745 | D Loss: 1.1422 | LR: 0.021868 | Momentum: 0.6888\n",
      "[Epoch 239/300] Batch 0 | G Loss: 0.9245 | D Loss: 1.2361 | LR: 0.021862 | Momentum: 0.6896\n",
      "[Epoch 239/300] Batch 100 | G Loss: 0.9579 | D Loss: 1.2079 | LR: 0.021853 | Momentum: 0.6896\n",
      "[Epoch 239/300] Batch 200 | G Loss: 0.9907 | D Loss: 1.1909 | LR: 0.021844 | Momentum: 0.6896\n",
      "[Epoch 239/300] Batch 300 | G Loss: 0.9755 | D Loss: 1.1088 | LR: 0.021835 | Momentum: 0.6896\n",
      "[Epoch 239/300] Batch 400 | G Loss: 0.9806 | D Loss: 1.1633 | LR: 0.021827 | Momentum: 0.6896\n",
      "[Epoch 239/300] Batch 500 | G Loss: 1.0090 | D Loss: 1.1143 | LR: 0.021818 | Momentum: 0.6896\n",
      "[Epoch 239/300] Batch 600 | G Loss: 0.9520 | D Loss: 1.2106 | LR: 0.021809 | Momentum: 0.6896\n",
      "[Epoch 239/300] Batch 700 | G Loss: 0.9064 | D Loss: 1.1799 | LR: 0.021801 | Momentum: 0.6896\n",
      "[Epoch 239/300] Batch 800 | G Loss: 0.9245 | D Loss: 1.2428 | LR: 0.021792 | Momentum: 0.6896\n",
      "[Epoch 240/300] Batch 0 | G Loss: 0.9404 | D Loss: 1.1719 | LR: 0.021786 | Momentum: 0.6904\n",
      "[Epoch 240/300] Batch 100 | G Loss: 0.9437 | D Loss: 1.1807 | LR: 0.021777 | Momentum: 0.6904\n",
      "[Epoch 240/300] Batch 200 | G Loss: 0.9526 | D Loss: 1.1495 | LR: 0.021768 | Momentum: 0.6904\n",
      "[Epoch 240/300] Batch 300 | G Loss: 0.9676 | D Loss: 1.1106 | LR: 0.021760 | Momentum: 0.6904\n",
      "[Epoch 240/300] Batch 400 | G Loss: 0.9394 | D Loss: 1.2525 | LR: 0.021751 | Momentum: 0.6904\n",
      "[Epoch 240/300] Batch 500 | G Loss: 0.9762 | D Loss: 1.1750 | LR: 0.021742 | Momentum: 0.6904\n",
      "[Epoch 240/300] Batch 600 | G Loss: 0.8945 | D Loss: 1.1579 | LR: 0.021734 | Momentum: 0.6904\n",
      "[Epoch 240/300] Batch 700 | G Loss: 0.9997 | D Loss: 1.1271 | LR: 0.021725 | Momentum: 0.6904\n",
      "[Epoch 240/300] Batch 800 | G Loss: 0.8550 | D Loss: 1.2724 | LR: 0.021716 | Momentum: 0.6904\n",
      "[Epoch 241/300] Batch 0 | G Loss: 0.9237 | D Loss: 1.2090 | LR: 0.021710 | Momentum: 0.6912\n",
      "[Epoch 241/300] Batch 100 | G Loss: 0.9415 | D Loss: 1.1739 | LR: 0.021702 | Momentum: 0.6912\n",
      "[Epoch 241/300] Batch 200 | G Loss: 0.9358 | D Loss: 1.1466 | LR: 0.021693 | Momentum: 0.6912\n",
      "[Epoch 241/300] Batch 300 | G Loss: 1.0149 | D Loss: 1.1042 | LR: 0.021684 | Momentum: 0.6912\n",
      "[Epoch 241/300] Batch 400 | G Loss: 0.9274 | D Loss: 1.2816 | LR: 0.021676 | Momentum: 0.6912\n",
      "[Epoch 241/300] Batch 500 | G Loss: 1.0114 | D Loss: 1.2475 | LR: 0.021667 | Momentum: 0.6912\n",
      "[Epoch 241/300] Batch 600 | G Loss: 1.0422 | D Loss: 1.1993 | LR: 0.021658 | Momentum: 0.6912\n",
      "[Epoch 241/300] Batch 700 | G Loss: 0.9836 | D Loss: 1.1465 | LR: 0.021650 | Momentum: 0.6912\n",
      "[Epoch 241/300] Batch 800 | G Loss: 0.9908 | D Loss: 1.1098 | LR: 0.021641 | Momentum: 0.6912\n",
      "[Epoch 242/300] Batch 0 | G Loss: 0.9640 | D Loss: 1.0727 | LR: 0.021635 | Momentum: 0.6920\n",
      "[Epoch 242/300] Batch 100 | G Loss: 0.9962 | D Loss: 1.1681 | LR: 0.021626 | Momentum: 0.6920\n",
      "[Epoch 242/300] Batch 200 | G Loss: 0.9556 | D Loss: 1.2889 | LR: 0.021618 | Momentum: 0.6920\n",
      "[Epoch 242/300] Batch 300 | G Loss: 0.9958 | D Loss: 1.2077 | LR: 0.021609 | Momentum: 0.6920\n",
      "[Epoch 242/300] Batch 400 | G Loss: 1.0238 | D Loss: 1.1747 | LR: 0.021600 | Momentum: 0.6920\n",
      "[Epoch 242/300] Batch 500 | G Loss: 1.0023 | D Loss: 1.1637 | LR: 0.021592 | Momentum: 0.6920\n",
      "[Epoch 242/300] Batch 600 | G Loss: 0.9326 | D Loss: 1.1828 | LR: 0.021583 | Momentum: 0.6920\n",
      "[Epoch 242/300] Batch 700 | G Loss: 0.9918 | D Loss: 1.2256 | LR: 0.021574 | Momentum: 0.6920\n",
      "[Epoch 242/300] Batch 800 | G Loss: 0.9478 | D Loss: 1.2122 | LR: 0.021566 | Momentum: 0.6920\n",
      "[Epoch 243/300] Batch 0 | G Loss: 0.9780 | D Loss: 1.2501 | LR: 0.021560 | Momentum: 0.6928\n",
      "[Epoch 243/300] Batch 100 | G Loss: 0.9549 | D Loss: 1.1784 | LR: 0.021551 | Momentum: 0.6928\n",
      "[Epoch 243/300] Batch 200 | G Loss: 0.9961 | D Loss: 1.1261 | LR: 0.021543 | Momentum: 0.6928\n",
      "[Epoch 243/300] Batch 300 | G Loss: 0.9672 | D Loss: 1.2264 | LR: 0.021534 | Momentum: 0.6928\n",
      "[Epoch 243/300] Batch 400 | G Loss: 0.8942 | D Loss: 1.2468 | LR: 0.021525 | Momentum: 0.6928\n",
      "[Epoch 243/300] Batch 500 | G Loss: 0.9068 | D Loss: 1.2003 | LR: 0.021517 | Momentum: 0.6928\n",
      "[Epoch 243/300] Batch 600 | G Loss: 0.9639 | D Loss: 1.1525 | LR: 0.021508 | Momentum: 0.6928\n",
      "[Epoch 243/300] Batch 700 | G Loss: 0.9697 | D Loss: 1.1610 | LR: 0.021500 | Momentum: 0.6928\n",
      "[Epoch 243/300] Batch 800 | G Loss: 0.9731 | D Loss: 1.1648 | LR: 0.021491 | Momentum: 0.6928\n",
      "[Epoch 244/300] Batch 0 | G Loss: 0.9538 | D Loss: 1.1655 | LR: 0.021485 | Momentum: 0.6936\n",
      "[Epoch 244/300] Batch 100 | G Loss: 1.0273 | D Loss: 1.1282 | LR: 0.021476 | Momentum: 0.6936\n",
      "[Epoch 244/300] Batch 200 | G Loss: 1.0189 | D Loss: 1.1494 | LR: 0.021468 | Momentum: 0.6936\n",
      "[Epoch 244/300] Batch 300 | G Loss: 0.9359 | D Loss: 1.1655 | LR: 0.021459 | Momentum: 0.6936\n",
      "[Epoch 244/300] Batch 400 | G Loss: 0.9310 | D Loss: 1.2471 | LR: 0.021451 | Momentum: 0.6936\n",
      "[Epoch 244/300] Batch 500 | G Loss: 0.9335 | D Loss: 1.2720 | LR: 0.021442 | Momentum: 0.6936\n",
      "[Epoch 244/300] Batch 600 | G Loss: 0.9457 | D Loss: 1.2377 | LR: 0.021434 | Momentum: 0.6936\n",
      "[Epoch 244/300] Batch 700 | G Loss: 0.9206 | D Loss: 1.1225 | LR: 0.021425 | Momentum: 0.6936\n",
      "[Epoch 244/300] Batch 800 | G Loss: 0.9948 | D Loss: 1.1726 | LR: 0.021416 | Momentum: 0.6936\n",
      "[Epoch 245/300] Batch 0 | G Loss: 0.9409 | D Loss: 1.1820 | LR: 0.021410 | Momentum: 0.6944\n",
      "[Epoch 245/300] Batch 100 | G Loss: 0.9631 | D Loss: 1.0932 | LR: 0.021402 | Momentum: 0.6944\n",
      "[Epoch 245/300] Batch 200 | G Loss: 0.9765 | D Loss: 1.1554 | LR: 0.021393 | Momentum: 0.6944\n",
      "[Epoch 245/300] Batch 300 | G Loss: 0.9141 | D Loss: 1.1724 | LR: 0.021385 | Momentum: 0.6944\n",
      "[Epoch 245/300] Batch 400 | G Loss: 1.0194 | D Loss: 1.2122 | LR: 0.021376 | Momentum: 0.6944\n",
      "[Epoch 245/300] Batch 500 | G Loss: 0.9350 | D Loss: 1.1194 | LR: 0.021368 | Momentum: 0.6944\n",
      "[Epoch 245/300] Batch 600 | G Loss: 0.9473 | D Loss: 1.1454 | LR: 0.021359 | Momentum: 0.6944\n",
      "[Epoch 245/300] Batch 700 | G Loss: 0.9205 | D Loss: 1.2485 | LR: 0.021351 | Momentum: 0.6944\n",
      "[Epoch 245/300] Batch 800 | G Loss: 0.9175 | D Loss: 1.2313 | LR: 0.021342 | Momentum: 0.6944\n",
      "[Epoch 246/300] Batch 0 | G Loss: 0.9799 | D Loss: 1.1844 | LR: 0.021336 | Momentum: 0.6952\n",
      "[Epoch 246/300] Batch 100 | G Loss: 0.9497 | D Loss: 1.1896 | LR: 0.021328 | Momentum: 0.6952\n",
      "[Epoch 246/300] Batch 200 | G Loss: 0.9760 | D Loss: 1.1167 | LR: 0.021319 | Momentum: 0.6952\n",
      "[Epoch 246/300] Batch 300 | G Loss: 0.9310 | D Loss: 1.1834 | LR: 0.021311 | Momentum: 0.6952\n",
      "[Epoch 246/300] Batch 400 | G Loss: 0.9618 | D Loss: 1.1785 | LR: 0.021302 | Momentum: 0.6952\n",
      "[Epoch 246/300] Batch 500 | G Loss: 0.9769 | D Loss: 1.2943 | LR: 0.021294 | Momentum: 0.6952\n",
      "[Epoch 246/300] Batch 600 | G Loss: 1.0086 | D Loss: 1.1523 | LR: 0.021285 | Momentum: 0.6952\n",
      "[Epoch 246/300] Batch 700 | G Loss: 0.9841 | D Loss: 1.2606 | LR: 0.021277 | Momentum: 0.6952\n",
      "[Epoch 246/300] Batch 800 | G Loss: 0.9293 | D Loss: 1.0981 | LR: 0.021268 | Momentum: 0.6952\n",
      "[Epoch 247/300] Batch 0 | G Loss: 0.9770 | D Loss: 1.2938 | LR: 0.021262 | Momentum: 0.6960\n",
      "[Epoch 247/300] Batch 100 | G Loss: 1.0204 | D Loss: 1.0588 | LR: 0.021254 | Momentum: 0.6960\n",
      "[Epoch 247/300] Batch 200 | G Loss: 0.9449 | D Loss: 1.2369 | LR: 0.021245 | Momentum: 0.6960\n",
      "[Epoch 247/300] Batch 300 | G Loss: 0.9148 | D Loss: 1.2607 | LR: 0.021237 | Momentum: 0.6960\n",
      "[Epoch 247/300] Batch 400 | G Loss: 0.9646 | D Loss: 1.2266 | LR: 0.021228 | Momentum: 0.6960\n",
      "[Epoch 247/300] Batch 500 | G Loss: 0.9657 | D Loss: 1.1703 | LR: 0.021220 | Momentum: 0.6960\n",
      "[Epoch 247/300] Batch 600 | G Loss: 0.9578 | D Loss: 1.1980 | LR: 0.021211 | Momentum: 0.6960\n",
      "[Epoch 247/300] Batch 700 | G Loss: 1.0149 | D Loss: 1.1942 | LR: 0.021203 | Momentum: 0.6960\n",
      "[Epoch 247/300] Batch 800 | G Loss: 0.9618 | D Loss: 1.0706 | LR: 0.021194 | Momentum: 0.6960\n",
      "[Epoch 248/300] Batch 0 | G Loss: 0.9383 | D Loss: 1.1275 | LR: 0.021188 | Momentum: 0.6968\n",
      "[Epoch 248/300] Batch 100 | G Loss: 1.0027 | D Loss: 1.1105 | LR: 0.021180 | Momentum: 0.6968\n",
      "[Epoch 248/300] Batch 200 | G Loss: 0.9517 | D Loss: 1.1537 | LR: 0.021171 | Momentum: 0.6968\n",
      "[Epoch 248/300] Batch 300 | G Loss: 0.9709 | D Loss: 1.1178 | LR: 0.021163 | Momentum: 0.6968\n",
      "[Epoch 248/300] Batch 400 | G Loss: 0.8977 | D Loss: 1.1533 | LR: 0.021155 | Momentum: 0.6968\n",
      "[Epoch 248/300] Batch 500 | G Loss: 0.9179 | D Loss: 1.2628 | LR: 0.021146 | Momentum: 0.6968\n",
      "[Epoch 248/300] Batch 600 | G Loss: 0.9500 | D Loss: 1.2022 | LR: 0.021138 | Momentum: 0.6968\n",
      "[Epoch 248/300] Batch 700 | G Loss: 0.9819 | D Loss: 1.1434 | LR: 0.021129 | Momentum: 0.6968\n",
      "[Epoch 248/300] Batch 800 | G Loss: 0.9533 | D Loss: 1.1233 | LR: 0.021121 | Momentum: 0.6968\n",
      "[Epoch 249/300] Batch 0 | G Loss: 1.0486 | D Loss: 1.1415 | LR: 0.021115 | Momentum: 0.6976\n",
      "[Epoch 249/300] Batch 100 | G Loss: 0.9938 | D Loss: 1.1593 | LR: 0.021106 | Momentum: 0.6976\n",
      "[Epoch 249/300] Batch 200 | G Loss: 1.0266 | D Loss: 1.2138 | LR: 0.021098 | Momentum: 0.6976\n",
      "[Epoch 249/300] Batch 300 | G Loss: 0.9468 | D Loss: 1.3129 | LR: 0.021090 | Momentum: 0.6976\n",
      "[Epoch 249/300] Batch 400 | G Loss: 0.9352 | D Loss: 1.1418 | LR: 0.021081 | Momentum: 0.6976\n",
      "[Epoch 249/300] Batch 500 | G Loss: 0.9731 | D Loss: 1.2190 | LR: 0.021073 | Momentum: 0.6976\n",
      "[Epoch 249/300] Batch 600 | G Loss: 1.0045 | D Loss: 1.1719 | LR: 0.021064 | Momentum: 0.6976\n",
      "[Epoch 249/300] Batch 700 | G Loss: 0.9412 | D Loss: 1.1290 | LR: 0.021056 | Momentum: 0.6976\n",
      "[Epoch 249/300] Batch 800 | G Loss: 0.9866 | D Loss: 1.1370 | LR: 0.021047 | Momentum: 0.6976\n",
      "[Epoch 250/300] Batch 0 | G Loss: 0.9307 | D Loss: 1.1183 | LR: 0.021042 | Momentum: 0.6984\n",
      "[Epoch 250/300] Batch 100 | G Loss: 0.9770 | D Loss: 1.2254 | LR: 0.021033 | Momentum: 0.6984\n",
      "[Epoch 250/300] Batch 200 | G Loss: 1.0147 | D Loss: 1.1357 | LR: 0.021025 | Momentum: 0.6984\n",
      "[Epoch 250/300] Batch 300 | G Loss: 0.9482 | D Loss: 1.1988 | LR: 0.021016 | Momentum: 0.6984\n",
      "[Epoch 250/300] Batch 400 | G Loss: 0.9436 | D Loss: 1.3235 | LR: 0.021008 | Momentum: 0.6984\n",
      "[Epoch 250/300] Batch 500 | G Loss: 0.9399 | D Loss: 1.1414 | LR: 0.021000 | Momentum: 0.6984\n",
      "[Epoch 250/300] Batch 600 | G Loss: 1.0240 | D Loss: 1.2015 | LR: 0.020991 | Momentum: 0.6984\n",
      "[Epoch 250/300] Batch 700 | G Loss: 0.9822 | D Loss: 1.1830 | LR: 0.020983 | Momentum: 0.6984\n",
      "[Epoch 250/300] Batch 800 | G Loss: 0.9626 | D Loss: 1.1599 | LR: 0.020974 | Momentum: 0.6984\n",
      "[Epoch 251/300] Batch 0 | G Loss: 0.9962 | D Loss: 1.1740 | LR: 0.020969 | Momentum: 0.6992\n",
      "[Epoch 251/300] Batch 100 | G Loss: 0.9668 | D Loss: 1.2440 | LR: 0.020960 | Momentum: 0.6992\n",
      "[Epoch 251/300] Batch 200 | G Loss: 0.9781 | D Loss: 1.0981 | LR: 0.020952 | Momentum: 0.6992\n",
      "[Epoch 251/300] Batch 300 | G Loss: 0.9106 | D Loss: 1.1225 | LR: 0.020943 | Momentum: 0.6992\n",
      "[Epoch 251/300] Batch 400 | G Loss: 1.0449 | D Loss: 1.1495 | LR: 0.020935 | Momentum: 0.6992\n",
      "[Epoch 251/300] Batch 500 | G Loss: 0.9809 | D Loss: 1.1393 | LR: 0.020927 | Momentum: 0.6992\n",
      "[Epoch 251/300] Batch 600 | G Loss: 0.9208 | D Loss: 1.1621 | LR: 0.020918 | Momentum: 0.6992\n",
      "[Epoch 251/300] Batch 700 | G Loss: 0.9896 | D Loss: 1.1108 | LR: 0.020910 | Momentum: 0.6992\n",
      "[Epoch 251/300] Batch 800 | G Loss: 0.8971 | D Loss: 1.1559 | LR: 0.020902 | Momentum: 0.6992\n",
      "[Epoch 252/300] Batch 0 | G Loss: 0.9934 | D Loss: 1.2038 | LR: 0.020896 | Momentum: 0.7000\n",
      "[Epoch 252/300] Batch 100 | G Loss: 0.9709 | D Loss: 1.1156 | LR: 0.020887 | Momentum: 0.7000\n",
      "[Epoch 252/300] Batch 200 | G Loss: 0.9756 | D Loss: 1.1620 | LR: 0.020879 | Momentum: 0.7000\n",
      "[Epoch 252/300] Batch 300 | G Loss: 0.9474 | D Loss: 1.1101 | LR: 0.020871 | Momentum: 0.7000\n",
      "[Epoch 252/300] Batch 400 | G Loss: 0.9500 | D Loss: 1.1316 | LR: 0.020862 | Momentum: 0.7000\n",
      "[Epoch 252/300] Batch 500 | G Loss: 0.9365 | D Loss: 1.1268 | LR: 0.020854 | Momentum: 0.7000\n",
      "[Epoch 252/300] Batch 600 | G Loss: 0.9660 | D Loss: 1.1569 | LR: 0.020846 | Momentum: 0.7000\n",
      "[Epoch 252/300] Batch 700 | G Loss: 0.9365 | D Loss: 1.1579 | LR: 0.020837 | Momentum: 0.7000\n",
      "[Epoch 252/300] Batch 800 | G Loss: 1.0107 | D Loss: 1.1705 | LR: 0.020829 | Momentum: 0.7000\n",
      "[Epoch 253/300] Batch 0 | G Loss: 0.9733 | D Loss: 1.1907 | LR: 0.020823 | Momentum: 0.7000\n",
      "[Epoch 253/300] Batch 100 | G Loss: 0.9887 | D Loss: 1.1381 | LR: 0.020815 | Momentum: 0.7000\n",
      "[Epoch 253/300] Batch 200 | G Loss: 0.9262 | D Loss: 1.1917 | LR: 0.020807 | Momentum: 0.7000\n",
      "[Epoch 253/300] Batch 300 | G Loss: 0.9595 | D Loss: 1.1974 | LR: 0.020798 | Momentum: 0.7000\n",
      "[Epoch 253/300] Batch 400 | G Loss: 0.9492 | D Loss: 1.2707 | LR: 0.020790 | Momentum: 0.7000\n",
      "[Epoch 253/300] Batch 500 | G Loss: 0.9361 | D Loss: 1.1644 | LR: 0.020782 | Momentum: 0.7000\n",
      "[Epoch 253/300] Batch 600 | G Loss: 0.9612 | D Loss: 1.0877 | LR: 0.020773 | Momentum: 0.7000\n",
      "[Epoch 253/300] Batch 700 | G Loss: 0.9167 | D Loss: 1.1701 | LR: 0.020765 | Momentum: 0.7000\n",
      "[Epoch 253/300] Batch 800 | G Loss: 0.9374 | D Loss: 1.1143 | LR: 0.020757 | Momentum: 0.7000\n",
      "[Epoch 254/300] Batch 0 | G Loss: 1.0235 | D Loss: 1.2011 | LR: 0.020751 | Momentum: 0.7000\n",
      "[Epoch 254/300] Batch 100 | G Loss: 0.9399 | D Loss: 1.1607 | LR: 0.020743 | Momentum: 0.7000\n",
      "[Epoch 254/300] Batch 200 | G Loss: 0.9337 | D Loss: 1.0993 | LR: 0.020734 | Momentum: 0.7000\n",
      "[Epoch 254/300] Batch 300 | G Loss: 0.9756 | D Loss: 1.1649 | LR: 0.020726 | Momentum: 0.7000\n",
      "[Epoch 254/300] Batch 400 | G Loss: 0.9440 | D Loss: 1.0756 | LR: 0.020718 | Momentum: 0.7000\n",
      "[Epoch 254/300] Batch 500 | G Loss: 0.9652 | D Loss: 1.1298 | LR: 0.020710 | Momentum: 0.7000\n",
      "[Epoch 254/300] Batch 600 | G Loss: 0.9115 | D Loss: 1.1478 | LR: 0.020701 | Momentum: 0.7000\n",
      "[Epoch 254/300] Batch 700 | G Loss: 1.0069 | D Loss: 1.0923 | LR: 0.020693 | Momentum: 0.7000\n",
      "[Epoch 254/300] Batch 800 | G Loss: 0.9022 | D Loss: 1.2094 | LR: 0.020685 | Momentum: 0.7000\n",
      "[Epoch 255/300] Batch 0 | G Loss: 0.9070 | D Loss: 1.1151 | LR: 0.020679 | Momentum: 0.7000\n",
      "[Epoch 255/300] Batch 100 | G Loss: 0.9854 | D Loss: 1.2740 | LR: 0.020671 | Momentum: 0.7000\n",
      "[Epoch 255/300] Batch 200 | G Loss: 0.9295 | D Loss: 1.1364 | LR: 0.020663 | Momentum: 0.7000\n",
      "[Epoch 255/300] Batch 300 | G Loss: 1.0192 | D Loss: 1.1463 | LR: 0.020654 | Momentum: 0.7000\n",
      "[Epoch 255/300] Batch 400 | G Loss: 0.9618 | D Loss: 1.1919 | LR: 0.020646 | Momentum: 0.7000\n",
      "[Epoch 255/300] Batch 500 | G Loss: 0.9780 | D Loss: 1.2467 | LR: 0.020638 | Momentum: 0.7000\n",
      "[Epoch 255/300] Batch 600 | G Loss: 0.9108 | D Loss: 1.1899 | LR: 0.020629 | Momentum: 0.7000\n",
      "[Epoch 255/300] Batch 700 | G Loss: 0.9528 | D Loss: 1.1189 | LR: 0.020621 | Momentum: 0.7000\n",
      "[Epoch 255/300] Batch 800 | G Loss: 0.9887 | D Loss: 1.1506 | LR: 0.020613 | Momentum: 0.7000\n",
      "[Epoch 256/300] Batch 0 | G Loss: 0.9378 | D Loss: 1.1993 | LR: 0.020607 | Momentum: 0.7000\n",
      "[Epoch 256/300] Batch 100 | G Loss: 0.9338 | D Loss: 1.0451 | LR: 0.020599 | Momentum: 0.7000\n",
      "[Epoch 256/300] Batch 200 | G Loss: 0.9595 | D Loss: 1.2621 | LR: 0.020591 | Momentum: 0.7000\n",
      "[Epoch 256/300] Batch 300 | G Loss: 0.9880 | D Loss: 1.1846 | LR: 0.020583 | Momentum: 0.7000\n",
      "[Epoch 256/300] Batch 400 | G Loss: 0.9852 | D Loss: 1.1278 | LR: 0.020574 | Momentum: 0.7000\n",
      "[Epoch 256/300] Batch 500 | G Loss: 0.9470 | D Loss: 1.3066 | LR: 0.020566 | Momentum: 0.7000\n",
      "[Epoch 256/300] Batch 600 | G Loss: 0.9739 | D Loss: 1.3017 | LR: 0.020558 | Momentum: 0.7000\n",
      "[Epoch 256/300] Batch 700 | G Loss: 0.9638 | D Loss: 1.1276 | LR: 0.020550 | Momentum: 0.7000\n",
      "[Epoch 256/300] Batch 800 | G Loss: 0.9571 | D Loss: 1.2190 | LR: 0.020541 | Momentum: 0.7000\n",
      "[Epoch 257/300] Batch 0 | G Loss: 0.9593 | D Loss: 1.2572 | LR: 0.020536 | Momentum: 0.7000\n",
      "[Epoch 257/300] Batch 100 | G Loss: 0.9398 | D Loss: 1.0906 | LR: 0.020528 | Momentum: 0.7000\n",
      "[Epoch 257/300] Batch 200 | G Loss: 0.9883 | D Loss: 1.0743 | LR: 0.020519 | Momentum: 0.7000\n",
      "[Epoch 257/300] Batch 300 | G Loss: 0.9276 | D Loss: 1.1101 | LR: 0.020511 | Momentum: 0.7000\n",
      "[Epoch 257/300] Batch 400 | G Loss: 0.9696 | D Loss: 1.1746 | LR: 0.020503 | Momentum: 0.7000\n",
      "[Epoch 257/300] Batch 500 | G Loss: 1.1183 | D Loss: 1.2299 | LR: 0.020495 | Momentum: 0.7000\n",
      "[Epoch 257/300] Batch 600 | G Loss: 0.9582 | D Loss: 1.2510 | LR: 0.020487 | Momentum: 0.7000\n",
      "[Epoch 257/300] Batch 700 | G Loss: 0.9612 | D Loss: 1.1444 | LR: 0.020478 | Momentum: 0.7000\n",
      "[Epoch 257/300] Batch 800 | G Loss: 0.9965 | D Loss: 1.1403 | LR: 0.020470 | Momentum: 0.7000\n",
      "[Epoch 258/300] Batch 0 | G Loss: 0.9404 | D Loss: 1.2486 | LR: 0.020465 | Momentum: 0.7000\n",
      "[Epoch 258/300] Batch 100 | G Loss: 0.9988 | D Loss: 1.0683 | LR: 0.020456 | Momentum: 0.7000\n",
      "[Epoch 258/300] Batch 200 | G Loss: 0.9414 | D Loss: 1.1027 | LR: 0.020448 | Momentum: 0.7000\n",
      "[Epoch 258/300] Batch 300 | G Loss: 0.9057 | D Loss: 1.2152 | LR: 0.020440 | Momentum: 0.7000\n",
      "[Epoch 258/300] Batch 400 | G Loss: 0.9336 | D Loss: 1.1536 | LR: 0.020432 | Momentum: 0.7000\n",
      "[Epoch 258/300] Batch 500 | G Loss: 0.9611 | D Loss: 1.1282 | LR: 0.020424 | Momentum: 0.7000\n",
      "[Epoch 258/300] Batch 600 | G Loss: 0.9642 | D Loss: 1.1537 | LR: 0.020415 | Momentum: 0.7000\n",
      "[Epoch 258/300] Batch 700 | G Loss: 0.9360 | D Loss: 1.2862 | LR: 0.020407 | Momentum: 0.7000\n",
      "[Epoch 258/300] Batch 800 | G Loss: 1.0005 | D Loss: 1.1979 | LR: 0.020399 | Momentum: 0.7000\n",
      "[Epoch 259/300] Batch 0 | G Loss: 1.0156 | D Loss: 1.1598 | LR: 0.020394 | Momentum: 0.7000\n",
      "[Epoch 259/300] Batch 100 | G Loss: 0.9267 | D Loss: 1.1783 | LR: 0.020385 | Momentum: 0.7000\n",
      "[Epoch 259/300] Batch 200 | G Loss: 0.9424 | D Loss: 1.1720 | LR: 0.020377 | Momentum: 0.7000\n",
      "[Epoch 259/300] Batch 300 | G Loss: 0.9723 | D Loss: 1.0285 | LR: 0.020369 | Momentum: 0.7000\n",
      "[Epoch 259/300] Batch 400 | G Loss: 0.9699 | D Loss: 1.0797 | LR: 0.020361 | Momentum: 0.7000\n",
      "[Epoch 259/300] Batch 500 | G Loss: 0.9635 | D Loss: 1.1328 | LR: 0.020353 | Momentum: 0.7000\n",
      "[Epoch 259/300] Batch 600 | G Loss: 0.9328 | D Loss: 1.2029 | LR: 0.020345 | Momentum: 0.7000\n",
      "[Epoch 259/300] Batch 700 | G Loss: 0.9538 | D Loss: 1.0773 | LR: 0.020336 | Momentum: 0.7000\n",
      "[Epoch 259/300] Batch 800 | G Loss: 0.9350 | D Loss: 1.2680 | LR: 0.020328 | Momentum: 0.7000\n",
      "[Epoch 260/300] Batch 0 | G Loss: 0.9903 | D Loss: 1.1524 | LR: 0.020323 | Momentum: 0.7000\n",
      "[Epoch 260/300] Batch 100 | G Loss: 0.9158 | D Loss: 1.1007 | LR: 0.020315 | Momentum: 0.7000\n",
      "[Epoch 260/300] Batch 200 | G Loss: 0.9085 | D Loss: 1.1820 | LR: 0.020306 | Momentum: 0.7000\n",
      "[Epoch 260/300] Batch 300 | G Loss: 0.9432 | D Loss: 1.2102 | LR: 0.020298 | Momentum: 0.7000\n",
      "[Epoch 260/300] Batch 400 | G Loss: 0.9470 | D Loss: 1.2161 | LR: 0.020290 | Momentum: 0.7000\n",
      "[Epoch 260/300] Batch 500 | G Loss: 0.9171 | D Loss: 1.1430 | LR: 0.020282 | Momentum: 0.7000\n",
      "[Epoch 260/300] Batch 600 | G Loss: 0.9520 | D Loss: 1.1731 | LR: 0.020274 | Momentum: 0.7000\n",
      "[Epoch 260/300] Batch 700 | G Loss: 0.9166 | D Loss: 1.2019 | LR: 0.020266 | Momentum: 0.7000\n",
      "[Epoch 260/300] Batch 800 | G Loss: 0.9446 | D Loss: 1.2280 | LR: 0.020258 | Momentum: 0.7000\n",
      "[Epoch 261/300] Batch 0 | G Loss: 0.9397 | D Loss: 1.1820 | LR: 0.020252 | Momentum: 0.7000\n",
      "[Epoch 261/300] Batch 100 | G Loss: 0.9671 | D Loss: 1.1607 | LR: 0.020244 | Momentum: 0.7000\n",
      "[Epoch 261/300] Batch 200 | G Loss: 0.9698 | D Loss: 1.1920 | LR: 0.020236 | Momentum: 0.7000\n",
      "[Epoch 261/300] Batch 300 | G Loss: 0.9779 | D Loss: 1.0589 | LR: 0.020228 | Momentum: 0.7000\n",
      "[Epoch 261/300] Batch 400 | G Loss: 0.9019 | D Loss: 1.1560 | LR: 0.020220 | Momentum: 0.7000\n",
      "[Epoch 261/300] Batch 500 | G Loss: 0.9789 | D Loss: 1.0576 | LR: 0.020212 | Momentum: 0.7000\n",
      "[Epoch 261/300] Batch 600 | G Loss: 0.9417 | D Loss: 1.0591 | LR: 0.020204 | Momentum: 0.7000\n",
      "[Epoch 261/300] Batch 700 | G Loss: 0.9391 | D Loss: 1.1686 | LR: 0.020196 | Momentum: 0.7000\n",
      "[Epoch 261/300] Batch 800 | G Loss: 0.9319 | D Loss: 1.1820 | LR: 0.020188 | Momentum: 0.7000\n",
      "[Epoch 262/300] Batch 0 | G Loss: 0.9644 | D Loss: 1.2143 | LR: 0.020182 | Momentum: 0.7000\n",
      "[Epoch 262/300] Batch 100 | G Loss: 0.9814 | D Loss: 1.1209 | LR: 0.020174 | Momentum: 0.7000\n",
      "[Epoch 262/300] Batch 200 | G Loss: 0.9141 | D Loss: 1.0716 | LR: 0.020166 | Momentum: 0.7000\n",
      "[Epoch 262/300] Batch 300 | G Loss: 0.9193 | D Loss: 1.0737 | LR: 0.020158 | Momentum: 0.7000\n",
      "[Epoch 262/300] Batch 400 | G Loss: 0.8963 | D Loss: 1.2112 | LR: 0.020150 | Momentum: 0.7000\n",
      "[Epoch 262/300] Batch 500 | G Loss: 0.9686 | D Loss: 1.1024 | LR: 0.020142 | Momentum: 0.7000\n",
      "[Epoch 262/300] Batch 600 | G Loss: 0.9243 | D Loss: 1.1293 | LR: 0.020134 | Momentum: 0.7000\n",
      "[Epoch 262/300] Batch 700 | G Loss: 0.9675 | D Loss: 1.2224 | LR: 0.020126 | Momentum: 0.7000\n",
      "[Epoch 262/300] Batch 800 | G Loss: 0.9412 | D Loss: 1.1654 | LR: 0.020117 | Momentum: 0.7000\n",
      "[Epoch 263/300] Batch 0 | G Loss: 0.9275 | D Loss: 1.2477 | LR: 0.020112 | Momentum: 0.7000\n",
      "[Epoch 263/300] Batch 100 | G Loss: 0.9939 | D Loss: 1.1558 | LR: 0.020104 | Momentum: 0.7000\n",
      "[Epoch 263/300] Batch 200 | G Loss: 0.9348 | D Loss: 1.1255 | LR: 0.020096 | Momentum: 0.7000\n",
      "[Epoch 263/300] Batch 300 | G Loss: 0.9624 | D Loss: 1.1361 | LR: 0.020088 | Momentum: 0.7000\n",
      "[Epoch 263/300] Batch 400 | G Loss: 0.9194 | D Loss: 1.0975 | LR: 0.020080 | Momentum: 0.7000\n",
      "[Epoch 263/300] Batch 500 | G Loss: 0.9059 | D Loss: 1.0558 | LR: 0.020072 | Momentum: 0.7000\n",
      "[Epoch 263/300] Batch 600 | G Loss: 0.9640 | D Loss: 1.0769 | LR: 0.020064 | Momentum: 0.7000\n",
      "[Epoch 263/300] Batch 700 | G Loss: 1.0058 | D Loss: 1.1152 | LR: 0.020056 | Momentum: 0.7000\n",
      "[Epoch 263/300] Batch 800 | G Loss: 0.9837 | D Loss: 1.1795 | LR: 0.020048 | Momentum: 0.7000\n",
      "[Epoch 264/300] Batch 0 | G Loss: 0.9389 | D Loss: 1.1195 | LR: 0.020042 | Momentum: 0.7000\n",
      "[Epoch 264/300] Batch 100 | G Loss: 0.9408 | D Loss: 1.2710 | LR: 0.020034 | Momentum: 0.7000\n",
      "[Epoch 264/300] Batch 200 | G Loss: 0.9762 | D Loss: 1.2275 | LR: 0.020026 | Momentum: 0.7000\n",
      "[Epoch 264/300] Batch 300 | G Loss: 0.9639 | D Loss: 1.1643 | LR: 0.020018 | Momentum: 0.7000\n",
      "[Epoch 264/300] Batch 400 | G Loss: 0.9787 | D Loss: 1.1369 | LR: 0.020010 | Momentum: 0.7000\n",
      "[Epoch 264/300] Batch 500 | G Loss: 0.9250 | D Loss: 1.2293 | LR: 0.020002 | Momentum: 0.7000\n",
      "[Epoch 264/300] Batch 600 | G Loss: 0.9184 | D Loss: 1.1841 | LR: 0.019994 | Momentum: 0.7000\n",
      "[Epoch 264/300] Batch 700 | G Loss: 0.9666 | D Loss: 1.1885 | LR: 0.019986 | Momentum: 0.7000\n",
      "[Epoch 264/300] Batch 800 | G Loss: 0.9086 | D Loss: 1.1203 | LR: 0.019978 | Momentum: 0.7000\n",
      "[Epoch 265/300] Batch 0 | G Loss: 0.9592 | D Loss: 1.1580 | LR: 0.019973 | Momentum: 0.7000\n",
      "[Epoch 265/300] Batch 100 | G Loss: 0.9570 | D Loss: 1.1037 | LR: 0.019965 | Momentum: 0.7000\n",
      "[Epoch 265/300] Batch 200 | G Loss: 0.9852 | D Loss: 1.0903 | LR: 0.019957 | Momentum: 0.7000\n",
      "[Epoch 265/300] Batch 300 | G Loss: 0.9476 | D Loss: 1.2379 | LR: 0.019949 | Momentum: 0.7000\n",
      "[Epoch 265/300] Batch 400 | G Loss: 0.9996 | D Loss: 1.0472 | LR: 0.019941 | Momentum: 0.7000\n",
      "[Epoch 265/300] Batch 500 | G Loss: 0.9170 | D Loss: 1.0820 | LR: 0.019933 | Momentum: 0.7000\n",
      "[Epoch 265/300] Batch 600 | G Loss: 0.9702 | D Loss: 1.1369 | LR: 0.019925 | Momentum: 0.7000\n",
      "[Epoch 265/300] Batch 700 | G Loss: 0.9894 | D Loss: 1.1031 | LR: 0.019917 | Momentum: 0.7000\n",
      "[Epoch 265/300] Batch 800 | G Loss: 0.9463 | D Loss: 1.1750 | LR: 0.019909 | Momentum: 0.7000\n",
      "[Epoch 266/300] Batch 0 | G Loss: 0.9499 | D Loss: 1.1198 | LR: 0.019903 | Momentum: 0.7000\n",
      "[Epoch 266/300] Batch 100 | G Loss: 1.0107 | D Loss: 1.0931 | LR: 0.019895 | Momentum: 0.7000\n",
      "[Epoch 266/300] Batch 200 | G Loss: 0.9512 | D Loss: 1.1460 | LR: 0.019887 | Momentum: 0.7000\n",
      "[Epoch 266/300] Batch 300 | G Loss: 1.0053 | D Loss: 1.2034 | LR: 0.019879 | Momentum: 0.7000\n",
      "[Epoch 266/300] Batch 400 | G Loss: 0.9920 | D Loss: 1.0008 | LR: 0.019871 | Momentum: 0.7000\n",
      "[Epoch 266/300] Batch 500 | G Loss: 0.9954 | D Loss: 1.2047 | LR: 0.019864 | Momentum: 0.7000\n",
      "[Epoch 266/300] Batch 600 | G Loss: 0.9839 | D Loss: 1.1928 | LR: 0.019856 | Momentum: 0.7000\n",
      "[Epoch 266/300] Batch 700 | G Loss: 0.9304 | D Loss: 1.1702 | LR: 0.019848 | Momentum: 0.7000\n",
      "[Epoch 266/300] Batch 800 | G Loss: 0.9785 | D Loss: 1.2180 | LR: 0.019840 | Momentum: 0.7000\n",
      "[Epoch 267/300] Batch 0 | G Loss: 0.9523 | D Loss: 1.1619 | LR: 0.019834 | Momentum: 0.7000\n",
      "[Epoch 267/300] Batch 100 | G Loss: 0.9228 | D Loss: 1.1029 | LR: 0.019826 | Momentum: 0.7000\n",
      "[Epoch 267/300] Batch 200 | G Loss: 1.0007 | D Loss: 1.2391 | LR: 0.019818 | Momentum: 0.7000\n",
      "[Epoch 267/300] Batch 300 | G Loss: 1.0232 | D Loss: 1.1657 | LR: 0.019810 | Momentum: 0.7000\n",
      "[Epoch 267/300] Batch 400 | G Loss: 0.8967 | D Loss: 1.1365 | LR: 0.019803 | Momentum: 0.7000\n",
      "[Epoch 267/300] Batch 500 | G Loss: 0.9721 | D Loss: 1.1024 | LR: 0.019795 | Momentum: 0.7000\n",
      "[Epoch 267/300] Batch 600 | G Loss: 0.9714 | D Loss: 1.1074 | LR: 0.019787 | Momentum: 0.7000\n",
      "[Epoch 267/300] Batch 700 | G Loss: 0.9054 | D Loss: 1.1900 | LR: 0.019779 | Momentum: 0.7000\n",
      "[Epoch 267/300] Batch 800 | G Loss: 0.9445 | D Loss: 1.1256 | LR: 0.019771 | Momentum: 0.7000\n",
      "[Epoch 268/300] Batch 0 | G Loss: 0.9203 | D Loss: 1.1533 | LR: 0.019765 | Momentum: 0.7000\n",
      "[Epoch 268/300] Batch 100 | G Loss: 0.9888 | D Loss: 1.1570 | LR: 0.019757 | Momentum: 0.7000\n",
      "[Epoch 268/300] Batch 200 | G Loss: 0.9313 | D Loss: 1.2247 | LR: 0.019750 | Momentum: 0.7000\n",
      "[Epoch 268/300] Batch 300 | G Loss: 0.9432 | D Loss: 1.1762 | LR: 0.019742 | Momentum: 0.7000\n",
      "[Epoch 268/300] Batch 400 | G Loss: 0.9859 | D Loss: 1.0770 | LR: 0.019734 | Momentum: 0.7000\n",
      "[Epoch 268/300] Batch 500 | G Loss: 0.9375 | D Loss: 1.1788 | LR: 0.019726 | Momentum: 0.7000\n",
      "[Epoch 268/300] Batch 600 | G Loss: 1.0252 | D Loss: 1.1058 | LR: 0.019718 | Momentum: 0.7000\n",
      "[Epoch 268/300] Batch 700 | G Loss: 0.9281 | D Loss: 1.1878 | LR: 0.019710 | Momentum: 0.7000\n",
      "[Epoch 268/300] Batch 800 | G Loss: 1.0138 | D Loss: 1.1600 | LR: 0.019702 | Momentum: 0.7000\n",
      "[Epoch 269/300] Batch 0 | G Loss: 0.9645 | D Loss: 1.1450 | LR: 0.019697 | Momentum: 0.7000\n",
      "[Epoch 269/300] Batch 100 | G Loss: 0.8946 | D Loss: 1.2460 | LR: 0.019689 | Momentum: 0.7000\n",
      "[Epoch 269/300] Batch 200 | G Loss: 0.9290 | D Loss: 1.1593 | LR: 0.019681 | Momentum: 0.7000\n",
      "[Epoch 269/300] Batch 300 | G Loss: 0.9769 | D Loss: 1.1266 | LR: 0.019673 | Momentum: 0.7000\n",
      "[Epoch 269/300] Batch 400 | G Loss: 0.9206 | D Loss: 1.2509 | LR: 0.019665 | Momentum: 0.7000\n",
      "[Epoch 269/300] Batch 500 | G Loss: 0.9006 | D Loss: 1.2171 | LR: 0.019657 | Momentum: 0.7000\n",
      "[Epoch 269/300] Batch 600 | G Loss: 0.9583 | D Loss: 1.1340 | LR: 0.019650 | Momentum: 0.7000\n",
      "[Epoch 269/300] Batch 700 | G Loss: 0.9374 | D Loss: 1.2066 | LR: 0.019642 | Momentum: 0.7000\n",
      "[Epoch 269/300] Batch 800 | G Loss: 0.9293 | D Loss: 1.1121 | LR: 0.019634 | Momentum: 0.7000\n",
      "[Epoch 270/300] Batch 0 | G Loss: 0.9239 | D Loss: 1.2099 | LR: 0.019628 | Momentum: 0.7000\n",
      "[Epoch 270/300] Batch 100 | G Loss: 0.9380 | D Loss: 1.1096 | LR: 0.019621 | Momentum: 0.7000\n",
      "[Epoch 270/300] Batch 200 | G Loss: 0.9189 | D Loss: 1.1945 | LR: 0.019613 | Momentum: 0.7000\n",
      "[Epoch 270/300] Batch 300 | G Loss: 0.9519 | D Loss: 1.2354 | LR: 0.019605 | Momentum: 0.7000\n",
      "[Epoch 270/300] Batch 400 | G Loss: 0.9709 | D Loss: 1.2202 | LR: 0.019597 | Momentum: 0.7000\n",
      "[Epoch 270/300] Batch 500 | G Loss: 0.9452 | D Loss: 1.2013 | LR: 0.019589 | Momentum: 0.7000\n",
      "[Epoch 270/300] Batch 600 | G Loss: 0.8941 | D Loss: 1.1796 | LR: 0.019581 | Momentum: 0.7000\n",
      "[Epoch 270/300] Batch 700 | G Loss: 1.0120 | D Loss: 1.1207 | LR: 0.019574 | Momentum: 0.7000\n",
      "[Epoch 270/300] Batch 800 | G Loss: 1.0099 | D Loss: 1.2021 | LR: 0.019566 | Momentum: 0.7000\n",
      "[Epoch 271/300] Batch 0 | G Loss: 0.9844 | D Loss: 1.0901 | LR: 0.019560 | Momentum: 0.7000\n",
      "[Epoch 271/300] Batch 100 | G Loss: 0.9705 | D Loss: 1.2100 | LR: 0.019553 | Momentum: 0.7000\n",
      "[Epoch 271/300] Batch 200 | G Loss: 0.9491 | D Loss: 1.2115 | LR: 0.019545 | Momentum: 0.7000\n",
      "[Epoch 271/300] Batch 300 | G Loss: 0.9659 | D Loss: 1.1290 | LR: 0.019537 | Momentum: 0.7000\n",
      "[Epoch 271/300] Batch 400 | G Loss: 0.9905 | D Loss: 1.1064 | LR: 0.019529 | Momentum: 0.7000\n",
      "[Epoch 271/300] Batch 500 | G Loss: 0.9182 | D Loss: 1.2406 | LR: 0.019521 | Momentum: 0.7000\n",
      "[Epoch 271/300] Batch 600 | G Loss: 0.9951 | D Loss: 1.2410 | LR: 0.019513 | Momentum: 0.7000\n",
      "[Epoch 271/300] Batch 700 | G Loss: 1.0070 | D Loss: 1.0996 | LR: 0.019506 | Momentum: 0.7000\n",
      "[Epoch 271/300] Batch 800 | G Loss: 0.9471 | D Loss: 1.2441 | LR: 0.019498 | Momentum: 0.7000\n",
      "[Epoch 272/300] Batch 0 | G Loss: 0.9977 | D Loss: 1.1618 | LR: 0.019492 | Momentum: 0.7000\n",
      "[Epoch 272/300] Batch 100 | G Loss: 0.9977 | D Loss: 1.1913 | LR: 0.019485 | Momentum: 0.7000\n",
      "[Epoch 272/300] Batch 200 | G Loss: 1.0391 | D Loss: 1.1016 | LR: 0.019477 | Momentum: 0.7000\n",
      "[Epoch 272/300] Batch 300 | G Loss: 0.9235 | D Loss: 1.0922 | LR: 0.019469 | Momentum: 0.7000\n",
      "[Epoch 272/300] Batch 400 | G Loss: 1.0201 | D Loss: 1.2548 | LR: 0.019461 | Momentum: 0.7000\n",
      "[Epoch 272/300] Batch 500 | G Loss: 0.9724 | D Loss: 1.1012 | LR: 0.019454 | Momentum: 0.7000\n",
      "[Epoch 272/300] Batch 600 | G Loss: 0.9498 | D Loss: 1.1264 | LR: 0.019446 | Momentum: 0.7000\n",
      "[Epoch 272/300] Batch 700 | G Loss: 0.9284 | D Loss: 1.1432 | LR: 0.019438 | Momentum: 0.7000\n",
      "[Epoch 272/300] Batch 800 | G Loss: 0.9451 | D Loss: 1.1460 | LR: 0.019430 | Momentum: 0.7000\n",
      "[Epoch 273/300] Batch 0 | G Loss: 0.9100 | D Loss: 1.1505 | LR: 0.019425 | Momentum: 0.7000\n",
      "[Epoch 273/300] Batch 100 | G Loss: 1.0764 | D Loss: 1.2137 | LR: 0.019417 | Momentum: 0.7000\n",
      "[Epoch 273/300] Batch 200 | G Loss: 0.9262 | D Loss: 1.1079 | LR: 0.019409 | Momentum: 0.7000\n",
      "[Epoch 273/300] Batch 300 | G Loss: 1.0062 | D Loss: 1.2172 | LR: 0.019402 | Momentum: 0.7000\n",
      "[Epoch 273/300] Batch 400 | G Loss: 0.9246 | D Loss: 1.1135 | LR: 0.019394 | Momentum: 0.7000\n",
      "[Epoch 273/300] Batch 500 | G Loss: 1.0542 | D Loss: 1.2303 | LR: 0.019386 | Momentum: 0.7000\n",
      "[Epoch 273/300] Batch 600 | G Loss: 0.9384 | D Loss: 1.1101 | LR: 0.019378 | Momentum: 0.7000\n",
      "[Epoch 273/300] Batch 700 | G Loss: 0.9979 | D Loss: 1.2291 | LR: 0.019371 | Momentum: 0.7000\n",
      "[Epoch 273/300] Batch 800 | G Loss: 0.9384 | D Loss: 1.2326 | LR: 0.019363 | Momentum: 0.7000\n",
      "[Epoch 274/300] Batch 0 | G Loss: 0.9408 | D Loss: 1.1177 | LR: 0.019357 | Momentum: 0.7000\n",
      "[Epoch 274/300] Batch 100 | G Loss: 0.9858 | D Loss: 1.1451 | LR: 0.019350 | Momentum: 0.7000\n",
      "[Epoch 274/300] Batch 200 | G Loss: 1.0081 | D Loss: 1.0978 | LR: 0.019342 | Momentum: 0.7000\n",
      "[Epoch 274/300] Batch 300 | G Loss: 0.9623 | D Loss: 1.1376 | LR: 0.019334 | Momentum: 0.7000\n",
      "[Epoch 274/300] Batch 400 | G Loss: 0.9365 | D Loss: 1.1953 | LR: 0.019326 | Momentum: 0.7000\n",
      "[Epoch 274/300] Batch 500 | G Loss: 0.9526 | D Loss: 1.0927 | LR: 0.019319 | Momentum: 0.7000\n",
      "[Epoch 274/300] Batch 600 | G Loss: 0.9454 | D Loss: 1.2117 | LR: 0.019311 | Momentum: 0.7000\n",
      "[Epoch 274/300] Batch 700 | G Loss: 0.9757 | D Loss: 1.1970 | LR: 0.019303 | Momentum: 0.7000\n",
      "[Epoch 274/300] Batch 800 | G Loss: 0.9859 | D Loss: 1.1941 | LR: 0.019296 | Momentum: 0.7000\n",
      "[Epoch 275/300] Batch 0 | G Loss: 0.9437 | D Loss: 1.1590 | LR: 0.019290 | Momentum: 0.7000\n",
      "[Epoch 275/300] Batch 100 | G Loss: 0.9541 | D Loss: 1.0920 | LR: 0.019283 | Momentum: 0.7000\n",
      "[Epoch 275/300] Batch 200 | G Loss: 0.8790 | D Loss: 1.1026 | LR: 0.019275 | Momentum: 0.7000\n",
      "[Epoch 275/300] Batch 300 | G Loss: 0.9769 | D Loss: 1.2054 | LR: 0.019267 | Momentum: 0.7000\n",
      "[Epoch 275/300] Batch 400 | G Loss: 0.9722 | D Loss: 1.1427 | LR: 0.019259 | Momentum: 0.7000\n",
      "[Epoch 275/300] Batch 500 | G Loss: 0.9779 | D Loss: 1.1749 | LR: 0.019252 | Momentum: 0.7000\n",
      "[Epoch 275/300] Batch 600 | G Loss: 0.9328 | D Loss: 1.2586 | LR: 0.019244 | Momentum: 0.7000\n",
      "[Epoch 275/300] Batch 700 | G Loss: 0.9568 | D Loss: 1.1591 | LR: 0.019236 | Momentum: 0.7000\n",
      "[Epoch 275/300] Batch 800 | G Loss: 0.9766 | D Loss: 1.2438 | LR: 0.019229 | Momentum: 0.7000\n",
      "[Epoch 276/300] Batch 0 | G Loss: 1.0260 | D Loss: 1.2143 | LR: 0.019223 | Momentum: 0.7000\n",
      "[Epoch 276/300] Batch 100 | G Loss: 0.9749 | D Loss: 1.1648 | LR: 0.019216 | Momentum: 0.7000\n",
      "[Epoch 276/300] Batch 200 | G Loss: 1.0068 | D Loss: 1.1257 | LR: 0.019208 | Momentum: 0.7000\n",
      "[Epoch 276/300] Batch 300 | G Loss: 0.9471 | D Loss: 1.1714 | LR: 0.019200 | Momentum: 0.7000\n",
      "[Epoch 276/300] Batch 400 | G Loss: 0.9414 | D Loss: 1.0340 | LR: 0.019193 | Momentum: 0.7000\n",
      "[Epoch 276/300] Batch 500 | G Loss: 0.9508 | D Loss: 1.2661 | LR: 0.019185 | Momentum: 0.7000\n",
      "[Epoch 276/300] Batch 600 | G Loss: 0.9758 | D Loss: 1.2137 | LR: 0.019177 | Momentum: 0.7000\n",
      "[Epoch 276/300] Batch 700 | G Loss: 0.9404 | D Loss: 1.1464 | LR: 0.019170 | Momentum: 0.7000\n",
      "[Epoch 276/300] Batch 800 | G Loss: 1.0253 | D Loss: 1.1501 | LR: 0.019162 | Momentum: 0.7000\n",
      "[Epoch 277/300] Batch 0 | G Loss: 0.9818 | D Loss: 1.0542 | LR: 0.019157 | Momentum: 0.7000\n",
      "[Epoch 277/300] Batch 100 | G Loss: 0.9325 | D Loss: 1.1188 | LR: 0.019149 | Momentum: 0.7000\n",
      "[Epoch 277/300] Batch 200 | G Loss: 0.9564 | D Loss: 1.0545 | LR: 0.019141 | Momentum: 0.7000\n",
      "[Epoch 277/300] Batch 300 | G Loss: 0.9638 | D Loss: 1.2211 | LR: 0.019134 | Momentum: 0.7000\n",
      "[Epoch 277/300] Batch 400 | G Loss: 0.9372 | D Loss: 1.2605 | LR: 0.019126 | Momentum: 0.7000\n",
      "[Epoch 277/300] Batch 500 | G Loss: 0.9968 | D Loss: 1.0903 | LR: 0.019118 | Momentum: 0.7000\n",
      "[Epoch 277/300] Batch 600 | G Loss: 0.9109 | D Loss: 1.1821 | LR: 0.019111 | Momentum: 0.7000\n",
      "[Epoch 277/300] Batch 700 | G Loss: 0.9451 | D Loss: 1.2696 | LR: 0.019103 | Momentum: 0.7000\n",
      "[Epoch 277/300] Batch 800 | G Loss: 0.9350 | D Loss: 1.1323 | LR: 0.019095 | Momentum: 0.7000\n",
      "[Epoch 278/300] Batch 0 | G Loss: 0.9219 | D Loss: 1.1263 | LR: 0.019090 | Momentum: 0.7000\n",
      "[Epoch 278/300] Batch 100 | G Loss: 1.0607 | D Loss: 1.1375 | LR: 0.019083 | Momentum: 0.7000\n",
      "[Epoch 278/300] Batch 200 | G Loss: 0.9572 | D Loss: 1.0962 | LR: 0.019075 | Momentum: 0.7000\n",
      "[Epoch 278/300] Batch 300 | G Loss: 0.9140 | D Loss: 1.1385 | LR: 0.019067 | Momentum: 0.7000\n",
      "[Epoch 278/300] Batch 400 | G Loss: 1.0148 | D Loss: 1.1379 | LR: 0.019060 | Momentum: 0.7000\n",
      "[Epoch 278/300] Batch 500 | G Loss: 0.9185 | D Loss: 1.1221 | LR: 0.019052 | Momentum: 0.7000\n",
      "[Epoch 278/300] Batch 600 | G Loss: 0.9449 | D Loss: 1.1156 | LR: 0.019044 | Momentum: 0.7000\n",
      "[Epoch 278/300] Batch 700 | G Loss: 0.9458 | D Loss: 1.1841 | LR: 0.019037 | Momentum: 0.7000\n",
      "[Epoch 278/300] Batch 800 | G Loss: 0.9534 | D Loss: 1.1768 | LR: 0.019029 | Momentum: 0.7000\n",
      "[Epoch 279/300] Batch 0 | G Loss: 1.0002 | D Loss: 1.1822 | LR: 0.019024 | Momentum: 0.7000\n",
      "[Epoch 279/300] Batch 100 | G Loss: 1.0189 | D Loss: 1.1273 | LR: 0.019016 | Momentum: 0.7000\n",
      "[Epoch 279/300] Batch 200 | G Loss: 0.9739 | D Loss: 1.2134 | LR: 0.019009 | Momentum: 0.7000\n",
      "[Epoch 279/300] Batch 300 | G Loss: 0.9303 | D Loss: 1.1468 | LR: 0.019001 | Momentum: 0.7000\n",
      "[Epoch 279/300] Batch 400 | G Loss: 0.8986 | D Loss: 1.2271 | LR: 0.018994 | Momentum: 0.7000\n",
      "[Epoch 279/300] Batch 500 | G Loss: 0.9189 | D Loss: 1.2021 | LR: 0.018986 | Momentum: 0.7000\n",
      "[Epoch 279/300] Batch 600 | G Loss: 0.9926 | D Loss: 1.0955 | LR: 0.018978 | Momentum: 0.7000\n",
      "[Epoch 279/300] Batch 700 | G Loss: 0.9490 | D Loss: 1.1872 | LR: 0.018971 | Momentum: 0.7000\n",
      "[Epoch 279/300] Batch 800 | G Loss: 0.9408 | D Loss: 1.2763 | LR: 0.018963 | Momentum: 0.7000\n",
      "[Epoch 280/300] Batch 0 | G Loss: 0.9699 | D Loss: 1.2165 | LR: 0.018958 | Momentum: 0.7000\n",
      "[Epoch 280/300] Batch 100 | G Loss: 1.0150 | D Loss: 1.1868 | LR: 0.018950 | Momentum: 0.7000\n",
      "[Epoch 280/300] Batch 200 | G Loss: 0.8966 | D Loss: 1.1989 | LR: 0.018943 | Momentum: 0.7000\n",
      "[Epoch 280/300] Batch 300 | G Loss: 0.9570 | D Loss: 1.1268 | LR: 0.018935 | Momentum: 0.7000\n",
      "[Epoch 280/300] Batch 400 | G Loss: 0.9735 | D Loss: 1.1280 | LR: 0.018928 | Momentum: 0.7000\n",
      "[Epoch 280/300] Batch 500 | G Loss: 1.0135 | D Loss: 1.1138 | LR: 0.018920 | Momentum: 0.7000\n",
      "[Epoch 280/300] Batch 600 | G Loss: 0.8976 | D Loss: 1.1638 | LR: 0.018912 | Momentum: 0.7000\n",
      "[Epoch 280/300] Batch 700 | G Loss: 1.0399 | D Loss: 1.1665 | LR: 0.018905 | Momentum: 0.7000\n",
      "[Epoch 280/300] Batch 800 | G Loss: 0.9236 | D Loss: 1.1865 | LR: 0.018897 | Momentum: 0.7000\n",
      "[Epoch 281/300] Batch 0 | G Loss: 0.9659 | D Loss: 1.1278 | LR: 0.018892 | Momentum: 0.7000\n",
      "[Epoch 281/300] Batch 100 | G Loss: 0.9467 | D Loss: 1.0865 | LR: 0.018885 | Momentum: 0.7000\n",
      "[Epoch 281/300] Batch 200 | G Loss: 0.9463 | D Loss: 1.2489 | LR: 0.018877 | Momentum: 0.7000\n",
      "[Epoch 281/300] Batch 300 | G Loss: 0.9186 | D Loss: 1.1894 | LR: 0.018869 | Momentum: 0.7000\n",
      "[Epoch 281/300] Batch 400 | G Loss: 0.9985 | D Loss: 1.1153 | LR: 0.018862 | Momentum: 0.7000\n",
      "[Epoch 281/300] Batch 500 | G Loss: 0.9909 | D Loss: 1.1374 | LR: 0.018854 | Momentum: 0.7000\n",
      "[Epoch 281/300] Batch 600 | G Loss: 0.9787 | D Loss: 1.1176 | LR: 0.018847 | Momentum: 0.7000\n",
      "[Epoch 281/300] Batch 700 | G Loss: 0.9372 | D Loss: 1.0793 | LR: 0.018839 | Momentum: 0.7000\n",
      "[Epoch 281/300] Batch 800 | G Loss: 0.9832 | D Loss: 1.1492 | LR: 0.018832 | Momentum: 0.7000\n",
      "[Epoch 282/300] Batch 0 | G Loss: 0.9668 | D Loss: 1.1339 | LR: 0.018827 | Momentum: 0.7000\n",
      "[Epoch 282/300] Batch 100 | G Loss: 0.9504 | D Loss: 1.1665 | LR: 0.018819 | Momentum: 0.7000\n",
      "[Epoch 282/300] Batch 200 | G Loss: 0.9489 | D Loss: 1.1223 | LR: 0.018812 | Momentum: 0.7000\n",
      "[Epoch 282/300] Batch 300 | G Loss: 1.0203 | D Loss: 1.1987 | LR: 0.018804 | Momentum: 0.7000\n",
      "[Epoch 282/300] Batch 400 | G Loss: 0.9656 | D Loss: 1.1271 | LR: 0.018796 | Momentum: 0.7000\n",
      "[Epoch 282/300] Batch 500 | G Loss: 1.0585 | D Loss: 1.2293 | LR: 0.018789 | Momentum: 0.7000\n",
      "[Epoch 282/300] Batch 600 | G Loss: 0.9272 | D Loss: 1.2519 | LR: 0.018781 | Momentum: 0.7000\n",
      "[Epoch 282/300] Batch 700 | G Loss: 0.9625 | D Loss: 1.1671 | LR: 0.018774 | Momentum: 0.7000\n",
      "[Epoch 282/300] Batch 800 | G Loss: 0.9543 | D Loss: 1.1996 | LR: 0.018766 | Momentum: 0.7000\n",
      "[Epoch 283/300] Batch 0 | G Loss: 0.9724 | D Loss: 1.2125 | LR: 0.018761 | Momentum: 0.7000\n",
      "[Epoch 283/300] Batch 100 | G Loss: 0.9477 | D Loss: 1.2057 | LR: 0.018754 | Momentum: 0.7000\n",
      "[Epoch 283/300] Batch 200 | G Loss: 0.9787 | D Loss: 1.1180 | LR: 0.018746 | Momentum: 0.7000\n",
      "[Epoch 283/300] Batch 300 | G Loss: 0.9843 | D Loss: 1.1799 | LR: 0.018739 | Momentum: 0.7000\n",
      "[Epoch 283/300] Batch 400 | G Loss: 0.9662 | D Loss: 1.1436 | LR: 0.018731 | Momentum: 0.7000\n",
      "[Epoch 283/300] Batch 500 | G Loss: 0.9582 | D Loss: 1.2220 | LR: 0.018724 | Momentum: 0.7000\n",
      "[Epoch 283/300] Batch 600 | G Loss: 1.0027 | D Loss: 1.2134 | LR: 0.018716 | Momentum: 0.7000\n",
      "[Epoch 283/300] Batch 700 | G Loss: 0.9981 | D Loss: 1.1235 | LR: 0.018709 | Momentum: 0.7000\n",
      "[Epoch 283/300] Batch 800 | G Loss: 0.9013 | D Loss: 1.2055 | LR: 0.018701 | Momentum: 0.7000\n",
      "[Epoch 284/300] Batch 0 | G Loss: 1.0365 | D Loss: 1.0452 | LR: 0.018696 | Momentum: 0.7000\n",
      "[Epoch 284/300] Batch 100 | G Loss: 0.9533 | D Loss: 1.2111 | LR: 0.018689 | Momentum: 0.7000\n",
      "[Epoch 284/300] Batch 200 | G Loss: 1.0033 | D Loss: 1.1469 | LR: 0.018681 | Momentum: 0.7000\n",
      "[Epoch 284/300] Batch 300 | G Loss: 0.9642 | D Loss: 1.1373 | LR: 0.018674 | Momentum: 0.7000\n",
      "[Epoch 284/300] Batch 400 | G Loss: 0.9233 | D Loss: 1.3223 | LR: 0.018666 | Momentum: 0.7000\n",
      "[Epoch 284/300] Batch 500 | G Loss: 0.9394 | D Loss: 1.1091 | LR: 0.018659 | Momentum: 0.7000\n",
      "[Epoch 284/300] Batch 600 | G Loss: 0.9450 | D Loss: 1.1523 | LR: 0.018651 | Momentum: 0.7000\n",
      "[Epoch 284/300] Batch 700 | G Loss: 0.9340 | D Loss: 1.1410 | LR: 0.018644 | Momentum: 0.7000\n",
      "[Epoch 284/300] Batch 800 | G Loss: 0.8942 | D Loss: 1.1006 | LR: 0.018636 | Momentum: 0.7000\n",
      "[Epoch 285/300] Batch 0 | G Loss: 1.0442 | D Loss: 1.1002 | LR: 0.018631 | Momentum: 0.7000\n",
      "[Epoch 285/300] Batch 100 | G Loss: 0.9635 | D Loss: 1.1539 | LR: 0.018624 | Momentum: 0.7000\n",
      "[Epoch 285/300] Batch 200 | G Loss: 0.9315 | D Loss: 1.1904 | LR: 0.018616 | Momentum: 0.7000\n",
      "[Epoch 285/300] Batch 300 | G Loss: 0.9431 | D Loss: 1.1090 | LR: 0.018609 | Momentum: 0.7000\n",
      "[Epoch 285/300] Batch 400 | G Loss: 0.9916 | D Loss: 1.1235 | LR: 0.018601 | Momentum: 0.7000\n",
      "[Epoch 285/300] Batch 500 | G Loss: 0.9759 | D Loss: 1.1706 | LR: 0.018594 | Momentum: 0.7000\n",
      "[Epoch 285/300] Batch 600 | G Loss: 0.8974 | D Loss: 1.2104 | LR: 0.018587 | Momentum: 0.7000\n",
      "[Epoch 285/300] Batch 700 | G Loss: 0.9860 | D Loss: 1.1013 | LR: 0.018579 | Momentum: 0.7000\n",
      "[Epoch 285/300] Batch 800 | G Loss: 0.9901 | D Loss: 1.0955 | LR: 0.018572 | Momentum: 0.7000\n",
      "[Epoch 286/300] Batch 0 | G Loss: 0.9954 | D Loss: 1.1584 | LR: 0.018567 | Momentum: 0.7000\n",
      "[Epoch 286/300] Batch 100 | G Loss: 0.9970 | D Loss: 1.2051 | LR: 0.018559 | Momentum: 0.7000\n",
      "[Epoch 286/300] Batch 200 | G Loss: 0.8993 | D Loss: 1.0444 | LR: 0.018552 | Momentum: 0.7000\n",
      "[Epoch 286/300] Batch 300 | G Loss: 1.0174 | D Loss: 1.1442 | LR: 0.018544 | Momentum: 0.7000\n",
      "[Epoch 286/300] Batch 400 | G Loss: 0.9473 | D Loss: 1.2218 | LR: 0.018537 | Momentum: 0.7000\n",
      "[Epoch 286/300] Batch 500 | G Loss: 0.9504 | D Loss: 1.1756 | LR: 0.018530 | Momentum: 0.7000\n",
      "[Epoch 286/300] Batch 600 | G Loss: 0.9836 | D Loss: 1.0657 | LR: 0.018522 | Momentum: 0.7000\n",
      "[Epoch 286/300] Batch 700 | G Loss: 0.9190 | D Loss: 1.2285 | LR: 0.018515 | Momentum: 0.7000\n",
      "[Epoch 286/300] Batch 800 | G Loss: 0.9683 | D Loss: 1.1188 | LR: 0.018507 | Momentum: 0.7000\n",
      "[Epoch 287/300] Batch 0 | G Loss: 1.0175 | D Loss: 1.1825 | LR: 0.018502 | Momentum: 0.7000\n",
      "[Epoch 287/300] Batch 100 | G Loss: 0.9692 | D Loss: 1.1066 | LR: 0.018495 | Momentum: 0.7000\n",
      "[Epoch 287/300] Batch 200 | G Loss: 0.9075 | D Loss: 1.2132 | LR: 0.018487 | Momentum: 0.7000\n",
      "[Epoch 287/300] Batch 300 | G Loss: 0.9474 | D Loss: 1.1333 | LR: 0.018480 | Momentum: 0.7000\n",
      "[Epoch 287/300] Batch 400 | G Loss: 0.9407 | D Loss: 1.1507 | LR: 0.018473 | Momentum: 0.7000\n",
      "[Epoch 287/300] Batch 500 | G Loss: 0.9996 | D Loss: 1.1953 | LR: 0.018465 | Momentum: 0.7000\n",
      "[Epoch 287/300] Batch 600 | G Loss: 0.8573 | D Loss: 1.0839 | LR: 0.018458 | Momentum: 0.7000\n",
      "[Epoch 287/300] Batch 700 | G Loss: 0.9842 | D Loss: 1.1442 | LR: 0.018450 | Momentum: 0.7000\n",
      "[Epoch 287/300] Batch 800 | G Loss: 0.9469 | D Loss: 1.2515 | LR: 0.018443 | Momentum: 0.7000\n",
      "[Epoch 288/300] Batch 0 | G Loss: 1.0106 | D Loss: 1.1439 | LR: 0.018438 | Momentum: 0.7000\n",
      "[Epoch 288/300] Batch 100 | G Loss: 1.0314 | D Loss: 1.1600 | LR: 0.018431 | Momentum: 0.7000\n",
      "[Epoch 288/300] Batch 200 | G Loss: 0.9784 | D Loss: 1.1658 | LR: 0.018423 | Momentum: 0.7000\n",
      "[Epoch 288/300] Batch 300 | G Loss: 0.9950 | D Loss: 1.1576 | LR: 0.018416 | Momentum: 0.7000\n",
      "[Epoch 288/300] Batch 400 | G Loss: 0.9493 | D Loss: 1.1587 | LR: 0.018409 | Momentum: 0.7000\n",
      "[Epoch 288/300] Batch 500 | G Loss: 0.9681 | D Loss: 1.0322 | LR: 0.018401 | Momentum: 0.7000\n",
      "[Epoch 288/300] Batch 600 | G Loss: 0.9386 | D Loss: 1.1266 | LR: 0.018394 | Momentum: 0.7000\n",
      "[Epoch 288/300] Batch 700 | G Loss: 1.0069 | D Loss: 1.2157 | LR: 0.018386 | Momentum: 0.7000\n",
      "[Epoch 288/300] Batch 800 | G Loss: 0.9574 | D Loss: 1.1301 | LR: 0.018379 | Momentum: 0.7000\n",
      "[Epoch 289/300] Batch 0 | G Loss: 1.0045 | D Loss: 1.1945 | LR: 0.018374 | Momentum: 0.7000\n",
      "[Epoch 289/300] Batch 100 | G Loss: 0.9382 | D Loss: 1.1846 | LR: 0.018367 | Momentum: 0.7000\n",
      "[Epoch 289/300] Batch 200 | G Loss: 0.9302 | D Loss: 1.1278 | LR: 0.018359 | Momentum: 0.7000\n",
      "[Epoch 289/300] Batch 300 | G Loss: 1.0357 | D Loss: 1.1029 | LR: 0.018352 | Momentum: 0.7000\n",
      "[Epoch 289/300] Batch 400 | G Loss: 0.9718 | D Loss: 1.1424 | LR: 0.018345 | Momentum: 0.7000\n",
      "[Epoch 289/300] Batch 500 | G Loss: 0.9623 | D Loss: 1.0706 | LR: 0.018337 | Momentum: 0.7000\n",
      "[Epoch 289/300] Batch 600 | G Loss: 0.9464 | D Loss: 1.1832 | LR: 0.018330 | Momentum: 0.7000\n",
      "[Epoch 289/300] Batch 700 | G Loss: 1.0139 | D Loss: 1.1868 | LR: 0.018323 | Momentum: 0.7000\n",
      "[Epoch 289/300] Batch 800 | G Loss: 0.9845 | D Loss: 1.1284 | LR: 0.018315 | Momentum: 0.7000\n",
      "[Epoch 290/300] Batch 0 | G Loss: 0.9474 | D Loss: 1.1631 | LR: 0.018310 | Momentum: 0.7000\n",
      "[Epoch 290/300] Batch 100 | G Loss: 0.9487 | D Loss: 1.1616 | LR: 0.018303 | Momentum: 0.7000\n",
      "[Epoch 290/300] Batch 200 | G Loss: 0.9462 | D Loss: 1.0688 | LR: 0.018296 | Momentum: 0.7000\n",
      "[Epoch 290/300] Batch 300 | G Loss: 1.0030 | D Loss: 1.1491 | LR: 0.018288 | Momentum: 0.7000\n",
      "[Epoch 290/300] Batch 400 | G Loss: 0.9790 | D Loss: 1.1677 | LR: 0.018281 | Momentum: 0.7000\n",
      "[Epoch 290/300] Batch 500 | G Loss: 0.9808 | D Loss: 1.1623 | LR: 0.018274 | Momentum: 0.7000\n",
      "[Epoch 290/300] Batch 600 | G Loss: 0.9597 | D Loss: 1.1511 | LR: 0.018266 | Momentum: 0.7000\n",
      "[Epoch 290/300] Batch 700 | G Loss: 1.0070 | D Loss: 1.0867 | LR: 0.018259 | Momentum: 0.7000\n",
      "[Epoch 290/300] Batch 800 | G Loss: 0.8594 | D Loss: 1.1892 | LR: 0.018252 | Momentum: 0.7000\n",
      "[Epoch 291/300] Batch 0 | G Loss: 1.0075 | D Loss: 1.0616 | LR: 0.018247 | Momentum: 0.7000\n",
      "[Epoch 291/300] Batch 100 | G Loss: 0.9857 | D Loss: 1.1194 | LR: 0.018239 | Momentum: 0.7000\n",
      "[Epoch 291/300] Batch 200 | G Loss: 0.9816 | D Loss: 1.1197 | LR: 0.018232 | Momentum: 0.7000\n",
      "[Epoch 291/300] Batch 300 | G Loss: 0.9632 | D Loss: 1.1877 | LR: 0.018225 | Momentum: 0.7000\n",
      "[Epoch 291/300] Batch 400 | G Loss: 1.0432 | D Loss: 1.1247 | LR: 0.018218 | Momentum: 0.7000\n",
      "[Epoch 291/300] Batch 500 | G Loss: 0.9954 | D Loss: 1.2083 | LR: 0.018210 | Momentum: 0.7000\n",
      "[Epoch 291/300] Batch 600 | G Loss: 1.0047 | D Loss: 1.1283 | LR: 0.018203 | Momentum: 0.7000\n",
      "[Epoch 291/300] Batch 700 | G Loss: 0.9762 | D Loss: 1.0935 | LR: 0.018196 | Momentum: 0.7000\n",
      "[Epoch 291/300] Batch 800 | G Loss: 0.9481 | D Loss: 1.1412 | LR: 0.018188 | Momentum: 0.7000\n",
      "[Epoch 292/300] Batch 0 | G Loss: 0.9684 | D Loss: 1.2282 | LR: 0.018183 | Momentum: 0.7000\n",
      "[Epoch 292/300] Batch 100 | G Loss: 0.9347 | D Loss: 1.0976 | LR: 0.018176 | Momentum: 0.7000\n",
      "[Epoch 292/300] Batch 200 | G Loss: 0.9956 | D Loss: 1.1774 | LR: 0.018169 | Momentum: 0.7000\n",
      "[Epoch 292/300] Batch 300 | G Loss: 0.9960 | D Loss: 1.1247 | LR: 0.018162 | Momentum: 0.7000\n",
      "[Epoch 292/300] Batch 400 | G Loss: 0.9708 | D Loss: 1.1972 | LR: 0.018154 | Momentum: 0.7000\n",
      "[Epoch 292/300] Batch 500 | G Loss: 0.9386 | D Loss: 1.0795 | LR: 0.018147 | Momentum: 0.7000\n",
      "[Epoch 292/300] Batch 600 | G Loss: 0.9612 | D Loss: 1.1781 | LR: 0.018140 | Momentum: 0.7000\n",
      "[Epoch 292/300] Batch 700 | G Loss: 0.9087 | D Loss: 1.1424 | LR: 0.018133 | Momentum: 0.7000\n",
      "[Epoch 292/300] Batch 800 | G Loss: 0.9506 | D Loss: 1.0977 | LR: 0.018125 | Momentum: 0.7000\n",
      "[Epoch 293/300] Batch 0 | G Loss: 1.0065 | D Loss: 1.1219 | LR: 0.018120 | Momentum: 0.7000\n",
      "[Epoch 293/300] Batch 100 | G Loss: 1.0161 | D Loss: 1.2256 | LR: 0.018113 | Momentum: 0.7000\n",
      "[Epoch 293/300] Batch 200 | G Loss: 0.9315 | D Loss: 1.0716 | LR: 0.018106 | Momentum: 0.7000\n",
      "[Epoch 293/300] Batch 300 | G Loss: 0.9925 | D Loss: 1.1338 | LR: 0.018099 | Momentum: 0.7000\n",
      "[Epoch 293/300] Batch 400 | G Loss: 1.0149 | D Loss: 1.1923 | LR: 0.018091 | Momentum: 0.7000\n",
      "[Epoch 293/300] Batch 500 | G Loss: 0.9804 | D Loss: 1.1628 | LR: 0.018084 | Momentum: 0.7000\n",
      "[Epoch 293/300] Batch 600 | G Loss: 0.9717 | D Loss: 1.1922 | LR: 0.018077 | Momentum: 0.7000\n",
      "[Epoch 293/300] Batch 700 | G Loss: 1.0085 | D Loss: 1.1540 | LR: 0.018070 | Momentum: 0.7000\n",
      "[Epoch 293/300] Batch 800 | G Loss: 0.9657 | D Loss: 1.1795 | LR: 0.018062 | Momentum: 0.7000\n",
      "[Epoch 294/300] Batch 0 | G Loss: 0.9759 | D Loss: 1.1774 | LR: 0.018057 | Momentum: 0.7000\n",
      "[Epoch 294/300] Batch 100 | G Loss: 1.0217 | D Loss: 1.1662 | LR: 0.018050 | Momentum: 0.7000\n",
      "[Epoch 294/300] Batch 200 | G Loss: 0.9609 | D Loss: 1.1728 | LR: 0.018043 | Momentum: 0.7000\n",
      "[Epoch 294/300] Batch 300 | G Loss: 1.0194 | D Loss: 1.1107 | LR: 0.018036 | Momentum: 0.7000\n",
      "[Epoch 294/300] Batch 400 | G Loss: 1.0149 | D Loss: 1.1361 | LR: 0.018029 | Momentum: 0.7000\n",
      "[Epoch 294/300] Batch 500 | G Loss: 0.9241 | D Loss: 1.1859 | LR: 0.018021 | Momentum: 0.7000\n",
      "[Epoch 294/300] Batch 600 | G Loss: 0.9618 | D Loss: 1.1121 | LR: 0.018014 | Momentum: 0.7000\n",
      "[Epoch 294/300] Batch 700 | G Loss: 1.0136 | D Loss: 1.0778 | LR: 0.018007 | Momentum: 0.7000\n",
      "[Epoch 294/300] Batch 800 | G Loss: 0.9407 | D Loss: 1.1446 | LR: 0.018000 | Momentum: 0.7000\n",
      "[Epoch 295/300] Batch 0 | G Loss: 0.9795 | D Loss: 1.1205 | LR: 0.017995 | Momentum: 0.7000\n",
      "[Epoch 295/300] Batch 100 | G Loss: 0.9334 | D Loss: 1.0883 | LR: 0.017988 | Momentum: 0.7000\n",
      "[Epoch 295/300] Batch 200 | G Loss: 0.9561 | D Loss: 1.1306 | LR: 0.017980 | Momentum: 0.7000\n",
      "[Epoch 295/300] Batch 300 | G Loss: 0.9993 | D Loss: 1.2414 | LR: 0.017973 | Momentum: 0.7000\n",
      "[Epoch 295/300] Batch 400 | G Loss: 0.9898 | D Loss: 1.2049 | LR: 0.017966 | Momentum: 0.7000\n",
      "[Epoch 295/300] Batch 500 | G Loss: 0.9921 | D Loss: 1.2880 | LR: 0.017959 | Momentum: 0.7000\n",
      "[Epoch 295/300] Batch 600 | G Loss: 0.9416 | D Loss: 1.1377 | LR: 0.017952 | Momentum: 0.7000\n",
      "[Epoch 295/300] Batch 700 | G Loss: 1.0480 | D Loss: 1.2412 | LR: 0.017944 | Momentum: 0.7000\n",
      "[Epoch 295/300] Batch 800 | G Loss: 0.9652 | D Loss: 1.2407 | LR: 0.017937 | Momentum: 0.7000\n",
      "[Epoch 296/300] Batch 0 | G Loss: 0.9506 | D Loss: 1.1973 | LR: 0.017932 | Momentum: 0.7000\n",
      "[Epoch 296/300] Batch 100 | G Loss: 0.9192 | D Loss: 1.1104 | LR: 0.017925 | Momentum: 0.7000\n",
      "[Epoch 296/300] Batch 200 | G Loss: 0.9832 | D Loss: 1.1959 | LR: 0.017918 | Momentum: 0.7000\n",
      "[Epoch 296/300] Batch 300 | G Loss: 0.9303 | D Loss: 1.0869 | LR: 0.017911 | Momentum: 0.7000\n",
      "[Epoch 296/300] Batch 400 | G Loss: 0.9510 | D Loss: 1.1426 | LR: 0.017904 | Momentum: 0.7000\n",
      "[Epoch 296/300] Batch 500 | G Loss: 1.0028 | D Loss: 1.0718 | LR: 0.017896 | Momentum: 0.7000\n",
      "[Epoch 296/300] Batch 600 | G Loss: 0.9594 | D Loss: 1.1310 | LR: 0.017889 | Momentum: 0.7000\n",
      "[Epoch 296/300] Batch 700 | G Loss: 0.9697 | D Loss: 1.0508 | LR: 0.017882 | Momentum: 0.7000\n",
      "[Epoch 296/300] Batch 800 | G Loss: 0.9804 | D Loss: 1.1483 | LR: 0.017875 | Momentum: 0.7000\n",
      "[Epoch 297/300] Batch 0 | G Loss: 0.9443 | D Loss: 1.1153 | LR: 0.017870 | Momentum: 0.7000\n",
      "[Epoch 297/300] Batch 100 | G Loss: 0.9858 | D Loss: 1.1070 | LR: 0.017863 | Momentum: 0.7000\n",
      "[Epoch 297/300] Batch 200 | G Loss: 0.9398 | D Loss: 1.0251 | LR: 0.017856 | Momentum: 0.7000\n",
      "[Epoch 297/300] Batch 300 | G Loss: 0.9739 | D Loss: 1.2286 | LR: 0.017849 | Momentum: 0.7000\n",
      "[Epoch 297/300] Batch 400 | G Loss: 0.9699 | D Loss: 1.1457 | LR: 0.017842 | Momentum: 0.7000\n",
      "[Epoch 297/300] Batch 500 | G Loss: 0.9773 | D Loss: 1.0969 | LR: 0.017834 | Momentum: 0.7000\n",
      "[Epoch 297/300] Batch 600 | G Loss: 0.9818 | D Loss: 1.0969 | LR: 0.017827 | Momentum: 0.7000\n",
      "[Epoch 297/300] Batch 700 | G Loss: 1.0306 | D Loss: 1.0979 | LR: 0.017820 | Momentum: 0.7000\n",
      "[Epoch 297/300] Batch 800 | G Loss: 0.9907 | D Loss: 1.1343 | LR: 0.017813 | Momentum: 0.7000\n",
      "[Epoch 298/300] Batch 0 | G Loss: 1.0216 | D Loss: 1.0677 | LR: 0.017808 | Momentum: 0.7000\n",
      "[Epoch 298/300] Batch 100 | G Loss: 0.9632 | D Loss: 1.1696 | LR: 0.017801 | Momentum: 0.7000\n",
      "[Epoch 298/300] Batch 200 | G Loss: 0.9709 | D Loss: 1.0356 | LR: 0.017794 | Momentum: 0.7000\n",
      "[Epoch 298/300] Batch 300 | G Loss: 1.0153 | D Loss: 1.1696 | LR: 0.017787 | Momentum: 0.7000\n",
      "[Epoch 298/300] Batch 400 | G Loss: 0.9316 | D Loss: 1.1018 | LR: 0.017780 | Momentum: 0.7000\n",
      "[Epoch 298/300] Batch 500 | G Loss: 1.0097 | D Loss: 1.1061 | LR: 0.017773 | Momentum: 0.7000\n",
      "[Epoch 298/300] Batch 600 | G Loss: 0.9677 | D Loss: 1.1142 | LR: 0.017765 | Momentum: 0.7000\n",
      "[Epoch 298/300] Batch 700 | G Loss: 0.9763 | D Loss: 1.1273 | LR: 0.017758 | Momentum: 0.7000\n",
      "[Epoch 298/300] Batch 800 | G Loss: 0.9735 | D Loss: 1.1424 | LR: 0.017751 | Momentum: 0.7000\n",
      "[Epoch 299/300] Batch 0 | G Loss: 0.9284 | D Loss: 1.1849 | LR: 0.017746 | Momentum: 0.7000\n",
      "[Epoch 299/300] Batch 100 | G Loss: 1.0216 | D Loss: 1.0797 | LR: 0.017739 | Momentum: 0.7000\n",
      "[Epoch 299/300] Batch 200 | G Loss: 0.9931 | D Loss: 1.2646 | LR: 0.017732 | Momentum: 0.7000\n",
      "[Epoch 299/300] Batch 300 | G Loss: 0.9385 | D Loss: 1.1301 | LR: 0.017725 | Momentum: 0.7000\n",
      "[Epoch 299/300] Batch 400 | G Loss: 0.9463 | D Loss: 1.0741 | LR: 0.017718 | Momentum: 0.7000\n",
      "[Epoch 299/300] Batch 500 | G Loss: 0.9593 | D Loss: 1.0747 | LR: 0.017711 | Momentum: 0.7000\n",
      "[Epoch 299/300] Batch 600 | G Loss: 0.9340 | D Loss: 1.1708 | LR: 0.017704 | Momentum: 0.7000\n",
      "[Epoch 299/300] Batch 700 | G Loss: 0.9792 | D Loss: 1.0711 | LR: 0.017697 | Momentum: 0.7000\n",
      "[Epoch 299/300] Batch 800 | G Loss: 0.9894 | D Loss: 1.0602 | LR: 0.017690 | Momentum: 0.7000\n",
      "[Epoch 300/300] Batch 0 | G Loss: 0.9815 | D Loss: 1.1265 | LR: 0.017685 | Momentum: 0.7000\n",
      "[Epoch 300/300] Batch 100 | G Loss: 0.9628 | D Loss: 1.1458 | LR: 0.017678 | Momentum: 0.7000\n",
      "[Epoch 300/300] Batch 200 | G Loss: 0.9627 | D Loss: 1.1096 | LR: 0.017671 | Momentum: 0.7000\n",
      "[Epoch 300/300] Batch 300 | G Loss: 0.9722 | D Loss: 1.0554 | LR: 0.017664 | Momentum: 0.7000\n",
      "[Epoch 300/300] Batch 400 | G Loss: 0.9610 | D Loss: 1.1608 | LR: 0.017656 | Momentum: 0.7000\n",
      "[Epoch 300/300] Batch 500 | G Loss: 0.9740 | D Loss: 1.1211 | LR: 0.017649 | Momentum: 0.7000\n",
      "[Epoch 300/300] Batch 600 | G Loss: 1.0058 | D Loss: 1.2202 | LR: 0.017642 | Momentum: 0.7000\n",
      "[Epoch 300/300] Batch 700 | G Loss: 0.9913 | D Loss: 1.2371 | LR: 0.017635 | Momentum: 0.7000\n",
      "[Epoch 300/300] Batch 800 | G Loss: 0.9993 | D Loss: 1.1873 | LR: 0.017628 | Momentum: 0.7000\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:10:00.008473Z",
     "start_time": "2025-06-08T09:09:59.787278Z"
    }
   },
   "cell_type": "code",
   "source": "gan.load_weights(path_prefix=\"300_tfd_gan_weights\", device=device)",
   "id": "f20a2b94f959f207",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights loaded from 300_tfd_gan_weights_*.pth\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:10:02.201314Z",
     "start_time": "2025-06-08T09:10:01.408427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "samples = gan.sample_z(batch_size=100000, uniform_range=UNIFORM_RANGE)\n",
    "samples = gan.generator(samples).detach()"
   ],
   "id": "b895d9888737a38c",
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.98 GiB. GPU 0 has a total capacity of 7.91 GiB of which 257.69 MiB is free. Including non-PyTorch memory, this process has 7.45 GiB memory in use. Of the allocated memory 7.27 GiB is allocated by PyTorch, and 59.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mOutOfMemoryError\u001B[39m                          Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m samples = gan.sample_z(batch_size=\u001B[32m100000\u001B[39m, uniform_range=UNIFORM_RANGE)\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m samples = \u001B[43mgan\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgenerator\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m)\u001B[49m.detach()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.cache/pypoetry/virtualenvs/adversarial-autoencoder-cawwEU7D-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.cache/pypoetry/virtualenvs/adversarial-autoencoder-cawwEU7D-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.cache/pypoetry/virtualenvs/adversarial-autoencoder-cawwEU7D-py3.12/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001B[39m, in \u001B[36mSequential.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    248\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[32m    249\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m250\u001B[39m         \u001B[38;5;28minput\u001B[39m = \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    251\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.cache/pypoetry/virtualenvs/adversarial-autoencoder-cawwEU7D-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.cache/pypoetry/virtualenvs/adversarial-autoencoder-cawwEU7D-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.cache/pypoetry/virtualenvs/adversarial-autoencoder-cawwEU7D-py3.12/lib/python3.12/site-packages/torch/nn/modules/activation.py:133\u001B[39m, in \u001B[36mReLU.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    132\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m133\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrelu\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minplace\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.cache/pypoetry/virtualenvs/adversarial-autoencoder-cawwEU7D-py3.12/lib/python3.12/site-packages/torch/nn/functional.py:1704\u001B[39m, in \u001B[36mrelu\u001B[39m\u001B[34m(input, inplace)\u001B[39m\n\u001B[32m   1702\u001B[39m     result = torch.relu_(\u001B[38;5;28minput\u001B[39m)\n\u001B[32m   1703\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1704\u001B[39m     result = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrelu\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1705\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[31mOutOfMemoryError\u001B[39m: CUDA out of memory. Tried to allocate 2.98 GiB. GPU 0 has a total capacity of 7.91 GiB of which 257.69 MiB is free. Including non-PyTorch memory, this process has 7.45 GiB memory in use. Of the allocated memory 7.27 GiB is allocated by PyTorch, and 59.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T07:09:35.276636Z",
     "start_time": "2025-05-28T03:34:44.775525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cross_validate_sigma(\n",
    "    samples=rescale_to_unit_interval_individual(samples, mean, std),\n",
    "    validation_dataset=rescale_to_unit_interval_individual(X_train[0:10000], mean, std),\n",
    "    sigma_range=np.exp(np.linspace(np.log(0.09), np.log(0.5),40)),\n",
    "    batch_size=100,\n",
    ")"
   ],
   "id": "ea052cf3cc9cd286",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating sigma = 0.08999999999999998\n",
      "Sigma: 0.09000, Log-Likelihood: 1769.41218\n",
      "Evaluating sigma = 0.09404551439665289\n",
      "Sigma: 0.09405, Log-Likelihood: 1818.78718\n",
      "Evaluating sigma = 0.0982728753125672\n",
      "Sigma: 0.09827, Log-Likelihood: 1885.94755\n",
      "Evaluating sigma = 0.10269025677787244\n",
      "Sigma: 0.10269, Log-Likelihood: 1888.07175\n",
      "Evaluating sigma = 0.10730620024665986\n",
      "Sigma: 0.10731, Log-Likelihood: 1887.96365\n",
      "Evaluating sigma = 0.11212963111274855\n",
      "Sigma: 0.11213, Log-Likelihood: 1918.23878\n",
      "Evaluating sigma = 0.1171698759678375\n",
      "Sigma: 0.11717, Log-Likelihood: 1886.46478\n",
      "Evaluating sigma = 0.12243668063541442\n",
      "Sigma: 0.12244, Log-Likelihood: 1880.03388\n",
      "Evaluating sigma = 0.12794022901529187\n",
      "Sigma: 0.12794, Log-Likelihood: 1859.38887\n",
      "Evaluating sigma = 0.1336911627752078\n",
      "Sigma: 0.13369, Log-Likelihood: 1824.89152\n",
      "Evaluating sigma = 0.13970060192756747\n",
      "Sigma: 0.13970, Log-Likelihood: 1786.50862\n",
      "Evaluating sigma = 0.1459801663311125\n",
      "Sigma: 0.14598, Log-Likelihood: 1733.03859\n",
      "Evaluating sigma = 0.15254199815909367\n",
      "Sigma: 0.15254, Log-Likelihood: 1674.86714\n",
      "Evaluating sigma = 0.15939878537739166\n",
      "Sigma: 0.15940, Log-Likelihood: 1627.64412\n",
      "Evaluating sigma = 0.16656378627798304\n",
      "Sigma: 0.16656, Log-Likelihood: 1566.96197\n",
      "Evaluating sigma = 0.17405085511518972\n",
      "Sigma: 0.17405, Log-Likelihood: 1501.08812\n",
      "Evaluating sigma = 0.18187446889428138\n",
      "Sigma: 0.18187, Log-Likelihood: 1435.35755\n",
      "Evaluating sigma = 0.19004975536423052\n",
      "Sigma: 0.19005, Log-Likelihood: 1365.24297\n",
      "Evaluating sigma = 0.19859252226874566\n",
      "Sigma: 0.19859, Log-Likelihood: 1280.65198\n",
      "Evaluating sigma = 0.20751928791214372\n",
      "Sigma: 0.20752, Log-Likelihood: 1210.16998\n",
      "Evaluating sigma = 0.21684731309916302\n",
      "Sigma: 0.21685, Log-Likelihood: 1141.80798\n",
      "Evaluating sigma = 0.22659463451047598\n",
      "Sigma: 0.22659, Log-Likelihood: 1059.35456\n",
      "Evaluating sigma = 0.23678009957843643\n",
      "Sigma: 0.23678, Log-Likelihood: 973.86234\n",
      "Evaluating sigma = 0.24742340293049728\n",
      "Sigma: 0.24742, Log-Likelihood: 892.79446\n",
      "Evaluating sigma = 0.258545124470766\n",
      "Sigma: 0.25855, Log-Likelihood: 807.34178\n",
      "Evaluating sigma = 0.2701667691733316\n",
      "Sigma: 0.27017, Log-Likelihood: 719.09067\n",
      "Evaluating sigma = 0.2823108086643085\n",
      "Sigma: 0.28231, Log-Likelihood: 628.76716\n",
      "Evaluating sigma = 0.2950007246729995\n",
      "Sigma: 0.29500, Log-Likelihood: 542.63146\n",
      "Evaluating sigma = 0.3082610544361957\n",
      "Sigma: 0.30826, Log-Likelihood: 452.80501\n",
      "Evaluating sigma = 0.3221174381434073\n",
      "Sigma: 0.32212, Log-Likelihood: 360.03128\n",
      "Evaluating sigma = 0.3365966685147641\n",
      "Sigma: 0.33660, Log-Likelihood: 270.71598\n",
      "Evaluating sigma = 0.3517267426074518\n",
      "Sigma: 0.35173, Log-Likelihood: 176.62978\n",
      "Evaluating sigma = 0.3675369159508549\n",
      "Sigma: 0.36754, Log-Likelihood: 82.73079\n",
      "Evaluating sigma = 0.3840577591150838\n",
      "Sigma: 0.38406, Log-Likelihood: -10.18426\n",
      "Evaluating sigma = 0.4013212168222653\n",
      "Sigma: 0.40132, Log-Likelihood: -105.21049\n",
      "Evaluating sigma = 0.4193606697148957\n",
      "Sigma: 0.41936, Log-Likelihood: -201.22729\n",
      "Evaluating sigma = 0.43821099890069154\n",
      "Sigma: 0.43821, Log-Likelihood: -296.69828\n",
      "Evaluating sigma = 0.4579086533987405\n",
      "Sigma: 0.45791, Log-Likelihood: -392.29007\n",
      "Evaluating sigma = 0.47849172061736883\n",
      "Sigma: 0.47849, Log-Likelihood: -489.07753\n",
      "Evaluating sigma = 0.5\n",
      "Sigma: 0.50000, Log-Likelihood: -587.11599\n",
      "Best sigma: 0.11212963111274855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.11212963111274855)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T07:38:44.708935Z",
     "start_time": "2025-05-28T07:31:21.048095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 0.11212963111274855\n",
    "estimate_log_likelihood(\n",
    "    samples=rescale_to_unit_interval_individual(samples, mean, std),\n",
    "    test_data=rescale_to_unit_interval_global(X_test),\n",
    "    sigma=0.11104586060596347\n",
    "\n",
    ")\n"
   ],
   "id": "50618adf21b73a28",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(2162.721767602233), np.float64(7.311285554510226))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

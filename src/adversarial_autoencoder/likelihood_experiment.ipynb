{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Adversarial Autoencoder (Basic Implementation)",
   "id": "cc6f0c4da6afad06"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-11T17:10:15.509594Z",
     "start_time": "2025-05-11T17:10:15.506721Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from adversarial import AdversarialAutoencoder\n",
    "from likelihood import"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset Configuration",
   "id": "d6e7501bcda3f6b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T17:10:16.544272Z",
     "start_time": "2025-05-11T17:10:16.540336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def configure_mnist(batch_size=100):\n",
    "    # Define the transform to convert to tensor and flatten the image\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # [0, 1 normalization]\n",
    "        transforms.Lambda(lambda x: x.view(-1))  # Flatten\n",
    "    ])\n",
    "\n",
    "    # Load the training and test datasets\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "    # Extract the training and test data and labels\n",
    "    X_train = train_dataset.data.float().div(255).view(-1, 28 * 28)  # Normalize and flatten\n",
    "    X_test = test_dataset.data.float().div(255).view(-1, 28 * 28)\n",
    "\n",
    "    Y_train = train_dataset.targets  # Get corresponding labels\n",
    "    Y_test = test_dataset.targets  # Get corresponding labels\n",
    "\n",
    "    # Create the DataLoader for training\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # Return data and dataloader as a tuple\n",
    "    return X_train, X_test, Y_train, Y_test, train_loader\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "1d205ac29e836e51",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paper Configuration",
   "id": "6ac1fa5ebb04e182"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T17:11:33.247835Z",
     "start_time": "2025-05-11T17:11:33.243694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "INPUT_DIM = 784\n",
    "BATCH_SIZE = 100\n",
    "AE_HIDDEN = 1000\n",
    "DC_HIDDEN = 1000\n",
    "LATENT_DIM = 8\n",
    "PRIOR_STD = 5.0\n",
    "recon_loss = nn.MSELoss()\n",
    "init_recon_lr = 0.01\n",
    "init_gen_lr = init_disc_lr = 0.1\n",
    "use_decoder_sigmoid = True\n"
   ],
   "id": "1b0bb15c7c03c19d",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "beaffbcac085f1c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T17:10:20.815167Z",
     "start_time": "2025-05-11T17:10:20.658629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "aae = AdversarialAutoencoder(\n",
    "    input_dim=INPUT_DIM,\n",
    "    ae_hidden=AE_HIDDEN,\n",
    "    dc_hidden=DC_HIDDEN,\n",
    "    latent_dim=LATENT_DIM,\n",
    "    recon_loss_fn=recon_loss,\n",
    "    init_recon_lr=init_recon_lr,\n",
    "    init_gen_lr=init_gen_lr,\n",
    "    init_disc_lr=init_disc_lr,\n",
    "    use_decoder_sigmoid=use_decoder_sigmoid,\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "X_train, X_test, Y_train, Y_test, train_loader = configure_mnist(batch_size=BATCH_SIZE)\n",
    "\n"
   ],
   "id": "38ae34fd974a4959",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T17:10:37.061208Z",
     "start_time": "2025-05-11T17:10:25.787759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "aae.train_mbgd(\n",
    "    data_loader=train_loader,\n",
    "    epochs=50,\n",
    "    prior_std=PRIOR_STD,\n",
    ")"
   ],
   "id": "3c342f55b0afaf44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch (1/50)\t)Recon Loss: 0.2297\t)Disc Loss: 0.3583\t)Gen Loss: 3.3949\t)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[27]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43maae\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain_mbgd\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdata_loader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m50\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43mprior_std\u001B[49m\u001B[43m=\u001B[49m\u001B[43mPRIOR_STD\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/school/adversarial-autoencoder/src/adversarial_autoencoder/adversarial.py:116\u001B[39m, in \u001B[36mAdversarialAutoencoder.train_mbgd\u001B[39m\u001B[34m(self, data_loader, epochs, prior_std)\u001B[39m\n\u001B[32m    113\u001B[39m total_disc_loss = \u001B[32m0\u001B[39m\n\u001B[32m    114\u001B[39m total_gen_loss = \u001B[32m0\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m116\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata_loader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    117\u001B[39m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    119\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# === RECON PHASE ====\u001B[39;49;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.cache/pypoetry/virtualenvs/adversarial-autoencoder-cawwEU7D-py3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    705\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    706\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    707\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m708\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    709\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    710\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    711\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    712\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    713\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    714\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.cache/pypoetry/virtualenvs/adversarial-autoencoder-cawwEU7D-py3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001B[39m, in \u001B[36m_SingleProcessDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    762\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    763\u001B[39m     index = \u001B[38;5;28mself\u001B[39m._next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m764\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    765\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pin_memory:\n\u001B[32m    766\u001B[39m         data = _utils.pin_memory.pin_memory(data, \u001B[38;5;28mself\u001B[39m._pin_memory_device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.cache/pypoetry/virtualenvs/adversarial-autoencoder-cawwEU7D-py3.12/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001B[39m, in \u001B[36m_MapDatasetFetcher.fetch\u001B[39m\u001B[34m(self, possibly_batched_index)\u001B[39m\n\u001B[32m     50\u001B[39m         data = \u001B[38;5;28mself\u001B[39m.dataset.__getitems__(possibly_batched_index)\n\u001B[32m     51\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m         data = [\u001B[38;5;28mself\u001B[39m.dataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     54\u001B[39m     data = \u001B[38;5;28mself\u001B[39m.dataset[possibly_batched_index]\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation",
   "id": "2b59937fd99ca13c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T11:21:11.672227Z",
     "start_time": "2025-04-29T11:21:11.651658Z"
    }
   },
   "cell_type": "code",
   "source": "aae.load_weights()",
   "id": "aed1c8ebded9bf22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights loaded from aae_weights_*.pth\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T17:11:05.273534Z",
     "start_time": "2025-05-11T17:11:05.271403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n"
   ],
   "id": "6546e2782cbfb046",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Include likelihood experiments down here after.",
   "id": "616086957e41d44c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

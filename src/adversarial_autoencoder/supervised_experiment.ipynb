{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Supervised Experiment",
   "id": "90a2d6b4ff9cfe71"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-16T10:57:56.282593Z",
     "start_time": "2025-05-16T10:57:56.273547Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from src.adversarial_autoencoder.supervised import SupervisedAdversarialAutoencoder\n",
    "from src.adversarial_autoencoder.supervised import load_data"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Paper Config",
   "id": "6149481fdebeb3d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:57:56.298254Z",
     "start_time": "2025-05-16T10:57:56.282593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NUM_EPOCHS = 2000\n",
    "\n",
    "INPUT_DIM = 784\n",
    "BATCH_SIZE = 100\n",
    "AE_HIDDEN = 1000\n",
    "DC_HIDDEN = 1000\n",
    "LATENT_DIM = 15\n",
    "NUM_CLASSES = 10\n",
    "PRIOR_STD = 1.0\n",
    "recon_loss = nn.MSELoss()\n",
    "init_recon_lr = 0.001#0.01\n",
    "init_gen_lr = init_disc_lr = 0.0005#0.1\n",
    "use_decoder_sigmoid = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "a4068a55159707f8",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load Training Data",
   "id": "4fa594e2dd543349"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:57:56.329558Z",
     "start_time": "2025-05-16T10:57:56.298254Z"
    }
   },
   "cell_type": "code",
   "source": "train_loader, test_loader = load_data(BATCH_SIZE, -1)",
   "id": "db9cd79c60faa096",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model setup",
   "id": "159605e1f656be70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T10:57:56.360437Z",
     "start_time": "2025-05-16T10:57:56.329558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "aae = SupervisedAdversarialAutoencoder(\n",
    "    input_dim=INPUT_DIM,\n",
    "    ae_hidden=AE_HIDDEN,\n",
    "    dc_hidden=DC_HIDDEN,\n",
    "    latent_dim=LATENT_DIM,\n",
    "    recon_loss_fn=recon_loss,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    init_recon_lr=init_recon_lr,\n",
    "    init_gen_lr=init_gen_lr,\n",
    "    init_disc_lr=init_disc_lr,\n",
    "    use_decoder_sigmoid=use_decoder_sigmoid,\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")"
   ],
   "id": "72aba123a7a1eb2f",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train Model",
   "id": "868a10d272019475"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-16T10:57:56.361590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# aae.load_weights(\"weights/supervised_2_2000\")\n",
    "aae.train_mbgd(\n",
    "    data_loader=train_loader,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    prior_std=PRIOR_STD,\n",
    ")\n",
    "aae.save_weights(\"weights/supervised_\" + str(LATENT_DIM) + \"_\" + str(NUM_EPOCHS))"
   ],
   "id": "4ac0d909b0e9c387",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 7/2000 [00:30<2:31:05,  4.55s/epoch]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualize",
   "id": "ab2f69f2b306311d"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_reconstructions(model, test_loader, num_images=5):\n",
    "    model.eval()\n",
    "    data_iter = iter(test_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    images = images.to(model.device)\n",
    "    images_flattened = images.view(images.size(0), -1)\n",
    "    labels_one_hot = torch.nn.functional.one_hot(labels, num_classes=model.num_classes).float().to(model.device)\n",
    "    \n",
    "    # Pass through the encoder and decoder\n",
    "    with torch.no_grad():\n",
    "        z = model.encoder(images_flattened)\n",
    "        z_cat = torch.cat([z, labels_one_hot], dim=1)\n",
    "        recon_images = model.decoder(z_cat)\n",
    "    \n",
    "    # Plot the original images and their reconstructions\n",
    "    fig, axes = plt.subplots(2, num_images, figsize=(12, 6))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Original image\n",
    "        ax = axes[0, i]\n",
    "        ax.imshow(images[i].cpu().detach().numpy().reshape(28, 28), cmap='gray')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"Original {labels[i].item()}\")\n",
    "        \n",
    "        # Reconstructed image\n",
    "        ax = axes[1, i]\n",
    "        ax.imshow(recon_images[i].cpu().detach().numpy().reshape(28, 28), cmap='gray')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"Reconstruction {labels[i].item()}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to display the results\n",
    "display_reconstructions(aae, test_loader)\n"
   ],
   "id": "5bf5db6de7332f13",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_image_grid(aae, latent_dim, prior_std, n_classes=10):\n",
    "    aae.eval()\n",
    "    device = next(aae.parameters()).device\n",
    "    fig, axes = plt.subplots(1, n_classes, figsize=(15, 2))\n",
    "\n",
    "    z = torch.randn(1, latent_dim).to(device) * prior_std\n",
    "    for i in range(n_classes):\n",
    "        # New z for each class (optional: use fixed z to see label impact)\n",
    "        y = torch.zeros(1, n_classes).to(device)\n",
    "        y[0, i] = 1  # One-hot\n",
    "        # print(y)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x_hat = aae.decoder(torch.cat([z, y], dim=1))\n",
    "            x_hat = x_hat.view(28, 28).cpu()\n",
    "\n",
    "        axes[i].imshow(x_hat, cmap='gray', vmin=0, vmax=1)  # Force [0,1] range\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f'{i}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "generate_image_grid(aae, latent_dim=LATENT_DIM, prior_std=PRIOR_STD)\n",
    "generate_image_grid(aae, latent_dim=LATENT_DIM, prior_std=PRIOR_STD)\n",
    "generate_image_grid(aae, latent_dim=LATENT_DIM, prior_std=PRIOR_STD)"
   ],
   "id": "4e4161cca660ea40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2bfe4ba861b0acd4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

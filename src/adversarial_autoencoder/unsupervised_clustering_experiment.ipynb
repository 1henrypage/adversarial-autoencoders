{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Unsupervised AAE – MNIST\n",
    "# Stand-alone version (no inheritance) + clustering accuracy\n",
    "\n",
    "# %%\n",
    "import torch, torch.nn as nn\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from unsupervised import (\n",
    "    UAAEConfig,\n",
    "    UnsupervisedAdversarialAutoencoder,\n",
    ")\n",
    "from dataloader import load_mnist_data          # your helper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "VAL_SAMPLES = 5000\n",
    "TEST_SAMPLES = 5000\n",
    "\n",
    "# Load full train and test sets\n",
    "train_loader_full, test_loader_full = load_mnist_data(batch_size=BATCH_SIZE, num_samples=-1)\n",
    "full_train_ds = train_loader_full.dataset   # 60,000 samples\n",
    "full_test_ds = test_loader_full.dataset     # 10,000 samples\n",
    "\n",
    "# Keep all of training set\n",
    "train_loader = torch.utils.data.DataLoader(full_train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "# ── Take 5,000 from test set for validation, rest for testing ──\n",
    "val_ds, test_ds = torch.utils.data.random_split(\n",
    "    full_test_ds,\n",
    "    [VAL_SAMPLES, TEST_SAMPLES],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "val_loader  = torch.utils.data.DataLoader(val_ds,  batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Train samples: {len(full_train_ds)} | Val samples: {len(val_ds)} | Test samples: {len(test_ds)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "cfg = UAAEConfig(\n",
    "    input_dim   = 784,\n",
    "    ae_hidden   = 3000,\n",
    "    disc_hidden = 3000,\n",
    "    latent_dim_categorical = 16,\n",
    "    latent_dim_style = 5,\n",
    "    use_decoder_sigmoid = True,\n",
    ")\n",
    "print(f'Device found: {cfg.device}')\n",
    "model = UnsupervisedAdversarialAutoencoder(cfg)\n",
    "# model.load_weights('runs/unsup_aae/weights_epoch_50/weights')\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_loader  = train_loader,\n",
    "    val_loader  = val_loader,     # gives val accuracy each epoch\n",
    "    test_loader = test_loader,\n",
    "    epochs      = 500, # 1500\n",
    "    prior_std   = 1.0,\n",
    "    result_folder     = Path(\"runs/unsup_aae\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "test_acc = model.evaluate_clustering(val_loader, test_loader)\n",
    "print(f\"Test clustering accuracy: {test_acc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "# ── 1. Read CSV ───────────────────────────────────────────────────────────────\n",
    "df = pd.read_csv(\"runs/unsup_aae/batch_log.csv\")\n",
    "df[\"batch\"] = df[\"batch\"].astype(int)\n",
    "df[\"epoch\"] = df[\"epoch\"].astype(int)\n",
    "\n",
    "# ── 2. Create Iteration Axis ──────────────────────────────────────────────────\n",
    "if df[\"epoch\"].nunique() > 1:\n",
    "    num_batches_per_epoch = df.loc[df[\"epoch\"] < df[\"epoch\"].max(), \"batch\"].max()\n",
    "else:\n",
    "    num_batches_per_epoch = df[\"batch\"].max()\n",
    "\n",
    "df[\"iteration\"] = (df[\"epoch\"] - 1) * num_batches_per_epoch + df[\"batch\"]\n",
    "df = df.sort_values(\"iteration\").reset_index(drop=True)\n",
    "\n",
    "# grab the final iteration value\n",
    "max_iter = df[\"iteration\"].max()\n",
    "\n",
    "# ── 3. Define loss groups and colors ─────────────────────────────────────────\n",
    "groups = {\n",
    "    \"Reconstruction Loss\"       : [\"recon_loss\"],\n",
    "    \"Categorical Disc/Gen Loss\" : [\"disc_cat_loss\", \"gen_cat_loss\"],\n",
    "    \"Style Disc/Gen Loss\"       : [\"disc_style_loss\", \"gen_style_loss\"],\n",
    "}\n",
    "\n",
    "colors = {\n",
    "    \"recon_loss\"      : \"green\",\n",
    "    \"disc_cat_loss\"   : \"blue\",\n",
    "    \"gen_cat_loss\"    : \"orange\",\n",
    "    \"disc_style_loss\" : \"blue\",\n",
    "    \"gen_style_loss\"  : \"orange\",\n",
    "}\n",
    "\n",
    "# ── 4. Plot each group in its own figure ──────────────────────────────────────\n",
    "for title, cols in groups.items():\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    for col in cols:\n",
    "        if col in df.columns:\n",
    "            ax.plot(df[\"iteration\"], df[col],\n",
    "                    label=col,\n",
    "                    color=colors[col],\n",
    "                    linewidth=1.5,\n",
    "                    alpha=0.8)\n",
    "\n",
    "    # labels and title\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "\n",
    "    # single tick at the final iteration\n",
    "    ax.set_xticks([max_iter])\n",
    "    ax.set_xticklabels([str(max_iter)])\n",
    "\n",
    "    # force plain formatting (no offset or sci notation)\n",
    "    fmt = ScalarFormatter(useOffset=False)\n",
    "    fmt.set_scientific(False)\n",
    "    ax.xaxis.set_major_formatter(fmt)\n",
    "    ax.yaxis.set_major_formatter(ScalarFormatter(useOffset=False))\n",
    "\n",
    "    ax.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import torch.nn.functional as F\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_heads(self, n: int, prior_std: float = 1.0):\n",
    "    z_cat = F.one_hot(torch.randint(0, self.cfg.latent_dim_categorical, (n,), device=self.device), num_classes=self.cfg.latent_dim_categorical).float()\n",
    "    z_style = torch.zeros(n, self.cfg.latent_dim_style, device=self.device)\n",
    "    z = torch.cat([z_cat, z_style], dim=1)\n",
    "    return self.decoder(z)\n",
    "        \n",
    "with torch.no_grad():\n",
    "    samples = generate_heads(model, 16).cpu().view(-1, 28, 28)\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(4,4))\n",
    "for ax, img in zip(axes.flatten(), samples):\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cluster_counts(model, test_loader):\n",
    "    from collections import Counter\n",
    "\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, _ in test_loader:\n",
    "            x = x.to(model.device)\n",
    "            preds = model.predict_clusters(x)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "\n",
    "    counts = Counter(all_preds)\n",
    "    K = model.cfg.latent_dim_categorical\n",
    "    print(\"Cluster assignment counts (on test set):\")\n",
    "    for cluster_id in range(K):\n",
    "        print(f\"  Cluster {cluster_id}: {counts[cluster_id]} samples\")\n",
    "\n",
    "print_cluster_counts(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1.  map each categorical cluster → the digit it most often predicts\n",
    "# ------------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def assign_cluster_labels(model, val_loader):\n",
    "    model.eval()\n",
    "    K = model.cfg.latent_dim_categorical\n",
    "    # running best label & max-prob seen so far for each cluster\n",
    "    best_label_for = torch.full((K,), -1, dtype=torch.long, device=model.device)\n",
    "    best_prob_for  = torch.zeros(K, device=model.device)\n",
    "\n",
    "    for x, y in val_loader:                  # y are ground-truth digits\n",
    "        x, y = x.to(model.device), y.to(model.device)\n",
    "        z_cat, _ = model.forward_encoder(x)\n",
    "        probs, preds = z_cat.max(dim=1)      # highest softmax prob + its cluster id\n",
    "        for i in range(x.size(0)):\n",
    "            cid   = preds[i].item()\n",
    "            prob  = probs[i].item()\n",
    "            label = y[i].item()\n",
    "            if prob > best_prob_for[cid]:\n",
    "                best_prob_for[cid]  = prob\n",
    "                best_label_for[cid] = label\n",
    "\n",
    "    # send back a plain Python dict so it’s easy to access in plotting\n",
    "    return {int(k): int(v) for k, v in enumerate(best_label_for.cpu()) if v >= 0}\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2.  plot a small grid of images per cluster with the inferred label\n",
    "# ------------------------------------------------------------\n",
    "def plot_clusters_with_labels(model, test_loader, val_loader, num_per_cluster=5):\n",
    "    cluster_labels = assign_cluster_labels(model, val_loader)\n",
    "\n",
    "    model.eval()\n",
    "    K = model.cfg.latent_dim_categorical\n",
    "    picked = {k: [] for k in range(K)}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, _ in test_loader:\n",
    "            x = x.to(model.device)\n",
    "            preds = model.predict_clusters(x)\n",
    "            for img, cid in zip(x, preds):\n",
    "                cid = cid.item()\n",
    "                if len(picked[cid]) < num_per_cluster:\n",
    "                    picked[cid].append(img.cpu())\n",
    "            if all(len(p) >= num_per_cluster for p in picked.values()):\n",
    "                break\n",
    "\n",
    "    # keep only non-empty clusters\n",
    "    clusters = [cid for cid, imgs in picked.items() if imgs]\n",
    "    rows = len(clusters)\n",
    "    fig, axes = plt.subplots(rows, num_per_cluster, figsize=(num_per_cluster*2, rows*2))\n",
    "\n",
    "    if rows == 1:                      # matplotlib quirk: axes isn’t 2-D if rows==1\n",
    "        axes = axes[None, :]\n",
    "\n",
    "    for r, cid in enumerate(clusters):\n",
    "        label = cluster_labels.get(cid, \"?\")\n",
    "        for c in range(num_per_cluster):\n",
    "            ax = axes[r][c]\n",
    "            if c < len(picked[cid]):\n",
    "                img = picked[cid][c].reshape(28, 28)\n",
    "                ax.imshow(img, cmap='gray')\n",
    "            ax.axis('off')\n",
    "            if c == 0:\n",
    "                ax.set_title(f\"label {label}\", fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_clusters_with_labels(model, train_loader, val_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import torch.nn.functional as F\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate(self, n: int, prior_std: float = 1.0):\n",
    "    z_cat = F.one_hot(torch.randint(0, self.cfg.latent_dim_categorical, (n,), device=self.device), num_classes=self.cfg.latent_dim_categorical).float()\n",
    "    z_style = torch.randn(n, self.cfg.latent_dim_style, device=self.device) * prior_std\n",
    "    z = torch.cat([z_cat, z_style], dim=1)\n",
    "    return self.decoder(z)\n",
    "        \n",
    "\n",
    "samples = generate(model, 16).cpu().view(-1, 28, 28)\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(4,4))\n",
    "for ax, img in zip(axes.flatten(), samples):\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
